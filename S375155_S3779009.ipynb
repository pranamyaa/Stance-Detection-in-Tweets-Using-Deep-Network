{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_DL__New.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kfY_1TQrqbp9",
        "xXlnOSPUrF18",
        "X9O7hrXxaMGO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7UPIghEqvMi"
      },
      "source": [
        "# **Assignment 2: Stance Detection in Tweets using Deep Learning on SemEval 2 task 6 data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfY_1TQrqbp9"
      },
      "source": [
        "# Setting notebook and related packages and methods.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONRDMNP9xflY"
      },
      "source": [
        "First we mount the google drive so that we can access the data files from the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4etGXG5qBdFD",
        "outputId": "deee5f5c-02a2-4326-894b-5540a27ff38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWHE3jlppGdq",
        "outputId": "7898fe25-3775-42a6-fc69-7a9b2095f530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2K98JlkpGTu",
        "outputId": "9dece2d8-262f-4aac-dbe8-9caa54f94613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "! pip install -U spacy-Lookups-data"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy-Lookups-data in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy-Lookups-data) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAy-EW1pGFK",
        "outputId": "79b5eef9-276d-4329-a44c-d9cf0313e655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPLZ3OoRpSVE",
        "outputId": "1922ae3c-03bb-4392-9abc-f4608b1abcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZD-TBcbpSRZ",
        "outputId": "269e5618-c2ba-4b24-e9a9-591ee50b12f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g56Mcbq6xo30"
      },
      "source": [
        "The next step is to do some preliminary steps like importing related packages and setting up tensorboard and plotter function ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGBdLqcCCK8",
        "outputId": "ccf0e93e-c0f4-404c-aefc-f11019ba639b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Importing Related Packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "\n",
        "import re\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "import spacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "from  IPython import display\n",
        "\n",
        "\n",
        "result_df = pd.DataFrame(columns = ['model', 'F1_score'])"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939jFOCeCCCj"
      },
      "source": [
        "# Loading Tensorboard\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Open an embedded TensorBoard viewer\n",
        "%tensorboard --logdir {logdir}/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k5AbgNRCB-Y"
      },
      "source": [
        "# Plotter Function to plot performance of models\n",
        "\n",
        "from itertools import cycle\n",
        "def plotter(history_hold, metric = 'binary_crossentropy', ylim=[0.0, 1.0]):\n",
        "  cycol = cycle('bgrcmk')\n",
        "  for name, item in history_hold.items():\n",
        "    y_train = item.history[metric]\n",
        "    y_val = item.history['val_' + metric]\n",
        "    x_train = np.arange(0,len(y_val))\n",
        "\n",
        "    c=next(cycol)\n",
        "\n",
        "    plt.plot(x_train, y_train, c+'-', label=name+'_train')\n",
        "    plt.plot(x_train, y_val, c+'--', label=name+'_val')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlim([1, max(plt.xlim())])\n",
        "  plt.ylim(ylim)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel(metric)\n",
        "  plt.grid(True)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXlnOSPUrF18"
      },
      "source": [
        "# Reading data and exploring related features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVp8CiXxyfcR"
      },
      "source": [
        "We use simple read_csv function to read the training as well as test data into dataframes.\n",
        "We can see from the below output that, train data has 2914 values of 5 different features while test data has 1956 values of 5 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4RM46CxCoSJ",
        "outputId": "9b34c38e-43cc-405d-e7b0-a9d65e6f2d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Reading Training and Test datasets\n",
        "train_data = \"/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/StanceDataset/train.csv\"\n",
        "test_data = \"/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/StanceDataset/test.csv\"\n",
        "#train_data = \"/content/drive/My Drive/Colab Notebooks/TweetsDataset/train.csv\"\n",
        "#test_data = \"/content/drive/My Drive/Colab Notebooks/TweetsDataset/test.csv\"\n",
        "\n",
        "traindata = pd.read_csv(train_data, engine='python')\n",
        "testdata = pd.read_csv(test_data, engine='python')\n",
        "print(traindata.shape)\n",
        "print(testdata.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2914, 5)\n",
            "(1956, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8jTXRWvy6nr"
      },
      "source": [
        "The features of the dataset are : Tweet, Target, Stance, Opinion_towards and Sentiment. Out of which our main aim is to predict the Stance of a tweet if Tweet and Target is provided. So for our experiment, we dont need fetures like Opinion_towards and Sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ZArRuxrYkx",
        "outputId": "7733e4a4-a0c1-48af-8fbb-0fc6e61e100b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "traindata.info()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2914 entries, 0 to 2913\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Tweet            2914 non-null   object\n",
            " 1   Target           2914 non-null   object\n",
            " 2   Stance           2914 non-null   object\n",
            " 3   Opinion Towards  2914 non-null   object\n",
            " 4   Sentiment        2914 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 114.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmlOzvB_uvps",
        "outputId": "0309a8f4-df2d-4813-83f8-9931485d8a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "testdata.info()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1956 entries, 0 to 1955\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Tweet            1956 non-null   object\n",
            " 1   Target           1956 non-null   object\n",
            " 2   Stance           1956 non-null   object\n",
            " 3   Opinion Towards  1956 non-null   object\n",
            " 4   Sentiment        1956 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 76.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPBm7yWzYsR"
      },
      "source": [
        "We can see from the below code output that, traindata consists of tweets related to 5 different Target values namely,\n",
        "\n",
        "1.   Hillary Clinton\n",
        "2.   Feminist Movement\n",
        "3.   Legalization of abortion\n",
        "4.   Atheism\n",
        "5.   Climate Change is a Real Concern\n",
        "\n",
        "And the tweets are classified into 3 Stance values namely,\n",
        "\n",
        "1.   tweets that FAVOR the target value\n",
        "2.   Tweets which are AGAINST the target value\n",
        "3.   Tweets which are neither in FAVOR nor AGAINST (i.e. NONE)\n",
        "\n",
        "We can see the number tweets for each target value as well as number of tweets of eah Stance values described below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJY2bxGvCn-J",
        "outputId": "0058ca28-42ab-4a77-ab73-6c24bac0a124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# We have to classify the stance of tweets according to the tweet statements as well as the target of the tweet.\n",
        "\n",
        "print(traindata['Target'].value_counts())\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(traindata['Stance'].value_counts())"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hillary Clinton                     689\n",
            "Feminist Movement                   664\n",
            "Legalization of Abortion            653\n",
            "Atheism                             513\n",
            "Climate Change is a Real Concern    395\n",
            "Name: Target, dtype: int64\n",
            "----------------------------------------------------------\n",
            "AGAINST    1395\n",
            "NONE        766\n",
            "FAVOR       753\n",
            "Name: Stance, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ZTvy53u0C2",
        "outputId": "8350e5bf-8602-4dd0-a1ed-958edd0161d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "testdata = testdata[testdata['Target'] != \"Donald Trump\"]\n",
        "print(testdata['Target'].value_counts())\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(testdata['Stance'].value_counts())"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hillary Clinton                     295\n",
            "Feminist Movement                   285\n",
            "Legalization of Abortion            280\n",
            "Atheism                             220\n",
            "Climate Change is a Real Concern    169\n",
            "Name: Target, dtype: int64\n",
            "----------------------------------------------------------\n",
            "AGAINST    715\n",
            "FAVOR      304\n",
            "NONE       230\n",
            "Name: Stance, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQUutoH90mWR"
      },
      "source": [
        "As a next task we try to explore the distribution of tweets as per their Stance values for each target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjsnLnseCn6s",
        "outputId": "38f3a617-1325-49ae-ba7c-0f857f43f1a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# The next exploration is to check the distribution of tweets of different stance values across each target.\n",
        "traindata.groupby(['Target'])['Stance'].value_counts()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target                            Stance \n",
              "Atheism                           AGAINST    304\n",
              "                                  NONE       117\n",
              "                                  FAVOR       92\n",
              "Climate Change is a Real Concern  FAVOR      212\n",
              "                                  NONE       168\n",
              "                                  AGAINST     15\n",
              "Feminist Movement                 AGAINST    328\n",
              "                                  FAVOR      210\n",
              "                                  NONE       126\n",
              "Hillary Clinton                   AGAINST    393\n",
              "                                  NONE       178\n",
              "                                  FAVOR      118\n",
              "Legalization of Abortion          AGAINST    355\n",
              "                                  NONE       177\n",
              "                                  FAVOR      121\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbjzHf9k09i9"
      },
      "source": [
        "From the above result, we can see that the number of tweets are not evenly distributed amongst each target values. For example, There are in total 1395 tweets which are of Stance AGAINST while only  753 tweets are in FAVOR with their target value.\n",
        "\n",
        "Furthermore, we can see that, in each target value, Tweets are not distributed evenly. For example, there are 393 tweets which are in AGAINST with target 'Hillary Clinton' while there are only 15 tweets which are in AGAINST of 'Climate Change is a Real Concern'.\n",
        "\n",
        "For futher better understanding we try to plot some exploration visualisations of the tweet distribution among each target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy6FdX2-y34o",
        "outputId": "51697578-ef4c-4509-8172-f2cd281eaedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Lets try to plot a graph of the above distribution to check whether there is a class imbalance issue in the dataset\n",
        "\n",
        "Target = traindata['Target'].unique().tolist()\n",
        "df = pd.DataFrame(columns=['Target', 'FAVOR', 'AGAINST', 'NONE'])\n",
        "for target in Target:\n",
        "  data = traindata[traindata['Target']==target]\n",
        "  #print(data[data['Stance']=='FAVOR'].shape[0])\n",
        "  df = df.append({'Target': target, 'FAVOR': data[data['Stance']=='FAVOR'].shape[0], 'AGAINST': data[data['Stance']=='AGAINST'].shape[0], 'NONE': data[data['Stance']=='NONE'].shape[0]}, ignore_index= True)\n",
        "df"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>FAVOR</th>\n",
              "      <th>AGAINST</th>\n",
              "      <th>NONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>118</td>\n",
              "      <td>393</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>121</td>\n",
              "      <td>355</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Atheism</td>\n",
              "      <td>92</td>\n",
              "      <td>304</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Climate Change is a Real Concern</td>\n",
              "      <td>212</td>\n",
              "      <td>15</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Feminist Movement</td>\n",
              "      <td>210</td>\n",
              "      <td>328</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Target FAVOR AGAINST NONE\n",
              "0                   Hillary Clinton   118     393  178\n",
              "1          Legalization of Abortion   121     355  177\n",
              "2                           Atheism    92     304  117\n",
              "3  Climate Change is a Real Concern   212      15  168\n",
              "4                 Feminist Movement   210     328  126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3eHwwwP_82t",
        "outputId": "3559583c-c225-4954-d00f-15089be760f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Grouped bar graph for stance values of each target value.\n",
        "pos = list(range(len(df['FAVOR']))) \n",
        "width = 0.25 \n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "plt.bar(pos, df['FAVOR'], width, alpha=0.5, color='#FF8000', label=df['Target'][0]) \n",
        "plt.bar([p + width for p in pos], df['AGAINST'], width, alpha=0.5, color='#0080FF', label=df['Target'][1]) \n",
        "plt.bar([p + width*2 for p in pos], df['NONE'], width, alpha=0.5, color='#66FF66', label=df['Target'][2]) \n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Count of tweets')\n",
        "ax.set_xticks([p + 1.5 * width for p in pos])\n",
        "ax.set_xticklabels(df['Target'])\n",
        "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
        "plt.ylim([0, max(df['FAVOR'] + df['AGAINST'] + df['NONE'])] )\n",
        "plt.legend(['FAVOR', 'AGAINST', 'NONE'], loc='upper right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoSqqoTashRa"
      },
      "source": [
        "We can see from the above exploration that there is a large difference between number of tweets of each target value. We can also find out that there is a class imbalance problem present in the data as number of tweets have large difference between each stance for each target. For example, for target value \"Climate Change is a Real Concern\", there are only 15 tweets with Stance \"AGAINST\" it.\n",
        "\n",
        "\n",
        "So below we are using two different appraches to tackle this problem. In the first approach we are considering the whole dataset as an input to a single model and try to build a deep model to train this data. In the second approach we divide the dataset according to the target values and then try to build a model for each target value to predict its stance so there are 5 different models for 5 different target values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9O7hrXxaMGO"
      },
      "source": [
        "# Approach 1 : Building a model which takes whole data as a input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fniHrrVx5wp"
      },
      "source": [
        "The main task is to predict the Stance of a particular tweet based on the tweet content and the target it is mentioned for. \n",
        "\n",
        "So for classification purpose we concatenate the tweet statement with its corresponding target value and store it as a complete tweet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D95ZRbdanCp",
        "outputId": "880e2e9e-a31b-4baf-9246-41f735865bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# as we have to use only tweet sentences and Target as an input for detecting the Stance, we concatenate this features into a single feature \n",
        "train_data = traindata[['Tweet','Stance','Target']]\n",
        "train_data[\"Tweet\"] = train_data[\"Tweet\"] + \" \" + train_data[\"Target\"]\n",
        "train_data.shape"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpJ9ffx6RXe9"
      },
      "source": [
        "***Data Exploration***\n",
        "\n",
        "For futher deep understanding of tweet data we tried some exploration in tweets before preprocessing it. We get a better idea of which kind of preprocessing steps we need to do from it.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4b9S5nyyxSh"
      },
      "source": [
        "As a first exploration step, we need to explore the number of words and characters in tweet statements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9pgoOiManJo",
        "outputId": "c0133b20-6ad0-4e03-e13f-c1db91fd87a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# Some more exloration about the tweets which may helps in preprocessing\n",
        "\n",
        "# Word count in the Tweet column \n",
        "\n",
        "train_data['Word_Count'] = train_data['Tweet'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "\n",
        "## Character Counts in Tweet column\n",
        "\n",
        "train_data['Character_Count'] = train_data['Tweet'].apply(lambda x: len(x))\n",
        "\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Character_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...             143\n",
              "1  Hillary is our best choice if we truly want to...  ...             105\n",
              "2  @TheView I think our country is ready for a fe...  ...              97\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...             140\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...              68\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g951fDh2O4W"
      },
      "source": [
        "In the next step of exploration we checked the number of stop words in the sentence as well as the average word length of the tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOP51w3anhD",
        "outputId": "fb485d51-b8a3-44ce-de5a-147c7b044480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# Calculating the average word length [calculated using formula =  (Character_Count/Word_Count)]\n",
        "\n",
        "train_data['Average_Word_length'] = train_data['Character_Count']/train_data['Word_Count']\n",
        "\n",
        "# Counting the stop words\n",
        "\n",
        "train_data['Stop_words_count'] = train_data['Tweet'].apply(lambda x: len([t for t in x.split() if t in STOP_WORDS]))\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Stop_words_count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...                3\n",
              "1  Hillary is our best choice if we truly want to...  ...                7\n",
              "2  @TheView I think our country is ready for a fe...  ...                7\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...                7\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...                5\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly0-mF12cvr"
      },
      "source": [
        "The next step is to explore the hashtags and mentions in the tweet.  We believe gashtags and mentions play an important role during prediction task. During literature survey we came to know that from hashtags we manually extract some decisions regarding the stance of that tweet.\n",
        "\n",
        "For example, tag #NoMoreReligions depicts that the tweet should be in FAVOR with target Atheism. while tag #Godswill states probability of the tweet being AGAINST the Atheism. but some tags like #atheism are ambiguous and we cannot predict Stance manually from them.\n",
        "\n",
        "For this purpose we need to know the number of Hashtags and mentions in the tweet first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikeXBs5Banwv",
        "outputId": "3a819cdd-561e-46e1-8d65-23e4f8f20d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "## Count HashTags -> # and mentions -> @\n",
        "\n",
        "train_data['HashTag_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.startswith(\"#\")])) \n",
        "\n",
        "train_data['Mention_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.startswith(\"@\")])) \n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Mention_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...             1\n",
              "1  Hillary is our best choice if we truly want to...  ...             0\n",
              "2  @TheView I think our country is ready for a fe...  ...             1\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...             0\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...             1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U64xah9j3-wh"
      },
      "source": [
        "In the below step we checked the number of digits and Upper case characters in the tweet. That is because we believe, people mostly write in capital letters when they are either highly in FAVOR or in AGAINST with something."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSuEHVC5an8q",
        "outputId": "a09d3a2a-3081-4398-c752-5127b82205fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "## Checking the numeric digits present in the tweets\n",
        "\n",
        "train_data['numeric_digit_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.isdigit()])) \n",
        "\n",
        "# Checking the count of Upper Case in the tweet (Because mostly people write in capital when they are Happy or Sad)\n",
        "\n",
        "train_data['uppercase_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.isupper() and len(x)>3])) \n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "      <th>numeric_digit_Count</th>\n",
              "      <th>uppercase_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... uppercase_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...               0\n",
              "1  Hillary is our best choice if we truly want to...  ...               0\n",
              "2  @TheView I think our country is ready for a fe...  ...               1\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...               2\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...               0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNV-2k6hrf4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Preprocessing the tweets**\n",
        "\n",
        "After some interesting exploration in Tweet column, we started some basic preprocessing. The first and very basic step is to convert the tweet into lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr-nQaDdannk",
        "outputId": "417f2ef5-b0b1-4373-c036-84b0cfbf0fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Converting to lower case\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: x.lower()) \n",
        "\n",
        "train_data['Tweet'].head(2)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz and, #handovertheserver she wiped cle...\n",
              "1    hillary is our best choice if we truly want to...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDra46Rl43xy"
      },
      "source": [
        "the next step is to convert contracted word into their expanded format. This step is needed as we want to seperate the words like 'don't' into 'do not' so that model can understand them clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vF9MaUganY7"
      },
      "source": [
        "# Contraction to Expandion [Meaning converting words like \"don't\" to \"do not\"]\n",
        "\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i had\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she had\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that had\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they had\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "\" n \":\"and\",\n",
        "\" u \": \"you\",\n",
        "}\n",
        "\n",
        "def con_to_ext(x):\n",
        "  if type(x) is str:\n",
        "    for key in contractions:\n",
        "      value = contractions[key]\n",
        "      x = x.replace(key, value)\n",
        "    return x\n",
        "  else:\n",
        "    return x"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhfNu43aanGQ",
        "outputId": "396240d2-6557-4da7-b1f5-de6381c41eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: con_to_ext(x))\n",
        "train_data['Tweet'].head(5)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz and, #handovertheserver she wiped cle...\n",
              "1    hillary is our best choice if we truly want to...\n",
              "2    @theview i think our country is ready for a fe...\n",
              "3    i just gave an unhealthy amount of my hard-ear...\n",
              "4    @portiaaboulger thank you for adding me to you...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfGLSMgE6lBE"
      },
      "source": [
        "The next step of preprocessing we done is to remove the email ids from the tweets as they may contain personal data in alphanumeric format which does not make sense towards Stance detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h1KhlT_am_J"
      },
      "source": [
        "## Count and remove emails from the tweet\n",
        "import re\n",
        "train_data['email'] = train_data['Tweet'].apply(lambda x: re.findall(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)',x))"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CTbaaJjKQY",
        "outputId": "1d0dd6a8-d667-41bc-9eaf-3dbab2601ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Counting the number of email present in the dataset \n",
        "\n",
        "train_data['email_count'] = train_data['email'].apply(lambda x: len(x))\n",
        "\n",
        "# Checking if the emails are greater that 1\n",
        "\n",
        "train_data[train_data['email_count']>0]"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "      <th>numeric_digit_Count</th>\n",
              "      <th>uppercase_Count</th>\n",
              "      <th>email</th>\n",
              "      <th>email_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>(2/2) 300 words and be sent to climateconferen...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Climate Change is a Real Concern</td>\n",
              "      <td>17</td>\n",
              "      <td>142</td>\n",
              "      <td>8.352941</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[climateconference2015@gmail.com]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2691</th>\n",
              "      <td>worldwide r.e. agents! - support a prolife gro...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>16</td>\n",
              "      <td>129</td>\n",
              "      <td>8.062500</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[proliferealestate@yahoo.com]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet  ... email_count\n",
              "676   (2/2) 300 words and be sent to climateconferen...  ...           1\n",
              "2691  worldwide r.e. agents! - support a prolife gro...  ...           1\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtBk_1vyjJ8D"
      },
      "source": [
        "## Removing the emails from the Tweet column.\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: re.sub(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)','',x))"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptWUIYd7xys"
      },
      "source": [
        "THe next step of preprocessing is to remove special characters and punctuations from the tweets. we removed all the special characters excluding # and @ from the tweets.\n",
        "\n",
        "After that, we removed extra white spaces from tweets. and removed words which may written in Accented characters.\n",
        "\n",
        "The last step is to remove stop words from the tweet statements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TolLbs8jJbE",
        "outputId": "e25c23ba-35ee-48c1-eb39-f265a2418b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "## Removing Special characters and punctuations\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: re.sub('[^A-Za-z0-9#@]+',' ',x))\n",
        "\n",
        "## Remove the multiple(extra) spaces\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "## Remove the Accented characters (e.g. àÿüûâ)\n",
        "import unicodedata\n",
        "\n",
        "def remove_accent(x):\n",
        "  x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "  return x\n",
        "\n",
        "## Applying on tweets\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: remove_accent(x))\n",
        "\n",
        "### Removing the stop words\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
        "\n",
        "\n",
        "train_data['Tweet'].head(5)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz #handovertheserver wiped clean 30k de...\n",
              "1    hillary best choice truly want continue progre...\n",
              "2    @theview think country ready female pres hilla...\n",
              "3    gave unhealthy hard earned money away big gov ...\n",
              "4    @portiaaboulger thank adding list hillary clinton\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJkiNwVr9Nw0"
      },
      "source": [
        "The next step is to tokenize (encoding) the preprocessed tweet data and then add padding to the data to make each tweet statement of the same length.\n",
        "\n",
        "for that we copied the Tweet data into a list named 'text'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zlq3tqta-Et",
        "outputId": "de01909e-01c9-4042-d7be-f4580d97c824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train_data['Tw'] = train_data['Tweet']\n",
        "#####\n",
        "text = train_data['Tweet'].tolist()\n",
        "text[:3]"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@tedcruz #handovertheserver wiped clean 30k deleted emails explains dereliction duty lies #benghazi etc #tcot hillary clinton',\n",
              " 'hillary best choice truly want continue progressive nation #ohio hillary clinton',\n",
              " '@theview think country ready female pres hillary hillary clinton']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0TE5tZAa-tH",
        "outputId": "f54c693e-9dc9-466a-a165-7c708ec34e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#####\n",
        "y = train_data['Stance']\n",
        "y = pd.get_dummies(y).values\n",
        "y.shape"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex9V1b04a-qt",
        "outputId": "1c0f19f4-7e21-4964-bf15-e7a247dfcc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "\n",
        "### Calculating the vocabulary size\n",
        "vocab_size = len(token.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIsieoxk-RXy"
      },
      "source": [
        "we used 50 as a max length for the padding to make each sentence of max length 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpc2mg7za-B5",
        "outputId": "b011fa33-94c3-476e-caeb-d69831c32707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## Encoding the text\n",
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:3])\n",
        "\n",
        "## By default prepadding is done\n",
        "\n",
        "sentence_max_length = 50\n",
        "X = pad_sequences(encoded_text, maxlen=sentence_max_length)\n",
        "print(X.shape)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[694, 3155, 3156, 1299, 3157, 819, 124, 1859, 3158, 1022, 130, 151, 435, 51, 2, 5], [2, 53, 68, 436, 24, 311, 1023, 173, 1024, 2, 5], [3159, 34, 99, 152, 153, 1860, 2, 2, 5]]\n",
            "(2914, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pTtyMLI_6TC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Word Embedding and Transfer Learning**\n",
        "\n",
        "As we can see from the above that we have very small dataset only with 2914 data points of 5 target values. We can see from above exploration that the data also has class imbalance problem so we are using a pretrained vector weights to use better representation of the vocabulary we have in our data set. \n",
        "\n",
        "We are using Glove Twitter 100 dimensional pretrained vector present on https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "This pretrained vector is present in various dimentions as 50d, 100d and 200d but we are simply using 100d vector for our task.\n",
        "we make a glove vector dictionary to save all the words from pretrained vector file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JL5Q9xuhRT5"
      },
      "source": [
        "##### Glove Vector\n",
        "# e.g. hello -0.11 0.23 0.333 0.54 0.65\n",
        "glove_vectors = dict()\n",
        "#file = open('/content/drive/My Drive/Colab Notebooks/TweetsDataset/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "file = open('/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "glove_vectors = dict()\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  features = np.asarray(values[1:])\n",
        "  glove_vectors[word] = features\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wXUEA-CAQ2"
      },
      "source": [
        "We can see from the below code that the Glove vector has almost 1.5 million words present with dimension shape of 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVGwo3zvhRRn",
        "outputId": "2646419d-4da5-4aef-f5ed-c63c1111e47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "### Prints the length of keys in glove vector dictionary\n",
        "print(len(glove_vectors.keys()))\n",
        "\n",
        "#### displaying the shape of the glove vector just for testing purpose\n",
        "print(glove_vectors.get('to').shape)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvz2WuTpCbLf"
      },
      "source": [
        "The next step is to create an Embedded Matrix by mapping each word in our vocabulary with the same word in the Glove Vector.\n",
        "The words which are not in the Glove vector are added to the list named 'Not_words'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGB6D7DphRMG",
        "outputId": "d3cb6ee9-1341-4453-eb94-38d8c8af7bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "E_T = np.zeros((vocab_size , 100))\n",
        "Not_words = list()\n",
        "for word, i in token.word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "    else:\n",
        "      #print(word) # Printing the misspelled words\n",
        "      Not_words.append(word)\n",
        "\n",
        "print(\"Embedding Matrix size: \", E_T.size)\n",
        "print(\"Words which are not in Embedding Matrix: \", len(Not_words))"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Matrix size:  902100\n",
            "Words which are not in Embedding Matrix:  2449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brmZISQuD5vs"
      },
      "source": [
        "The next step is to split the data into Training and Validation datasets. We are using simple train_test_split() function from sklearn to split the data with split size of 0.2 which mean 80% data is used for training the model while remaining 20% data is used for validation purpose to check how well our model is generalizing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMlOHDfIhRJx",
        "outputId": "66629d95-c72e-4f57-8023-f36a3023217e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_val shape: \", X_test.shape)\n",
        "print(\"y_val shape: \", y_test.shape)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (2331, 50)\n",
            "y_train shape:  (2331, 3)\n",
            "X_val shape:  (583, 50)\n",
            "y_val shape:  (583, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNGd_W2lEYNy"
      },
      "source": [
        "We can see from the above code that, 2331 records are used for model training purpose while 583 records are used for validation of the model.\n",
        "\n",
        "---\n",
        " \n",
        "In the next code cell, we created a baseline model with Transfer Learning layer. \n",
        "\n",
        "The model architechture is like encoded input is fed to the Glove pretrained vector to create an Embedding Layer weights. We create an Embedding Layer with the weights generated above and it is our first layer of the model. Output of this layer is given to the LSTM layer with 32 memory units which has dropout rate of 0.5 and recurrent_dropout rate of 0.25. Output of this layer is again passed through the dropout layer of 0.6 value. The output of this dropout layer is fed to the ReLU dense layer of 64 unit for the non-linear activation. This output is again passed though the dropuout layer of 0.6 value and finally fed to the Softmax activation layer with 3 output units which predict the Stance as either 'FAVOR', 'AGAINST' or 'NONE'.\n",
        "\n",
        "We are using 'categorical_crossentropy' as a error metric and 'Categorical_Accuracy' as a performance metric while compiling the model. We have used basic 'adam' optimizer for the training purpose.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBywrek8hRGp"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        " \n",
        "def create_model(embedding_layer):\n",
        "\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(embedding_layer)\n",
        "  model_glove.add(LSTM(units=32, dropout=0.5, recurrent_dropout= 0.25))\n",
        "  #model_glove.add(LSTM(units=64, kernel_regularizer=regularizers.l2(0.01)))\n",
        "  model_glove.add(Dropout(0.6))\n",
        "  model_glove.add(Dense(64, activation='relu'))\n",
        "  model_glove.add(Dropout(0.4))\n",
        "  model_glove.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  #opt= tf.keras.optimizers.SGD(learning_rate= 0.02, momentum=0.6)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model_glove  "
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YbmJtWvKRO0"
      },
      "source": [
        "We dont train the embedding layer as we are using pre-trained vector weights in our embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Matbsx_6hREN",
        "outputId": "8951f428-1da5-4494-dc0d-33656680b25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "vector_size = 100\n",
        "embedding_layer = Embedding( vocab_size,\n",
        "                     vector_size,\n",
        "                     input_length=50,\n",
        "                     weights=[E_T],\n",
        "                     trainable=False)\n",
        "model1 = create_model(embedding_layer)\n",
        "print(model1.summary())"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 50, 100)           902100    \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 921,431\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 902,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__47i84wwctc"
      },
      "source": [
        "def get_callbacks(name):\n",
        "  return [\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=1),\n",
        "  ]"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVt3nWn7Ke_G"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKScRAqrhRBB",
        "outputId": "7306e2de-78b0-49b4-8840-c46776902b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from sklearn.model_selection import KFold\n",
        "#num_folds = 3\n",
        "#input = np.concatenate((X_train, X_test), axis= 0)\n",
        "#target = np.concatenate((y_train, y_test), axis= 0)\n",
        "\n",
        "#kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "#K = 1\n",
        "#for train, test in kfold.split(input, target):\n",
        "#    print(\"fold number: \", K)\n",
        "#    m_histories = {}\n",
        "#    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=64, epochs=50, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "#    K = K+1\n",
        "\n",
        "m_histories = {}\n",
        "m_histories['with_TL'] = model1.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/37 [>.............................] - ETA: 12s - loss: 1.1067WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0883s vs `on_train_batch_end` time: 0.5979s). Check your callbacks.\n",
            "37/37 [==============================] - 4s 98ms/step - loss: 1.0819 - val_loss: 1.0153\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 1.0355 - val_loss: 1.0006\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 1.0236 - val_loss: 0.9887\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 1.0090 - val_loss: 0.9805\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 1.0037 - val_loss: 0.9734\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9810 - val_loss: 0.9658\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9848 - val_loss: 0.9624\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9874 - val_loss: 0.9534\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9697 - val_loss: 0.9469\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9613 - val_loss: 0.9336\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9552 - val_loss: 0.9320\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9476 - val_loss: 0.9231\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9341 - val_loss: 0.9249\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9326 - val_loss: 0.9161\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9300 - val_loss: 0.9136\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9169 - val_loss: 0.9115\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.9101 - val_loss: 0.9090\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.9174 - val_loss: 0.9108\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.9111 - val_loss: 0.9035\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8959 - val_loss: 0.9040\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.9009 - val_loss: 0.9032\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8912 - val_loss: 0.9099\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8840 - val_loss: 0.8953\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.8767 - val_loss: 0.8873\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8768 - val_loss: 0.8800\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8675 - val_loss: 0.8892\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8600 - val_loss: 0.8813\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8589 - val_loss: 0.8834\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8583 - val_loss: 0.8730\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 0.8399 - val_loss: 0.8745\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8434 - val_loss: 0.8708\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8288 - val_loss: 0.8638\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8388 - val_loss: 0.8620\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8373 - val_loss: 0.8670\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8205 - val_loss: 0.8634\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8292 - val_loss: 0.8567\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8156 - val_loss: 0.8654\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8019 - val_loss: 0.8728\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8117 - val_loss: 0.8689\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8115 - val_loss: 0.8683\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.8076 - val_loss: 0.8505\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.7862 - val_loss: 0.8791\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7890 - val_loss: 0.8587\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.7917 - val_loss: 0.8620\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.7709 - val_loss: 0.8730\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.7973 - val_loss: 0.8579\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7611 - val_loss: 0.8728\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 0.7740 - val_loss: 0.8587\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.7821 - val_loss: 0.8577\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.7610 - val_loss: 0.8660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EsEfx51klRv",
        "outputId": "09f83339-2449-44e4-ee58-2766fc6819f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hV5Zn38e9NOISTgBxSS0RQaYtaCZqiomhoR2Q81ikVbbXWthcdO1Zrp7ba1+qUOqOjztRxPJUqpbUqWC0OrXSQqlHEekCMouABESSUjoqcAoTj/f5xr+3ehBVIgJUE8vtc17r23s9aa+9nP5B17+e4zN0RERGpq01zZ0BERFomBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVJkFCDM70MyeNLN5Zva6mV2WcoyZ2a1mtsDMXjWzowr2XWhmbyfbhVnlU0RE0llW8yDM7ADgAHefY2ZdgZeAL7r7vIJjTgW+C5wKHAP8l7sfY2b7A7OBcsCTc4929xWZZFZERLaTWQ3C3Ze5+5zk+RpgPtC3zmFnAb/x8BzQPQkspwAz3P2jJCjMAEZllVcREdle26b4EDPrDwwBnq+zqy+wpOB1dZJWX3rae48FxgJ07Njx6AMPPHCP5Lml27p1K23aqAsJVBY5KoegcshrSFm89dZbH7p777R9mQcIM+sCPAx8z91X7+n3d/fxwHiA8vJynz179p7+iBapsrKSioqK5s5Gi6CyCCqHoHLIa0hZmNni+vZlGmbNrB0RHO5z99+nHLIUKPzJX5qk1ZcuIiJNJMtRTAbcA8x39/+s57CpwNeS0UzHAqvcfRkwHRhpZj3MrAcwMkkTEZEmkmUT0/HABcBcM6tK0n4M9ANw97uAacQIpgXAOuCiZN9HZvYz4MXkvHHu/lGGeRURkToyCxDu/gxgOznGgX+qZ98EYEIGWRORjG3atInq6mpqa2ub/LO7devG/Pnzm/xzW6LCsiguLqa0tJR27do1+PwmGcUkIq1LdXU1Xbt2pX///kRrc9NZs2YNXbt2bdLPbKlyZeHuLF++nOrqagYMGNDg8zUWTET2uNraWnr27NnkwUHSmRk9e/ZsdI1OAUJEMqHg0LLsyr+HAoSIiKRSgBARkVQKECLSKp166qmsXLmSlStXcscdd3ycXllZyemnn96g9zj77LMpKyvj0EMPpVu3bpSVlVFWVsazzz5LRUUFDVnZoaqqimnTpjU6/3/9618ZPXp0o89rDAUIEWmVpk2bRvfu3bcLEI0xZcoUqqqquPvuuxk+fDhVVVVUVVUxbNiwBr/HjgLE5s2b6z3vk5/8JA899FCj89wYGuYqIpn63vegqmrnxzVGWRnccsuOj7npppvo0KEDl156KZdffjmvvPIKTzzxBE888QT33HMPs2bNYvbs2Vx55ZW88847lJWVcfLJJ3PaaadRU1PD6NGjee211zj66KP57W9/m0mn+8aNG7nmmmtYv349zzzzDFdddRXz58/nnXfeYeHChfTr14/rr7+eCy64gLVr1wJw2223MWzYMBYtWsTpp5/Oa6+9xsSJE5k6dSrr1q3jnXfe4eyzz+bGG2/c7fypBiEi+6Thw4czc+ZMAGbPnk1NTQ2bNm1i5syZnHjiiR8fd8MNN3DIIYdQVVXFTTfdBMDLL7/MLbfcwrx581i4cCGzZs3KJI/t27dn3LhxjBkzhqqqKsaMGQPAvHnz+POf/8wDDzxAnz59mDFjBnPmzGHy5Mlceumlqe9VVVXF5MmTmTt3LpMnT2bJkiWpxzWGahAikqmd/dLPytFHH81LL73E6tWr6dChA0cddRSzZ89m5syZ3HrrrVx//fX1njt06FBKS0sBKCsrY9GiRZxwwglNlXXOPPNMOnbsCMSs9EsuuYSqqiqKiop46623Us/5whe+QLdu3QA47LDDWLx4Md27d9+tfChAiMg+qV27dgwYMICJEycybNgwjjzySJ588kkWLFjAoEGDdnhuhw4dPn5eVFS0w76ALHTu3Pnj5z//+c8pKSnhlVdeYevWrRQXF6eek0We1cQkIvus4cOHc/PNN3PiiScyfPhw7rrrLoYMGbJNf0LXrl1Zs2ZNs+VxZ5+/atUqDjjgANq0acO9997Lli1bmixvChAiss8aPnw4y5Yt47jjjqOkpITi4mKGDx++zTE9e/bk+OOP54gjjuCKK67Yo59/2mmnUVpaSmlpKV/+8pdTjxkxYgTz5s2jrKyMyZMnb7f/O9/5Dr/+9a8ZPHgwb7zxxja1i6xZLKi6b9Ad5VonlUVoSeUwf/78nTbjZEWL9eXVLYu0fxcze8ndy9POVw1CRERSqZNaRKQBzj77bN59991t0v793/+dU045pUHnT58+nR/96EfbpA0YMIApU6bssTzuaQoQIiINsLsX8lNOOaXBwaSlUBOTiIikyqwGYWYTgNOB9939iJT9VwBfLcjHIKB3cj/qRcAaYAuwub4OFBERyU6WNYiJwKj6drr7Te5e5u5lwFXAU+7+UcEhI5L9Cg4iIs0gswDh7k8DH+30wHAe8EBWeRERkcZr9j4IM+tE1DQeLkh24DEze8nMxjZPzkRkX9ZS7gfRWI3J3+5qCaOYzgBm1WleOsHdl5pZH2CGmb2R1Ei2kwSQsQAlJSVUVlZmnuGWoKamptV8151RWYSWVA7dunVrtuUrtmzZ0qDPzs1aXrx4MbfddhsXXHABAOvWrWPz5s0Neo/f/OY3AB8vAPi73/1um3ysXbt2j5dDY/JXtyxqa2sb9X+kJQSIc6nTvOTuS5PH981sCjAUSA0Q7j4eGA8xk7qlzCTNWkuaNdvcVBahJZXD/Pnzt5nBm5atc86B73wH1q2DU0/dfv/Xvx7bhx9C3Run7egal5s93ND7QVx33XW8++67DB8+/OP7QdTW1nLRRRc1+H4QnTp1om3bttt856KiIjp37rzTWd3HHnss99xzD4cffjgAFRUV3HzzzWzdupXLLruM2tpaOnbsyK9+9Ss+/elPp37Wzsoip7i4mCFDhuz0vJxmbWIys27AScD/FKR1NrOuuefASOC15smhiOyt9ob7QQCMGTOGBx98EIBly5axbNkyysvL+cxnPsPMmTN5+eWXGTduHD/+8Y8zy0N9shzm+gBQAfQys2rgWqAdgLvflRx2NvCYu68tOLUEmJJE67bA/e7+v1nlU0Syt6Nf/J067Xh/r1473l+fveV+EOeccw4jR47kpz/9KQ8++ODH95letWoVF154IW+//TZmxqZNmzL5/B3JLEC4+3kNOGYiMRy2MG0hMDibXIlIa7G33A+ib9++9OzZk1dffZXJkydz113x+/knP/kJI0aMYMqUKSxatKhZmg+bfRSTiEhW9ob7QUA0M914442sWrWKI488EogaRN++fQGYOHFis+RLAUJE9ll7w/0gAEaPHs2kSZM455xzPk774Q9/yFVXXcWQIUOa/I52ObofxF6qJY1YaW4qi9CSykH3g2gZdD8IERHJREuYByEi0uLpfhAiInuIu+9wctneZm+/H8SudCeoiUlE9rji4mKWL1++Sxcl2fPcneXLl1NcXNyo81SDEJE9rrS0lOrqaj744IMm/+za2tpGXwj3VYVlUVxc/PHkv4ZSgBCRPS43Sa05VFZWNmq9oX3Z7paFmphERCSVAoSIiKRSgBARkVQKECIikkoBQkREUilAiIhIKgUIERFJpQAhIiKpFCBERCSVAoSIiKTKLECY2QQze9/MXqtnf4WZrTKzqmS7pmDfKDN708wWmNmVWeVRRETql2UNYiIwaifHzHT3smQbB2BmRcDtwN8DhwHnmdlhGeZTRERSZBYg3P1p4KNdOHUosMDdF7r7RmAScNYezZyIiOxUc6/mepyZvQL8FfiBu78O9AWWFBxTDRxT3xuY2VhgLEBJSQmVlZXZ5bYFqampaTXfdWdUFkHlEFQOebtbFs0ZIOYAB7l7jZmdCjwCDGzsm7j7eGA8QHl5ubeUm7ZnrSXdoL65qSyCyiGoHPJ2tyyabRSTu69295rk+TSgnZn1ApYCBxYcWpqkiYhIE2q2AGFmn7DkhrVmNjTJy3LgRWCgmQ0ws/bAucDU5sqniEhrlVkTk5k9AFQAvcysGrgWaAfg7ncBo4GLzWwzsB441+MGtpvN7BJgOlAETEj6JkREpAllFiDc/byd7L8NuK2efdOAaVnkS0REGkYzqUVEJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpMosQJjZBDN738xeq2f/V83sVTOba2bPmtnggn2LkvQqM5udVR5FRKR+WdYgJgKjdrD/XeAkd/8s8DNgfJ39I9y9zN3LM8qfiIjsQNus3tjdnzaz/jvY/2zBy+eA0qzyIiIijWfunt2bR4D4o7sfsZPjfgB8xt2/lbx+F1gBOPALd69buyg8dywwFqCkpOToSZMm7ZnMt3A1NTV06dKlubPRIqgsgsohqBzyGlIWI0aMeKm+lprMahANZWYjgG8CJxQkn+DuS82sDzDDzN5w96fTzk+Cx3iA8vJyr6ioyDrLLUJlZSWt5bvujMoiqByCyiFvd8uiWUcxmdmRwN3AWe6+PJfu7kuTx/eBKcDQ5smhiEjr1WwBwsz6Ab8HLnD3twrSO5tZ19xzYCSQOhJKRESyk1kTk5k9AFQAvcysGrgWaAfg7ncB1wA9gTvMDGBz0g5WAkxJ0toC97v7/2aVTxERSZflKKbzdrL/W8C3UtIXAoO3P0NERJqSZlKLiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSqkEBwswuM7P9LNxjZnPMbGTWmRMRkebT0BrEN9x9NXH7zx7ABcANmeVqFy1fDq+/Dps3N3dORET2fg29o5wlj6cC97r765bcE7QlWbQIjjgCOnaEwYPhqKNiKy+P9KKi5s6hiMjeo6E1iJfM7DEiQEw3s67A1p2dZGYTzOx9M3utnv1mZrea2QIze9XMjirYd6GZvZ1sFzYkk4cdBvfeC//4j9ChQzz/1regrAx69oRTT4Xrr4dnnoENGxr4zUVEWqmG1iC+CZQBC919nZntD1zUgPMmArcBv6ln/98DA5PtGOBO4Jjk/a8FygEnAtRUd1+xow/r2BHOPz82gK1bYeFCeO45mDkztj/9KfZ16ABDh8KgQdCnD5SUxGNu++QnoXv3BnxDEZF9VEMDxHFAlbuvNbPzgaOA/9rZSe7+tJn138EhZwG/cXcHnjOz7mZ2AFABzHD3jwDMbAYwCnhgR5+3cSNMmABHHx21iXbt4NBDY8sFjQ8/jBrEzJnx+MgjkbY1pT5UUQEXXgijR0OXLjv7tiIi+xaLa/NODjJ7FRgMHEnUCu4GznH3kxpwbn/gj+5+RMq+PwI3uPszyevHgR8RAaLY3a9L0n8CrHf3m1PeYywwFmC//Q4+evXqdwBo124rBx9cw8CBNXzta4vp3XsD69e3oW1bp127bb/zli2wZk07Vqxoz4oV7Vi5sj3vvdeJGTNK+OtfO1JcvIUTT/yAU075G2VlK2lTT8Pc1q1QW1tEbW0R69e3+fh5bW0RZs6gQavp2HGnLXMNUlNTQxdFLUBlkaNyCCqHvIaUxYgRI15y9/K0fQ2tQWx2dzezs4Db3P0eM/tmI/OaCXcfD4wHKC8v9/vvhzlzYM6cNsyZsx+zZu3HPfd8kj594Lrr4NproV8/OPhgOOQQ6N8fvv99KC6GVavisUOH3HvDs8/CxIlFPPjgJ3jssU/Qrx8MHw5r1sDKlXHOypWxrV4d59SnQ4eolZx2WvSHHHLIrn/vyspKKioqdv0N9iEqi6ByCCqHvN0ti4YGiDVmdhUxvHW4mbUB2u3yp+YtBQ4seF2apC0lahGF6ZUNecNPfSq2c8+N1+6QG281YkQ0Q73zTvRNPPJIXNh/9KPY/8Mfwvjx8IlPwIEHRvA49FD45S/h1lth4kR46KFomurePbb+/fPPu3WDrl2hc+fYOnXKP1+3Dh57DKZNg0svje1Tn4pAMXx4fM7BB6spS0RajoYGiDHAV4j5EH8zs37ATXvg86cCl5jZJKKTepW7LzOz6cC/mVmP5LiRwFW78gGFg3GPPz62QrW1+eGvX/pSdE4vWQKLF0NVFbz6Kvzbv0UH+B/+AE88AfvtF81JW7ZA374ROAD+4z9g/fqooQwcGFvhBX/UKPjP/4wA9ac/waOPwp13wi235I8pKYlgccghsZWWRp4OOCAee/ak3iYuEZE9qUEBIgkK9wGfM7PTgRfcvb6RSR8zsweImkAvM6smRia1S97zLmAaMXR2AbCOZGSUu39kZj8DXkzealyuw3pPKy7OPx85MrZChU1Gl1wSv/aXLYvmpNWrtx3p9Oij8OST255/5pnwP/8Tz//7vyPQlJZGU9P550dH+ptvRtBYsCAe33knAtFvUkq4bdsIFl26HMWRR0YNpnA76KD4DBGR3dWgAGFm5xA1hkpi0tx/m9kV7v7Qjs5z9/N2st+Bf6pn3wRgQkPyl6XCGsipp8ZWnyeegLVr40L/9tvw1ltRI8i5+uoIKoUuuihGXh11FEyaBGefHU1PbdpE7eZvf4O//jW2Zcvyj3PnbuGll+D3v4dNm7Z9zwED4Ljj4Nhj43Hw4AhEIiKN0dAmpv8HfM7d3wcws97An4EdBojWqHPnuCAPHrz9vg8+iIt7dXVsS5dGMIBIPy8Jp926wTHHxDyNL38Zhg2LZUSmT49mpvbtoaxsMaNH96CkBN5/P2aRL1oE774bTWOVlXD//fF+xcUxm/xzn4P994/zO3TY9rG4ePt+k9zz/fdXs5ZIa9TQANEmFxwSy9FKsI3Wvn00AR100Pb7Skpg3jx4/vmY2Pfcc9H3cdBBcOSRUSv56lcLzyjj8stjtvj550NNTfSRHHoonHMOnHVW1DZ69oz3ffzx6GjfsqXx+e7ePYLLMcfkt969d7UURGRv0dAA8b9Jx3FuotoYov9A9pA2bWJW96BB8PWvR9qGDfkmrsGD4Y03Im3DBnjqqVfo3HkwJ5wQ++fPjw7wus1Ns2bFciMTJ0ZzVqEuXSKolJbCU09FUCoq2rZZ7dBDo6ls5kz485/zfTL9+sWExIEDY8RXbistzQePFSvgvfdiW7w4HpcsiZrJJz8ZHfx9++af9+mj9bJEWpKGdlJfYWZfAnJjgMa7+5TssiWQn48B0QT06U/nX69du4LC4c1f/GIMpX3vvRhJ1aFDnNOnT+z/2teiprF4cfSP5LahQ+OC/dvfwt13b5+HmppoZrr88ghCObkLf9u226+eaxZb2uz0He1r1y5qS7lFFocOjUeI0WTr18fnFRXFtt9++drYgw9G81p1dQSh6uoIqvfcE/urqyMItbwlJkVarobWIHD3h4GHM8yL7Ka2bWMuRZo2bWLLDZ8dNWrb/f/yL/CTn8RFeO3aCDbr1kXwgKiFnHhi7F+/PjrQN2yA730v+kDuuguefjo/YXDz5ui7uPrqqG3MmhUX8A4doi9m0aK4yF9/fTSFXX55zE156aXYIC7mw4fHiK8JE+IiX6hLl2hC69x5CO+9lw9mfftGR/3nPx/HrVkTI7xKSuL9TjwxAs+gQdHfIyLpdhggzGwNsVjedruIQUj7ZZIraRZFRXHRTZusd/jhsaX5xCciwOxIeepE/rzS0ggaZhGA3ngjPxrsuuvyNY7i4vyExN69ownstde20rFjBIi1a6NJbPHiCCj33x/5O+20CGSPPw6TJ8d73XEHXHxxfMYPfhBBZcCACCb9+kWNLRcgC23ZEu/fr18E5d/9LprnBgyIAJ17Dw03lr3dDgOEu3dtqoxI65ZrVkqzenUsadK797bzVnIqK1+hoqKCFSsisMyfH49vvRXNTS+8EAsyFjKDn/0sAkjnzrE8y/Tp2y4D/9OfxlDhuXNjCHLHjvkRYxs2xPyVT30q8nfnnRHYCq1YER38//qvcN99+drXunURjFckaxNPnhzDmY84IrY+fdKbwrZuja1tg+v9krNpU6yCsGZNDPbo3Lm5c7R30H81afH22y+2nenRI+Z9HHfc9vvWrYtgUdhhvnhxbG++CR99tP0Ir2uvTf+c9u2jhnD11dFn8ulPx/IrHTvGRf/dd+OzcpMoe/eO2lfHjvmtsJb2wAP5yZQQzWZDh8ayLBDNYs89l+/rKS6O5rNHH43XF18c+d+4cSAvvBA1m0GD0oda78zGjRFM27eHXr1iUMKKFVH+uxOYNm2KGl2uzE87Ld7/oYciEHfpEuXVo0c8Xn11DF545ZX47rkm0qKieBw9Or12V9e6ddEPdfPN8W/eqVN+Zec5c6I5snCu0o58+GGUR+/eUbs977zI90knRTPoMcek1xo3b47v8eqr+YEi06ZFbff44+N77qr16+P/Q1Z9awoQ0ip06hQX8sKO/kJbtkRfSHV1/EHnOtNzG8SvzzffzG9/+Us0LxXq0iU/o/2SS6LprGPHWAesbdvoiM9tDz8cF7yLLooLXi6ALVmSnx8DMGZM9Ju0bx8XxzVrtr2oLFsWtaalS0t45JFIO/vsmEQJ0by3bl1+4EKHDnDGGfDP/xwBYcSI6Bf64IPoQwK48sroH1q5MgJW7rt16xYX8O9/H77xjbjI3XdffgRbcXFcPI88Mi6+Tz0F3/xm1LoKA/Cf/wxf+EIEiUMOifwtXx6rCKxYAVdcEcfNmJF/Xujkk+Pf9J57os/qtNPiexQGjTlz4JRT4sJ+/PHRpDh4cP6Yiy6C116Lsv3Sl+K79e8fAXnr1lgvbc2aqN3NnRvlfM01EdB6945y+OgjGDcu0tq3j4B3xhnx/2PKlPj+s2bF+5jFYJIePWJ5nRkzIh/9+0f+Ro6MwSQQ52zaFP9n2raNsuvUCYYMieef/3yUc24S7QEHpP+/3l0KECLEhTo3VHdH6i7FUlMTfRgLF+Z/HS9eHBfEWbPyF9zGmjYt5sSccUZshx1W/6/EXFCorHyGo46qYMmS/MRG97hY19TkBxbU1uYv1u3aRe3gwAOjaat379g+97nY3749/Pzn0cSX23JNZxDf+9vf3j5PEybEBbhPnxgOfe650TeTmweUG31WUcE2o/HquvjiaBLKrX2Wa2bLDaVetCiWpLnzzghOI0bACSf0pKIiymzUqMhfbjh4od/+NgL8734H3/1upF14YQSINm0igBcXR4AcOTLKMTfwoVu3/AV+5cqoQT71FHz2s5H25JNw1VWRh69+NWoZw4dHcAD44x9jQuusWbE9/ngEslyAOP/8+G6Fzjor/q2LiiJPBx8cW5arJDTofhB7i/Lycp89e3ZzZ6NJaEnjvJZcFuvWxUV506btt82bt7/wbdkSF/CZM2OOSm5E18EHR6AYMSLOLbxg57a1a5dw3nkHcsIJDZvIWFsbvz7btYtAUDizvu58mPrkal65ocXr18fAgSOOaLoRYjEvKILqo4/CunXrqa7u2OBmF/doFtyyJWo0uYv47li1KmpnDZ1Q6h5BvGvS6/vCC/F/Z/PmfNNi7uZnjdGQvw0zq/d+EAoQe6mWfFFsavtyWSxdGr82//CH+JVZW7v9MV27xsX4/fe3sHFjzDQcNCg/pPe44+JX/7x5224LF6bPR4H8kOjcApYjRuQvXvXZuDEu1js7LmszZjzFySfv9F5mrcLuBgg1MYm0YH37RhPJt78dvyjnzo226G7d8sN9c81Jjz32DF26nMTTT0cNZNKkuL9JoXbton9jyJBo+jjooPjlvHHjtlttbTSB/OpXcPvt0Q4+bFgEi5NOimaV3DDkt9+O54sXR8A57LD8YIHjjoPPfKZp1/Kqe8dI2XUKECJ7iU6dYqRMfdq3d4YNiwv5lVfGhX/u3Giu6NUrLtyHHNK4NusNG+KuitOnxw2vrr562/3dusVyK8cem1++/vnno4M2N4u9e/fI97BhETCOOWbno9Lco8nq//4vXtcdNGAWneY9ekQetERLNhQgRPZRRUVQVhbbrurQIZqXRoyAG26IeSDPPRdt6wMHRmdpWlu/e8xD+ctfYnv22ZhMmbvD4xFHRLAYNiw6dpcsiZFY8+bl57HU1DQ8n/vtlx8m26HDZz8eGdar165/d1GAEJFG6NMnboK1M2b5YcW5xSdXrYrazLPPRtCYPHn7JrC+faP/5BvfiMe+fSPdfdtt69YIICtXRv9K7nHFCqiq6sjFF8fIpJEj4StfiRFAu3I739znNbSJzD1GJf3hDzF0dujQxn9mS6IAISJNolu3mL9w8snxeuvWfK2hX7/oq9gTI5+efPIF9t+/gvvvj0mI558fc1HOPDPmhKxdG1tNTX55lsLnude558XFMYJszJgYNps2Ga62Nvp8br0VXn450m68MeaAXH/93rs8vgKEiDSLNm12vMbXrjLL37Tr+uujxnL//bHib24dro4dY7mNLl3yN8jq0iWapOqmf/BBTDqcPDkGBZx5ZgSLkSNjct+dd8IvfhHHHX54PD/rrJi9fcstMZ9i3LiY07Gj2eirV+fn1Lz77raPH34If/d3MZ/k1FObbp2vTAOEmY0C/gsoAu529xvq7P85MCJ52Qno4+7dk31bgLnJvvfcvQEVWxGRvDZtYpLcCSfEr/t16+Ki39hO7dtvj8lvkydHsLjvvqjtrF0bgwHOOAMuuyz6anJ9MjfdFE1ll14a2y9/CbfdFkOPN26MpTdeeCG255+PfpdCvXrF5MKjj448P/pozNTu2jVmZJ93XgSNLCfKZRYgzKwIuB04GagGXjSzqe4+L3eMu19ecPx3gSEFb7He3Xeje01EJK9t24at6VXfubnmsTvuiKVCHn44OsW/8536l9kfNChGf02ZEsuTnHRSdNC//XZ+Ycg+fWJk11e+EvtyKwLXzevmzTEh8IEH4rPvvTeW1P/ylyOAZTGSK8saxFBggbsvBDCzScBZwLx6jj8PqGd5NBGRlqF9+2jmOZ3OnggAAAuPSURBVPXUhh1vBv/wD9F/ceON0Yk9alR0YA8dGv0vDZn13bZtrF/1hS9EkJo+Pfo93nsvu2G+mc2kNrPRwCh3/1by+gLgGHe/JOXYg4DngFJ335KkbQaqgM3ADe7+SD2fMxYYC1BSUnL0pEmTsvg6LU5NTQ1ddmVYxj5IZRFUDqG1lUNu6HCahpTFiBEjWvxM6nOBh3LBIXGQuy81s4OBJ8xsrru/U/dEdx8PjIdYamNfXXKhrn15eYnGUlkElUNQOeTtbllkOQF+KVC4NmZpkpbmXOCBwgR3X5o8LgQq2bZ/QkREMpZlgHgRGGhmA8ysPREEptY9yMw+A/QA/lKQ1sPMOiTPewHHU3/fhYiIZCCzJiZ332xmlwDTiWGuE9z9dTMbB8x291ywOBeY5Nt2hgwCfmFmW4kgdkPh6CcREclepn0Q7j4NmFYn7Zo6r/8l5bxngc9mmTcREdmxJlyEV0RE9iYKECIikkoBQkREUilAiIhIKgUIERFJpQAhIiKpFCBERCSVAoSIiKRSgBARkVQKECIikkoBQkREUilAiIhIKgUIERFJpQAhIiKpFCBERCSVAoSIiKRSgBARkVQKECIikirTAGFmo8zsTTNbYGZXpuz/upl9YGZVyfatgn0XmtnbyXZhlvkUEZHtZXZPajMrAm4HTgaqgRfNbKq7z6tz6GR3v6TOufsD1wLlgAMvJeeuyCq/IiKyrSxrEEOBBe6+0N03ApOAsxp47inADHf/KAkKM4BRGeVTRERSZFaDAPoCSwpeVwPHpBz3JTM7EXgLuNzdl9Rzbt+0DzGzscBYgJKSEiorK3c/53uBmpqaVvNdd0ZlEVQOQeWQt7tlkWWAaIg/AA+4+wYz+zbwa+DzjXkDdx8PjAcoLy/3ioqKPZ7JlqiyspLW8l13RmURVA5B5ZC3u2WRZRPTUuDAgtelSdrH3H25u29IXt4NHN3Qc0VEJFtZBogXgYFmNsDM2gPnAlMLDzCzAwpengnMT55PB0aaWQ8z6wGMTNJERKSJZNbE5O6bzewS4sJeBExw99fNbBww292nApea2ZnAZuAj4OvJuR+Z2c+IIAMwzt0/yiqvIiKyvUz7INx9GjCtTto1Bc+vAq6q59wJwIQs8yciIvXTTGoREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkyDRBmNsrM3jSzBWZ2Zcr+75vZPDN71cweN7ODCvZtMbOqZJuaZT5FRGR7md2T2syKgNuBk4Fq4EUzm+ru8woOexkod/d1ZnYxcCMwJtm33t3LssqfiIjsWJY1iKHAAndf6O4bgUnAWYUHuPuT7r4uefkcUJphfkREpBGyDBB9gSUFr6uTtPp8E/hTwetiM5ttZs+Z2RezyKCIiNQvsyamxjCz84Fy4KSC5IPcfamZHQw8YWZz3f2dlHPHAmMBSkpKqKysbIosN7uamppW8113RmURVA5B5ZC3u2WRZYBYChxY8Lo0SduGmf0d8P+Ak9x9Qy7d3ZcmjwvNrBIYAmwXINx9PDAeoLy83CsqKvbcN2jBKisraS3fdWdUFkHlEFQOebtbFlk2Mb0IDDSzAWbWHjgX2GY0kpkNAX4BnOnu7xek9zCzDsnzXsDxQGHntoiIZCyzGoS7bzazS4DpQBEwwd1fN7NxwGx3nwrcBHQBfmdmAO+5+5nAIOAXZraVCGI31Bn9JCIiGcu0D8LdpwHT6qRdU/D87+o571ngs1nmTUREdkwzqUVEJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVAoQIiKSSgFCRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChIiIpFKAEBGRVJkGCDMbZWZvmtkCM7syZX8HM5uc7H/ezPoX7LsqSX/TzE7JMp8iIrK9zAKEmRUBtwN/DxwGnGdmh9U57JvACnc/FPg58O/JuYcB5wKHA6OAO5L3ExGRJpJlDWIosMDdF7r7RmAScFadY84Cfp08fwj4gplZkj7J3Te4+7vAguT9RESkibTN8L37AksKXlcDx9R3jLtvNrNVQM8k/bk65/ZN+xAzGwuMTV7WmNmbu5/1vUIv4MPmzkQLobIIKoegcshrSFkcVN+OLANEk3D38cD45s5HUzOz2e5e3tz5aAlUFkHlEFQOebtbFlk2MS0FDix4XZqkpR5jZm2BbsDyBp4rIiIZyjJAvAgMNLMBZtae6HSeWueYqcCFyfPRwBPu7kn6uckopwHAQOCFDPMqIiJ1ZNbElPQpXAJMB4qACe7+upmNA2a7+1TgHuBeM1sAfEQEEZLjHgTmAZuBf3L3LVnldS/V6prVdkBlEVQOQeWQt1tlYfGDXUREZFuaSS0iIqkUIEREJJUCxF7AzCaY2ftm9lpB2v5mNsPM3k4eezRnHpuCmR1oZk+a2Twze93MLkvSW2NZFJvZC2b2SlIWP03SByTL1ixIlrFp39x5bQpmVmRmL5vZH5PXra4czGyRmc01syozm52k7dbfhgLE3mEiseRIoSuBx919IPB48npftxn4Z3c/DDgW+KdkWZbWWBYbgM+7+2CgDBhlZscSy9X8PFm+ZgWxnE1rcBkwv+B1ay2HEe5eVjD3Ybf+NhQg9gLu/jQxyqtQ4TIlvwa+2KSZagbuvszd5yTP1xAXhL60zrJwd69JXrZLNgc+TyxbA62kLMysFDgNuDt5bbTCcqjHbv1tKEDsvUrcfVny/G9ASXNmpqklK/8OAZ6nlZZF0qxSBbwPzADeAVa6++bkkHqXqNnH3AL8ENiavO5J6ywHBx4zs5eSJYhgN/829vqlNiR+TZpZqxmvbGZdgIeB77n76vjBGFpTWSRzg8rMrDswBfhMM2epyZnZ6cD77v6SmVU0d36a2QnuvtTM+gAzzOyNwp278rehGsTe6//M7ACA5PH9Zs5PkzCzdkRwuM/df58kt8qyyHH3lcCTwHFA92TZGmgdS9QcD5xpZouIFaM/D/wXra8ccPelyeP7xA+Goezm34YCxN6rcJmSC4H/aca8NImkbfkeYL67/2fBrtZYFr2TmgNm1hE4meiTeZJYtgZaQVm4+1XuXuru/YmVGJ5w96/SysrBzDqbWdfcc2Ak8Bq7+behmdR7ATN7AKgglu79P+Ba4BHgQaAfsBg4x93rdmTvU8zsBGAmMJd8e/OPiX6I1lYWRxKdjkXED70H3X2cmR1M/JLeH3gZON/dNzRfTptO0sT0A3c/vbWVQ/J9pyQv2wL3u/u/mllPduNvQwFCRERSqYlJRERSKUCIiEgqBQgREUmlACEiIqkUIEREJJUChEgjmNmWZLXM3LbHFgY0s/6FK/aKNDcttSHSOOvdvay5MyHSFFSDENkDkrX4b0zW43/BzA5N0vub2RNm9qqZPW5m/ZL0EjObktzP4RUzG5a8VZGZ/TK5x8NjySxpkWahACHSOB3rNDGNKdi3yt0/C9xGrDAK8N/Ar939SOA+4NYk/VbgqeR+DkcBryfpA4Hb3f1wYCXwpYy/j0i9NJNapBHMrMbdu6SkLyJu4LMwWVDwb+7e08w+BA5w901J+jJ372VmHwClhcs/JEuYz0hu7oKZ/Qho5+7XZf/NRLanGoTInuP1PG+MwvWCtqB+QmlGChAie86Ygse/JM+fJVYZBfgqsdggxO0fL4aPb/zTrakyKdJQ+nUi0jgdk7u45fyvu+eGuvYws1eJWsB5Sdp3gV+Z2RXAB8BFSfplwHgz+yZRU7gYWIZIC6I+CJE9IOmDKHf3D5s7LyJ7ipqYREQklWoQIiKSSjUIERFJpQAhIiKpFCBERCSVAoSIiKRSgBARkVT/H2ECdV8Z/AJpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "190IQVmlRb06"
      },
      "source": [
        "**Evaluating on test data.**\n",
        "\n",
        "After training the model on training data we are going to predict the data mentioned in the test data set.\n",
        "But before that, we have preprocess the test data same as the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeDae0NKpDs9",
        "outputId": "42d329b6-a9cb-495d-f3c4-4b9abd5dcc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "def preprocessing(data):\n",
        "   data = data[['Tweet','Stance','Target']]\n",
        "   data[\"Tweet\"] = data[\"Tweet\"] + \" \" +data[\"Target\"]\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: x.lower()) \n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: con_to_ext(x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: re.sub(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)','',x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: re.sub('[^A-Za-z0-9#@]+',' ',x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: remove_accent(x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
        "   text = data['Tweet'].tolist()\n",
        "   return text\n",
        "\n",
        "text = preprocessing(testdata)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMStB_Bpyi05",
        "outputId": "fd56b1bf-4e91-437f-d5a3-ec395edbc6ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = testdata['Stance']\n",
        "y = pd.get_dummies(y).values\n",
        "y.shape"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1249, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoZVHlcczOjg"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "encoded_text = token.texts_to_sequences(text)\n",
        "X = pad_sequences(encoded_text, maxlen=sentence_max_length)"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_s2rLpfzpDu"
      },
      "source": [
        "y_pred_test = model1.predict_classes(X) "
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye1vhxBKzzjz",
        "outputId": "32decae8-6f8f-4c1e-8759-fe187edf01bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = np.argmax(y, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(y_true, y_pred_test,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach1_All_data_model', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4929876235139486"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmcvYG6GaZAp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Approach 2 : Building separate model for each target value. i.e. 5 models for 5 different targets in training data\n",
        "\n",
        "\n",
        "\n",
        "In this approach, we split the whole dataset into 5 subsets each for one Target value and then construct model for each target to predict if the tweet is in FAVOR of that target or AGAINST that target or NONE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeMLkxwkXkZS"
      },
      "source": [
        "## We are dividing the whole training data into subsets according to the target subject value.\n",
        "\n",
        "traindata_HC = traindata[traindata['Target'] == \"Hillary Clinton\"]\n",
        "testdata_HC = testdata[testdata['Target'] == \"Hillary Clinton\"]\n",
        "traindata_AB = traindata[traindata['Target'] == \"Legalization of Abortion\"]\n",
        "testdata_AB = testdata[testdata['Target'] == \"Legalization of Abortion\"]\n",
        "traindata_AT = traindata[traindata['Target'] == \"Atheism\"]\n",
        "testdata_AT = testdata[testdata['Target'] == \"Atheism\"]\n",
        "traindata_CC = traindata[traindata['Target'] == \"Climate Change is a Real Concern\"]\n",
        "testdata_CC = testdata[testdata['Target'] == \"Climate Change is a Real Concern\"]\n",
        "traindata_FM = traindata[traindata['Target'] == \"Feminist Movement\"]\n",
        "testdata_FM = testdata[testdata['Target'] == \"Feminist Movement\"]"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYUy_g85O6Kf"
      },
      "source": [
        "From the Approach 1, we now knew the exact preprocessing steps required for the tweets. and hence we used minimum required steps of preprocessing on each subset of training data. \n",
        "\n",
        "We have created one method to preprocess the data provided. This preprocessing involves \n",
        "1. concatenating Tweet and Targets\n",
        "2. converting text into Lowercase\n",
        "3. removing some bad symbols like brackets and other alphanumeric characters except # and @\n",
        "4. We will apply this method on each dataset created above as a preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoz-Yq9tXksi"
      },
      "source": [
        "## We are doing some pre-processing steps prior modelling \n",
        "## 1. concatenating Tweet and Targets\n",
        "## 2. converting text into Lowercase\n",
        "## 3. removing some bad symbols like brackets and other alphanumeric characters except # and @\n",
        "## 4. We will apply this method on each dataset created above as a preprocessing data\n",
        "\n",
        "def TextPreprocessing(traindata):\n",
        "  traindata = traindata.reset_index(drop= True)\n",
        "  REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;]')\n",
        "  BAD_SYMBOLS_RE = re.compile('[^a-z #@]')\n",
        "  Tweet_Lines = list()\n",
        "  Tweets = list()\n",
        "  tknzr = TweetTokenizer()\n",
        "\n",
        "  def clean_text(text):\n",
        "      text = text.lower() # lowercase text\n",
        "      text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "      text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "      text = ''.join(word for word in text.split() if word not in stopwords.words()) # remove stopwords from text\n",
        "      return text\n",
        "\n",
        "  traindata['Tweet'] = traindata.Tweet + ' ' + traindata.Target\n",
        "  lines = traindata['Tweet'].values.tolist()\n",
        "  for line in lines:\n",
        "      tokens = tknzr.tokenize(line)\n",
        "      Tweet_Lines = list()\n",
        "      for token in tokens:\n",
        "        token = clean_text(token)\n",
        "        if token != '' :\n",
        "          Tweet_Lines.append(token)\n",
        "      Tweets.append(Tweet_Lines)\n",
        "          \n",
        "  return Tweets"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3Sag7uXkfU"
      },
      "source": [
        "Tweets_HC = TextPreprocessing(traindata_HC)\n",
        "Tweets_AB = TextPreprocessing(traindata_AB)\n",
        "Tweets_AT = TextPreprocessing(traindata_AT)\n",
        "Tweets_CC = TextPreprocessing(traindata_CC)\n",
        "Tweets_FM = TextPreprocessing(traindata_FM)\n",
        "\n",
        "Test_Tweets_HC = TextPreprocessing(testdata_HC)\n",
        "Test_Tweets_AB = TextPreprocessing(testdata_AB)\n",
        "Test_Tweets_AT = TextPreprocessing(testdata_AT)\n",
        "Test_Tweets_CC = TextPreprocessing(testdata_CC)\n",
        "Test_Tweets_FM = TextPreprocessing(testdata_FM)"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5nhHtkuPam7"
      },
      "source": [
        "We have to do similar tokenizing and padding task for each of the 5 datasets so we created a generic method which is used to do tokenization and padding.\n",
        "\n",
        "We have used 40 as a max length while padding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKs7MVplfJW-"
      },
      "source": [
        "## Tokenizing and padding the Tweets data to make it suitable for further modelling.\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LENGTH = 40\n",
        "embedding_dim = 100\n",
        "\n",
        "def Padding(Tweets):  \n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(Tweets)\n",
        "  word_index = tokenizer.word_index\n",
        "  print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "  X = tokenizer.texts_to_sequences(Tweets)\n",
        "  X = pad_sequences(X, maxlen=MAX_LENGTH, padding= 'post')\n",
        "  print('Shape of data tensor:', X.shape)\n",
        "\n",
        "  return X, word_index"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOncA-sP_iF"
      },
      "source": [
        "The next step is to split the data for training and validation. We have simply used train_test_split() function from sklearn to split the data with provided split size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLD2-gXytvLO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split(X, Y, split_size):\n",
        "    X_train, X_Val, Y_train, Y_Val = train_test_split(X, Y, test_size= split_size, random_state = 42)\n",
        "    return X_train, X_Val, Y_train, Y_Val"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11z4YpgTu160"
      },
      "source": [
        "def get_callbacks(name):\n",
        "  return [\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=1),\n",
        "  ]"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWsGX69fQTjF"
      },
      "source": [
        "**Baseline Model**\n",
        "\n",
        "In the next code cell, we created a baseline model with Transfer Learning layer. \n",
        "\n",
        "The model architechture is like encoded input is fed to the Glove pretrained vector to create an Embedding Layer weights. We create an Embedding Layer with the weights generated above and it is our first layer of the model. Output of this layer is given to the LSTM layer with 32 memory units which has dropout rate of 0.5 and recurrent_dropout rate of 0.25. Output of this layer is again passed through the dropout layer of 0.6 value. The output of this dropout layer is fed to the ReLU dense layer of 64 unit for the non-linear activation. This output is again passed though the dropuout layer of 0.6 value and finally fed to the Softmax activation layer with 3 output units which predict the Stance as either 'FAVOR', 'AGAINST' or 'NONE'.\n",
        "\n",
        "We are using 'categorical_crossentropy' as a error metric and 'Categorical_Accuracy' as a performance metric while compiling the model. We have used basic 'adam' optimizer for the training purpose.\n",
        "\n",
        "Here we are checking the model with and without transfer learning for each of 5 target related models hence we have created a method which will construct a model as per the provided embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbVybWPDu3f5"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "\n",
        "def create_model(embedding_layer):\n",
        "\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(embedding_layer)\n",
        "  model_glove.add(LSTM(units=32, dropout= 0.5, recurrent_dropout= 0.25, kernel_regularizer=regularizers.l2(0.001)))\n",
        "  #model_glove.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, recurrent_dropout= 0.25)))\n",
        "  #model_glove.add(LSTM(units=64, kernel_regularizer=regularizers.l2(0.01)))\n",
        "  model_glove.add(Dropout(0.4))\n",
        "  model_glove.add(Dense(64, activation='relu'))\n",
        "  model_glove.add(Dropout(0.3))\n",
        "  model_glove.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  #opt= tf.keras.optimizers.SGD(learning_rate= 0.015, momentum= 0.9)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model_glove  "
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJlSroDPuctp"
      },
      "source": [
        "**Word Embedding and Transfer Learning**\n",
        "\n",
        "As we can see from the above that we have very small dataset only with 2914 data points of 5 target values. We can see from above exploration that the data also has class imbalance problem so we are using a pretrained vector weights to use better representation of the vocabulary we have in our data set. \n",
        "\n",
        "We are using Glove Twitter 100 dimensional pretrained vector present on https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "This pretrained vector is present in various dimentions as 50d, 100d and 200d but we are simply using 100d vector for our task.\n",
        "we make a glove vector dictionary to save all the words from pretrained vector file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-rz1hPOuWuF"
      },
      "source": [
        "#file = open('/content/drive/My Drive/Colab Notebooks/TweetsDataset/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "file = open('/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "glove_vectors = dict()\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  features = np.asarray(values[1:])\n",
        "  glove_vectors[word] = features\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh2kj1jcsSBM"
      },
      "source": [
        "# **1. modelling for tweets related to Target : Hillary Clinton**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElHeoAt3RK1x"
      },
      "source": [
        "First we check the preprocessed tweet data for target Hillary Clinton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbUZD-AE0JAI",
        "outputId": "5592b443-cb73-4557-adc9-556d9bf622b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_HC[:1]"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['@tedcruz',\n",
              "  '#handovertheserver',\n",
              "  'wiped',\n",
              "  'clean',\n",
              "  'deleted',\n",
              "  'emails',\n",
              "  'explains',\n",
              "  'dereliction',\n",
              "  'duty',\n",
              "  'lies',\n",
              "  '#benghazi',\n",
              "  'etc',\n",
              "  '#tcot',\n",
              "  'hillary',\n",
              "  'clinton']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxRy1JBoRScS"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXrlCw2QfJPm",
        "outputId": "472952fd-8537-4269-e1d9-1d6d38ff005c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_HC)\n",
        "Y = pd.get_dummies(traindata_HC['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2966 unique tokens.\n",
            "Shape of data tensor: (689, 40)\n",
            "Shape of label tensor: (689, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x275qrnrjtXA"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiT6k6-ZDvJf",
        "outputId": "0520d3d9-3332-461b-8425-ff34a8300d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (551, 40)\n",
            "Y train shape:  (551, 3)\n",
            "X Val shape:  (138, 40)\n",
            "Y Val shape:  (138, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDYjJn7mv5W6"
      },
      "source": [
        "**Model without Transfer Learning**\n",
        "\n",
        "First we try to model without transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hirEyLi6wUZ6",
        "outputId": "a8713a09-bd8d-4d2b-c1df-fa49a7deba6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model2 = create_model(embedding_layer)\n",
        "print(model2.summary())"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 40, 100)           296700    \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 316,031\n",
            "Trainable params: 316,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMm66YgkzHT"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 20 epochs in each of the 3 folds.\n",
        "The batch size is set to 32 and we trained the data for 20 epochs and 3 folds.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQq9_JExwxag",
        "outputId": "8fdb86e8-eac0-461b-aca9-ed2e9dcc2a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model2.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/15 [===>..........................] - ETA: 4s - loss: 1.1955WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0703s vs `on_train_batch_end` time: 0.5754s). Check your callbacks.\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 1.1546 - val_loss: 1.0937\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 1.0801 - val_loss: 1.0722\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.0341 - val_loss: 1.0538\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.0301 - val_loss: 1.0454\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 1.0086 - val_loss: 1.0350\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 1.0246 - val_loss: 1.0291\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 85ms/step - loss: 1.0015 - val_loss: 1.0266\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 90ms/step - loss: 1.0243 - val_loss: 1.0191\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.9920 - val_loss: 1.0161\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 85ms/step - loss: 0.9995 - val_loss: 1.0129\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.9912 - val_loss: 1.0100\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.9981 - val_loss: 1.0084\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.9791 - val_loss: 1.0099\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 0.9814 - val_loss: 1.0090\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.9904 - val_loss: 1.0036\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.9849 - val_loss: 1.0052\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.9802 - val_loss: 1.0032\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.9821 - val_loss: 1.0051\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.9868 - val_loss: 1.0023\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.9770 - val_loss: 1.0027\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.9893 - val_loss: 0.9666\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.9936 - val_loss: 0.9671\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.9924 - val_loss: 0.9683\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.9970 - val_loss: 0.9686\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.9937 - val_loss: 0.9657\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.9888 - val_loss: 0.9596\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.9572 - val_loss: 0.8276\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 78ms/step - loss: 0.6604 - val_loss: 0.6392\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 84ms/step - loss: 0.5596 - val_loss: 0.7503\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 80ms/step - loss: 0.5002 - val_loss: 0.7077\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.4588 - val_loss: 0.7993\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 76ms/step - loss: 0.6061 - val_loss: 1.0926\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 69ms/step - loss: 0.4700 - val_loss: 0.7499\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 86ms/step - loss: 0.4720 - val_loss: 0.8170\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 80ms/step - loss: 0.4664 - val_loss: 1.2481\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.5499 - val_loss: 0.9554\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.4660 - val_loss: 0.9000\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.4950 - val_loss: 0.9722\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 75ms/step - loss: 0.4761 - val_loss: 0.9528\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 74ms/step - loss: 0.4721 - val_loss: 0.9300\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 77ms/step - loss: 0.6742 - val_loss: 0.4660\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 73ms/step - loss: 0.7358 - val_loss: 0.4369\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.6809 - val_loss: 0.4487\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 72ms/step - loss: 0.6534 - val_loss: 0.4691\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 75ms/step - loss: 0.5938 - val_loss: 0.4659\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 76ms/step - loss: 0.6200 - val_loss: 0.4555\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.5990 - val_loss: 0.4497\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5731 - val_loss: 0.4462\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.5504 - val_loss: 0.4301\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.5395 - val_loss: 0.4211\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.5403 - val_loss: 0.4249\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5138 - val_loss: 0.4230\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5309 - val_loss: 0.4193\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.5152 - val_loss: 0.4186\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.4931 - val_loss: 0.4129\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 0.4578 - val_loss: 0.4058\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.4839 - val_loss: 0.4096\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.4444 - val_loss: 0.4090\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.4492 - val_loss: 0.4132\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.4441 - val_loss: 0.4071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD5NMWk0lOWL"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ObT2XJfxELR",
        "outputId": "f535f04a-337f-4ec6-eecc-9e6f0764312a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUvG0BXKM3ch",
        "outputId": "7f5a75e1-dc14-4ee1-9f0d-53646e2da1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_HC)\n",
        "Y_true = pd.get_dummies(testdata_HC['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1600 unique tokens.\n",
            "Shape of data tensor: (295, 40)\n",
            "Shape of label tensor: (295, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVJAH2oeM3IV",
        "outputId": "d5850634-9b6f-428c-b852-8f31b15ede57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_HC_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5317073170731706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5dx-eGBl3mr"
      },
      "source": [
        "**Model with Transfer Learning**\n",
        "\n",
        "we try to model with transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_u1IEZrmSlg",
        "outputId": "bf4e8d22-b346-43e5-d0ee-1265a34a4797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296700"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYFvAnzHydbj",
        "outputId": "27bbc6bd-2cfb-4179-cec4-63906d1a07a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model2 = create_model(embedding_layer_TL)\n",
        "print(model2.summary())"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 40, 100)           296700    \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 316,031\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 296,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48l4e_FTyxVr",
        "outputId": "a25d9570-ad70-404f-953a-4008fe80ec22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model2.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/18 [==>...........................] - ETA: 4s - loss: 1.2104WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0545s vs `on_train_batch_end` time: 0.4752s). Check your callbacks.\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 1.1714 - val_loss: 1.1139\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 1.0719 - val_loss: 1.0478\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 1.0306 - val_loss: 1.0259\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 1.0141 - val_loss: 1.0154\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9993 - val_loss: 1.0021\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9998 - val_loss: 0.9981\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9832 - val_loss: 0.9900\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9700 - val_loss: 0.9819\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9557 - val_loss: 0.9542\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9449 - val_loss: 0.9419\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9303 - val_loss: 0.9389\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.9284 - val_loss: 0.9434\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8851 - val_loss: 0.9601\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9126 - val_loss: 1.0036\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.9282 - val_loss: 0.9440\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8959 - val_loss: 0.9575\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8811 - val_loss: 0.9404\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.8871 - val_loss: 0.9670\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.8699 - val_loss: 0.9569\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8558 - val_loss: 0.9555\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8906 - val_loss: 0.9750\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8641 - val_loss: 0.9159\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8721 - val_loss: 0.9742\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8558 - val_loss: 0.9441\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8584 - val_loss: 1.0096\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8326 - val_loss: 0.9289\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8491 - val_loss: 0.9367\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8519 - val_loss: 0.9283\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8582 - val_loss: 0.9656\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8341 - val_loss: 0.9453\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8370 - val_loss: 0.9417\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.8490 - val_loss: 0.9475\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8384 - val_loss: 0.9365\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8337 - val_loss: 0.9468\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8331 - val_loss: 0.9580\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8361 - val_loss: 0.9993\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8218 - val_loss: 0.9790\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8247 - val_loss: 0.9625\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8122 - val_loss: 0.9761\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8225 - val_loss: 0.9628\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8151 - val_loss: 0.9523\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8094 - val_loss: 0.9372\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8208 - val_loss: 1.0028\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8163 - val_loss: 0.9436\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8220 - val_loss: 1.0156\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8016 - val_loss: 0.9524\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7930 - val_loss: 0.9425\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7769 - val_loss: 1.0184\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.8066 - val_loss: 0.9427\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7743 - val_loss: 0.9671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08-b6AZBy9lr",
        "outputId": "ae455cf8-3067-4ab5-d32b-40cd9e19c1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c9FWMJWQNCAgIJKFbUIEnEDhbYqVavSImBba61Kq1K1rdalLo9oq0Uf28eiVaqISwtYKxb94YJCFLFWI0ZAUNkFxKKAQECWJNfvj3vGmYSTZEJykkC+79frvDJz1nvuzJzr3Mu5j7k7IiIiZTWq6wSIiEj9pAAhIiKRFCBERCSSAoSIiERSgBARkUgKECIiEim2AGFmXc1sppktMLP3zezKiHXMzO41s8VmNtfMjk5bdoGZLUpMF8SVThERiWZx3QdhZp2ATu4+x8xaA+8A57j7grR1Tgd+AZwOHAv8n7sfa2b7APlALuCJbfu6+4ZYEisiIruIrQTh7mvcfU7i9WZgIdC5zGpnA4958CbQNhFYTgOmu/v6RFCYDgyOK60iIrKrxrVxEDPrBvQB/lNmUWdgZdr7VYl55c2P2vdIYCRA8+bN+3bt2rVG0lzflZSU0KiRmpBAeZGkfAiUDymZ5MVHH330ubvvG7Us9gBhZq2AfwJXufummt6/u48DxgHk5uZ6fn5+TR+iXsrLy2PgwIF1nYx6QXkRKB8C5UNKJnlhZivKWxZrmDWzJoTg8Dd3fzpildVA+iV/l8S88uaLiEgtibMXkwEPAwvd/Z5yVpsK/DjRm+k4YKO7rwFeBE41s3Zm1g44NTFPRERqSZxVTCcC5wPzzKwgMe8G4AAAd38AmEbowbQY2ApcmFi23sxuA95ObDfa3dfHmFYRESkjtgDh7q8DVsk6DlxezrLxwPgYkiYiMdu5cyerVq1i27ZttX7sNm3asHDhwlo/bn2UnhfZ2dl06dKFJk2aZLx9rfRiEpGGZdWqVbRu3Zpu3boRaptrz+bNm2ndunWtHrO+SuaFu7Nu3TpWrVpF9+7dM95efcFEpMZt27aN9u3b13pwkGhmRvv27atcolOAEJFYKDjUL7vz/1CAEBGRSAoQIiISSQFCRBqk008/nS+++IIvvviC+++//6v5eXl5nHnmmRntY8iQIfTu3ZtDDjmENm3a0Lt3b3r37s0bb7zBwIEDyWRkh4KCAqZNm1bl9H/yyScMHTq0yttVhQKEiDRI06ZNo23btrsEiKqYMmUKBQUFPPTQQwwYMICCggIKCgo44YQTMt5HRQGiqKio3O32339/nnrqqSqnuSrUzVVEYnXVVVBQUPl6VdG7N/zpTxWvc9ddd9GsWTOuuOIKfvnLX/Lee+8xY8YMZsyYwcMPP8zs2bPJz8/nuuuuY8mSJfTu3ZtTTjmFM844g8LCQoYOHcr8+fPp27cvTzzxRCyN7jt27ODmm2/myy+/5PXXX+f6669n4cKFLFmyhKVLl3LAAQdwxx13cP7557NlyxYAxo4dywknnMDy5cs588wzmT9/PhMmTGDq1Kls3bqVJUuWMGTIEMaMGVPt9KkEISJ7pQEDBjBr1iwA8vPzKSwsZOfOncyaNYuTTjrpq/XuvPNODj74YAoKCrjrrrsAePfdd/nTn/7EggULWLp0KbNnz44ljU2bNmX06NEMHz6cgoIChg8fDsCCBQt4+eWXmThxIvvttx/Tp09nzpw5TJ48mSuuuCJyXwUFBUyePJl58+YxefJkVq5cGbleVagEISKxquxKPy59+/blnXfeYdOmTTRr1oyjjz6a/Px8Zs2axb333ssdd9xR7rb9+vWjS5cuAPTu3Zvly5fTv3//2ko6Z511Fs2bNwfCXemjRo2ioKCArKwsPvroo8htvvWtb9GmTRsADj/8cFasWEHbtm2rlQ4FCBHZKzVp0oTu3bszYcIETjjhBHr16sXMmTNZvHgxPXv2rHDbZs2affU6KyurwraAOLRs2fKr13/84x/Jycnhvffeo6SkhOzs7Mht4kizqphEZK81YMAA7r77bk466SQGDBjAAw88QJ8+fUq1J7Ru3ZrNmzfXWRorO/7GjRvp1KkTjRo14vHHH6e4uLjW0qYAISJ7rQEDBrBmzRqOP/54cnJyyM7OZsCAAaXWad++PSeeeCJHHnkk11xzTY0e/4wzzqBLly506dKFc889N3KdQYMGsWDBAnr37s3kyZN3WX7ZZZfx6KOPctRRR/HBBx+UKl3EzcKAqnsHPVGuYVJeBPUpHxYuXFhpNU5cNFhfStm8iPq/mNk77p4btb1KECIiEkmN1CIiGRgyZAjLli0rNe8Pf/gDp512Wkbbv/jii1x77bWl5nXv3p0pU6bUWBprmgKEiEgGqnsiP+200zIOJvWFqphERCRSbCUIMxsPnAmsdfcjI5ZfA/wwLR09gX0Tz6NeDmwGioGi8hpQREQkPnGWICYAg8tb6O53uXtvd+8NXA+86u7r01YZlFiu4CAiUgdiCxDu/hqwvtIVg/OAiXGlRUREqq7O2yDMrAWhpPHPtNkOvGRm75jZyLpJmYjszerL8yCqqirpq6760Ivpu8DsMtVL/d19tZntB0w3sw8SJZJdJALISICcnBzy8vJiT3B9UFhY2GA+a2WUF0F9yoc2bdrU2fAVxcXFGR07edfyihUrGDt2LOeffz4AW7dupaioKKN9PPbYYwBfDQD4j3/8o1Q6tmzZUuP5UJX0lc2Lbdu2Vek7Uh8CxAjKVC+5++rE37VmNgXoB0QGCHcfB4yDcCd1fbmTNG716a7Zuqa8COpTPixcuLDUHbxRyRo2DC67DLZuhdNP33X5T34Sps8/h7IPTqvoHJe8ezjT50HcfvvtLFu2jAEDBnz1PIht27Zx4YUXZvw8iBYtWtC4ceNSnzkrK4uWLVtWelf3cccdx8MPP8wRRxwBwMCBA7n77rspKSnhyiuvZNu2bTRv3pxHHnmEQw89NPJYleVFUnZ2Nn369Kl0u6Q6rWIyszbAycC/0ua1NLPWydfAqcD8ukmhiOyp9oTnQQAMHz6cJ598EoA1a9awZs0acnNzOeyww5g1axbvvvsuo0eP5oYbbogtDeWJs5vrRGAg0MHMVgG3AE0A3P2BxGpDgJfcfUvapjnAlES0bgz83d1fiCudIhK/iq74W7SoeHmHDhUvL8+e8jyIYcOGceqpp3Lrrbfy5JNPfvWc6Y0bN3LBBRewaNEizIydO3fGcvyKxBYg3P28DNaZQOgOmz5vKXBUPKkSkYZiT3keROfOnWnfvj1z585l8uTJPPBAuH6+6aabGDRoEFOmTGH58uV1Un1Y572YRETisic8DwJCNdOYMWPYuHEjvXr1AkIJonPnzgBMmDChTtKlACEie6094XkQAEOHDmXSpEkMGzbsq3m/+c1vuP766+nTp0+tP9EuSc+D2EPVpx4rdU15EdSnfNDzIOoHPQ9CRERiUR/ugxARqff0PAgRkRri7hXeXLan2dOfB7E7zQmqYhKRGpednc26det266QkNc/dWbduHdnZ2VXaTiUIEalxXbp0YdWqVXz22We1fuxt27ZV+US4t0rPi+zs7K9u/suUAoSI1LjkTWp1IS8vr0rjDe3NqpsXqmISEZFIChAiIhJJAUJERCIpQIiISCQFCBERiaQAISIikRQgREQkkgKEiIhEUoAQEZFIChAiIhIptgBhZuPNbK2ZzS9n+UAz22hmBYnp5rRlg83sQzNbbGbXxZVGEREpX5wliAnA4ErWmeXuvRPTaAAzywLuA74DHA6cZ2aHx5hOERGJEFuAcPfXgPW7sWk/YLG7L3X3HcAk4OwaTZyIiFSqrkdzPd7M3gM+Aa529/eBzsDKtHVWAceWtwMzGwmMBMjJySEvLy++1NYjhYWFDeazVkZ5ESgfAuVDSnXzoi4DxBzgQHcvNLPTgWeAHlXdibuPA8YB5Obmen15aHvc6tMD6uua8iJQPgTKh5Tq5kWd9WJy903uXph4PQ1oYmYdgNVA17RVuyTmiYhILaqzAGFmHS3xwFoz65dIyzrgbaCHmXU3s6bACGBqXaVTRKShiq2KycwmAgOBDma2CrgFaALg7g8AQ4FLzawI+BIY4eEBtkVmNgp4EcgCxifaJkREpBbFFiDc/bxKlo8FxpazbBowLY50iYhIZnQntYiIRFKAEBGRSAoQIiISSQFCREQiKUCIiEgkBQgREYmkACEiIpEUIEREJJIChIiIRFKAEBGRSAoQIiISSQFCREQiKUCIiEgkBQgREYmkACEiIpEUIEREJJIChIiIRFKAEBGRSLEFCDMbb2ZrzWx+Oct/aGZzzWyemb1hZkelLVuemF9gZvlxpVFERMoXZwliAjC4guXLgJPd/RvAbcC4MssHuXtvd8+NKX0iIlKBxnHt2N1fM7NuFSx/I+3tm0CXuNIiIiJVZ+4e385DgHjO3Y+sZL2rgcPc/eLE+2XABsCBB929bOkifduRwEiAnJycvpMmTaqZxNdzhYWFtGrVqq6TUS8oLwLlQ6B8SMkkLwYNGvROeTU1sZUgMmVmg4CLgP5ps/u7+2oz2w+YbmYfuPtrUdsngsc4gNzcXB84cGDcSa4X8vLyaCiftTLKi0D5ECgfUqqbF3Xai8nMegEPAWe7+7rkfHdfnfi7FpgC9KubFIqINFx1FiDM7ADgaeB8d/8obX5LM2udfA2cCkT2hBIRkfjEVsVkZhOBgUAHM1sF3AI0AXD3B4CbgfbA/WYGUJSoB8sBpiTmNQb+7u4vxJVOERGJFmcvpvMqWX4xcHHE/KXAUbtuISIitUl3UouISCQFCBERiaQAISIikRQgREQkkgKEiIhEUoAQEZFIChAiIhJJAUJERCIpQIiISCQFCBERiaQAISIikRQgREQk0l4VIHburOsUiIjsPfaqAPH++zB5cl2nQkRk77BXBYhmzWDECBg2DD7/vK5TIyKyZ8soQJjZlWb2NQseNrM5ZnZq3ImrqpYt4Wc/gylT4Igj4Jln6jpFIiJ7rkxLED91902Ex3+2A84H7owtVbvp88/hwQehY0fYZx8YMgR+/GPYsKGuUyYisufJNEBY4u/pwOPu/n7avHrjqKNgwgQ45hjIz4ebb4YnnoBOneDEE+GOO2Dx4rpOpYjIniHTAPGOmb1ECBAvmllroKSyjcxsvJmtNbP55Sw3M7vXzBab2VwzOzpt2QVmtigxXZBJIrOy4IIL4OmnQ3XTrbfCwIGwfTu88QbccAP06AGtWoWqqKeegrffDstFRKpiwQJYsaKuUxGvTAPERcB1wDHuvhVoAlyYwXYTgMEVLP8O0CMxjQT+AmBm+wC3AMcC/YBbzKxdhmktZcaMUPWUlxdKFP37Q+fOMHEinHsu9OsHzZuHaqnTT4f774eVK3fnSHu24uK6TkH9Nm0aXHut8kmCOXNCTUXfvjA/8vK3alavDn/nzYP33qv+/mpKpgHieOBDd//CzH4E3AhsrGwjd38NWF/BKmcDj3nwJtDWzDoBpwHT3X29u28AplNxoKlQ+/Zw8smhRDFrFnz4IaxbF17/4Adw4IHw2Wfw/PNw+eXwjW/A+eeH0khODnTtCgcdBIcdFpYNHQrPPgsbN8K2bbubqvphzRoYPBh+8Yu6Tkn99eKLcM45MGYM/OEPdZ2a+uuVV+CRR+o6FVVXXAwnnQR3353Z+qtXw3e/G84rHTvCli3VO/6LL4bzy3PPhR6YZ59df3phmrtXvpLZXOAooBehVPAQMMzdT85g227Ac+5+ZMSy54A73f31xPtXgGuBgUC2u9+emH8T8KW77/IvNLORhNIHOTk5fSdNmlTp54lSXGx8+GErZs7cl6VLW7FyZQuKi43NmxvjbrhDSUn427ixU1TUiEaNSigpaUSLFkXsv/+XdO++hc6dv+Tkkz+jW7etFBdDo0ZgMbTWFBYW0qpVq2rtY/bs9owZcxhbt2bxl7/M4ZBDCnGPJ71xqom8KM/8+V/jmmuOonPnLxkw4DO+851P2W+/+lknGWc+VGTr1iweeOBgnn12f849dyWXXbaE7dsb8dhjBzJgwOcceujmWv1O7U4+PProgUyY0J2f/GQZP/7xinLTu2NHI0aN6sOqVc3585/fpVu3LWRlhWVbtmTRsmXVipirVzfn5z8/mv32287YsXNYsaIlV1zRhyOP3MiYMXNp3Ljy83NFMsmLQYMGvePuuZEL3b3SCZiT+HszcFH6vAy27QbML2fZc0D/tPevALnA1cCNafNvAq6u7Fh9+/b1uBUXu2/e7D5jhvvll7t36uQOYTILf3/wA/fp093/9S/35s3dDz/c/Xvfc3/+efeSkppJx8yZM3d72y1b3H/+85DWo492X7gwzF+71r1/f/e33qqZNNaW6uRFRUpK3HNz3Xv0cP/009T84mL3L76I5ZDVElc+VHxM927dwnf/6qvdv/wyzJ89271x4/AdO/BA91//2v2119x37Mh830VF7tu3706aZma03qpV7rfdFv6fRUXuP/lJSO8NN5T/Oy0pcf/f/3V/7rnS8++5J+TDihWZp3PzZvcjjnDfZx/3JUtS8x99NKTjyisz31d5MskLIN/LO3+Xt6DUSvAqcD2wCOhIqJqal+G2FQWIB4Hz0t5/CHQCzgMeLG+98qbaCBBR1q51nzjR/ac/df/611MBA8I//4AD3L/2tfD+G99wX7my+seszsngmWfCD/o3vyn9A1y+3L1795DW2bOrn8Yo27aFH2R195F01VXuo0Z9lPG2W7a4jxjhPnSo+5w5la+/Zk3Il3Tnnut+0knuO3dmfNhaUdsB4pVXwnf6kEOivy/r17s/8oj76ae7N2kS1k3m+UcfuS9YUPpEnP5/Pecc99atw3bHHOM+alS4wMpEJvnw+efhwq1VK/fFi8O84mL3kSNDOq+5Ztdt/vvf8veXnx9+N4cc4r56deVpLCkJF42NGoWLybKuuiqk49lnK99PRWorQHQEfgUMSLw/APhxhttWFCDOAJ4ndJk9DngrMX8fYBnhnot2idf7VHasugoQZW3Y4P7ii+6jR7ufcYZ7+/apgNGkSfjB3HGH+9ixpa9Mq6KqJ4PPPnP/z39S7+fPj15v5cpwxdyqlfurr1a8z6qcIOfNc7/kEvfs7FCquvnmML+kJJS0Fi0KV3Hl2bTJfdIk92HDSv+ob7st5Ovvf195GjZtcj/55BAckwH7ppt2XW/lynCCKO/zPf542Pb66ys/ZlU991wo1Z16qvvWrVXbtjYCREmJ+7p14XVRUbia3rKl8u02bHCfMiV1cZA8EXfp4j5kiPuhh4bPnXTppe6XXeZ+7bXuAwe6t2wZ3iePO2SI+29/Gy7M5s0rfaFTWT5s2uTer597s2ahJqDs57vySvcJE0rP/+tfw3dm7tzy9/vGGyGdPXtWHEySx7njjlDyiLJzp/v//V/lJa5zzgkXqOWplQAR9kEOcGZi2i/DbSYCa4CdwCpCb6ifAz9PLDfgPmAJMA/ITdv2p8DixHRhJserLwGirJKScMX0yCPuF1/sfthhpUsZHTq4n3CC+y9/6f7CC+FkXpnK/vHbt7vn5YXicm5uOCk2a+a+bFnl+/7kk5DGFi1CtYB7+MLOmeN+333uP/pRuFIaNSosKyqquPpg2LDwObOz3S+6KHzOp54Ky1asSOVDo0YheLRp4/7gg2H5hx+GUlnTpmGdnBz3n/0sVSTfudP9W9/61CEEnYquqF54IeTBxInhhDV6dMgj91BSePPNkPc9e4ar12TVW5RLLgnp+X//r/L8zMSKFeHHDuHzDhmSWvb734cT1OefV7yPOALEkiXhe3vVVe6DBoUScYcOlZ8AK7N8efgfDx3qfvDB7t/9rvuYMeWvv3Nnqlpv9epQNZOVlfruNG7s/pe/hOXPP/+qv/Za6RJJ0pdfun/zm2HbZ56pPJ3vvuv+0kth/6edVvlFUV5e+A6fdVbqu5isdkuqSjWbe/hOfvppOPYzz4TvSTIvnn8+nFvKU1sliGHACuBR4LHEFf3QTLatzam+Bogon30Wrh569kzV1aZPOTlh2bBh7n/4Q7jSmT/ffePGsP1LL+X58uXu77wTvsCTJoWT98cfh+VjxoT9ZGWFdoXRo0MJItM2kE8/DUXgNWtCAEgvBeXkhC9pskTyn/+E+V/7Wthm3Dj3hx5KXS3efXe4Woo6wW3fHk7M48e733hjuHK/8spU6WX5cvfhw91/9Sv3WbOiSxkvvzzTL7wwpOHaa3f9jOnbrFoV/XmvvTZs3759CGTJwFGerVvdjzoqnDCrUu8cZcmSEIxbtHC/887SV8PFxe69eqX+lyedFPLjiSdSn+3ee8MV7zXXLPTf/S4E7mnTwvJFi0LAPfLI0DZ2551hWbIU4B5OPB984P7Pf4bvyfDhqZLt738fjt28ebjqvuQS9/vvD1fhdW3bNvf33nP/299Cae7NN8P8MWMKvrogGTTI/dZbw/9z2zb3118PFwmPPlr5/hctChcmjRqF6qhM251eeilcmLmHYNC0aai6Pf308D3u3j18lzNRVBSOffjh7vvvH/4XnTqVrg2oSG0FiPfSSw3AvsB7mWxbm9OeFCDSlZS4L10arhIffDCcUAcP3jVoQPiSPfOM+403zo9cnqyzXLYsrJcMKNV1zz3uf/972G/ZE/CmTeHkcskl7l27ptJSWRVVTZk5c6YXF4eG91tvLb1s9epwgq2sLnfTphCIjzhi1wbI8nz0UShpvfVWOPksWBBKFPfdFxpsv//9VFXe4sUhaOblhSqs4uLSbVF33LFrW0dSSUkovV13nfuxx4YSxu23h2UbNuz6HWjbNlT9uIf//+WXh6rO9P9N8gT5r3+FE2b69t26hSvnZP4tXFhx9V9989xzr/kzz4RST58+qc4j+flheVXaAO+4IwTXpUurlobkb2Tz5hB0R4wI38NmzcL/obz/dZTJk0PV9He+E37TVanara0AMa/M+4wbqWtz2lMDRJSSkvBFnjXL/a67QknisMNSjX1lp6ZNwxV8To77+eeHBsLdtXFjOEn++tfhhPTTn2b+hS4pcX///XBlV1uSP4KSktQPc+nSMB18cGbtKbsrWUqaPr30/6NZs1CvnjzuQw+VXp6dHaZFi6p//M8+CwFo4sR/71KdUdb69SFNyRLChx+GYPbIIyHQbd5cvfTUB2VPiuvXh0BYH4JcUdHudW7Y3Q4R1Q0QjcnMC2b2YqJNAWA4MC3DbWU3mEGXLmHq3z81f9u2MDzI009/xAEHfJ1t2yg1bdgQ7hLPy4PHHgtDjVRmxw549VWYOTPceZ6fH24eato03Cn6t7+FMa0uvTQMV7LffhWn+/DDq/vpd0+y7/qaNZCbC1u3QnY2vPwyHHtsPMdslLjVtE+fkEfdu4cpJye1DMJNl4MGwZIlqalDB9h//+ofv0OHMK1cuY3s7IrXb9cu3BSW9PWvw113VS8N9V27dnDWWXWdiiB5z0RVNc70TF3TyoscZSfg+8A9iWlIptvV5rQ3lSAqU9GVwdtvh55IZqFuvby+5OvWuf/ud6l7ORo3Do3lN94YujAme9F8/HFoXG7UKFyN33JLzVVd1YSyeVFSEno39eiRqippCOriPoj6SPmQUt0SRMYPDHL3f7r7rxLTlHjCldSE3Fx49124+OIwNMTxx8MHH6SWL1kCo0aFIUR++9swfMi//hVKH7Nnw223wTe/GcaogrDeQw+FJ/YNHhyGLDnooDA0wbJlodKkPjGDG2+Ejz6C3r3rOjUie64KCy5mthmI+vkb4O7+tVhSJdXWsiWMGxcGILz4Yjj6aLjpplB9NGVKKLL+4Afwq19Br16Z7fOww+Af/wj7uOEGuOaaMHXpEqotTj45/D300FR1T0lJGFdmzRr45BNYuzYsP+aY3S9uJ82eDX/6E7RpcwBHHAH77lu9/YlIaRUGCHdvXVsJkXicc04YsfbCC8NJvW1buO66UILY3frv3Fx46aUwiuWrr8Jrr4W2i7//PSzfd98wAOKnn4apqGjXfbRrB6eeGkokp50WntmRqRUrwsiqkyeHz/PFFwfxxBPwwx/ClVdmHvBEpGJ11fQhtWj//cNIte+8Az17hudh1IQjjwzT5ZeHaqbFi0OwePVV+O9/w2Nf998/nPyTfzt0gIICeOGFME2eHPZ11FEhUAwYACecEJ4IWFZhIdx5Z6jaatQIbrkllGCeeuot3nyzH489BuPHh4b5K68MI25u3hyqwZYuDVPydfv28O1vwymnhBKQiOxKAaKBaNQoVOvExSw8jKlHD7jooorX/frXw7DG7jB3bipY/PGPYUhtCD2h+vcPTwI88cQwNPsNN4Sqqh/+MDwdsGvXsO6BB27lggvgd78LbSVjx4bHzTZrtuvDoPbZB7p1C0EqWeI59NAQKE45JQSXpk1DMNqypfTUtm0IZHGNTLptW6iG++9/w+dv0yae44hkSgFC6oxZOOEedVSoMtq6NXThff310L4weXJoR0k69tjwtMDjjove3z77wG9+E9pVnnkmBJWuXUO304MOCn/btg3ruoeHs7z8MkyfHkoeY8dWnua+fUP13IgRVNqldPPm0F6zcWMIOMmgk3y9fn14tsAnn4S/69OenNK8OQwfDpdcEjoZ7G5Q2rw5PPmsY0c44IA9byh3qVsKEFJvtGgRGrpPPjm8LykJPadmzw7tGkOGlL63oDyNG4eHOg0dWv46ZqGtolevEFC2b4d//zs8mtYsVMO1bJmaWrWChQvhvvtCe87VV4eT96WXhhMvhHtH8vND+8z06WF/Ue0vEAJA27bh6YYHHZR60uH++4dAN21aKOFMmBCq6i6+ODzEqn378j9TYWFjZswITzubMydUKS5alOpl1rp12NeRR4aea0ceGToe7LsvNGlSeb5Kw5PRA4P2FLm5uZ6fn1/XyagVeXl5DMzkLrgGoDbzwj3chPjnP4euwRBuwmrUKDTUf/FFmHf00akqq5ycEGCSU4sWmfXgKixMlaLeeitUmZ1yStg2WQrZvLl0iSSpa9dQ2jn66BAM1q4NJab588PfdetKH6tNm9QNd8mpZcvwuZJTVlbqAVhbtqSOvXlz6nWzZqDW2eQAAA9DSURBVKHE079/KujVNv02UjLJCzMr94FBKkGIVIFZuCN60CD4+GN44IHQ7pGdDd/7XjiBf+tbNdPltlWr0J5z0UWhreavfw2lk+zssKxNm9DAngw827cvZejQgzj66IqP7x7aOebPDyWMzz8vPa1ZE4735ZehFFdSEkpHydclJalSVevWYWrVKnRC2LQpPHY0WV3XrVvoeHDiiaFklAxm6dOOHaFkc8wxobqxoqq7HTvCI4M/+CCUwrp1Cz3mWlejv2VRUbg3qGnTUEJr3br8qrji4vB44mQPva5dQ9r3VgoQIrvpgAPg978PjeMQb/1+r16h1FKRvLyPGTjwoEr3ZRbaJDp2DD25atrOnfDee6Et6fXXQ1B7/PFd18vKSp2MN2wI8xo3DiWeY44J3anbtg1tKPPnh+rGRYvK7zZ94IFhatToEP7979Rn7NQp/N133xCQ5s4N6SsoCNP8+aU7MzRuHIJZ+/Zhat48lMA+/TQEh5KS0sfu2TN0ujj33L0vWChAiFSTGn5La9IknNxzc+Gqq0KJZenSUCJJlnZatw5X7GZh+apVof3m7bfD33/8I9VBwQwOPjicfL/3vfC3Z8+wv48/DvfFJKclS2DZso5MiRjroVGj0if3Dh3Cnfa/+EVojykpCVVvZadNm0Lg6dcvFXQ6dgxjks2dG9I6enQYYeDww0OgGDo0vM6kzawiySrN554LHSPi7IkYRQFCRGKVPMFXtLxr1zANGRLmuYeT/ebNoRtyixbR2x5//K7z8vJe59hjB35VDZSc1qwJ1Ve9e4epU6fqB/f+/eGyy8L+n366dLBo1iz0nDvkkNSUDHTJLtrlcQ8lr9tuC500AO65JwTI228PAbI2KECISL1jFk6ou6t589TIurWhY8cQKJLBYtq00FayeHGYZswI3biTDjkkVO99+9uhPSt5Y6g7PPtsCAJvvx0CydixoQrr/vvhf/83dOG+4AL4n/9J9aCLiwKEiEgN6tgRfvrT0vPcQ+BYsiR0P37llTA8/AMPhGDYt28Yx+zll0O11UEHhU4JP/5xqIqDMHLAZZeFm0Tvvz8Mw5/JEPzVUc0asoqZ2WAz+9DMFpvZdRHL/2hmBYnpIzP7Im1ZcdqyqXGmU0QkTmahSqt//zAMzNSpoVvy7NmhJNC8Odx7b7ib/tFHQ+nj4otTwSFp331DVdOiReG+mD//OTyLZMeOeNIdWwnCzLKA+4BTgFXA22Y21d0XJNdx91+mrf8LoE/aLr50dw3WLCJ7pSZNwrhjJ5wAN98celI1aZJZw3ZyCP5rrgm9sMoGkpoSZxVTP2Cxuy8FMLNJwNnAgnLWPw+4Jcb0iIjUW82aVX2bQw8NU1ziDBCdgZVp71cBkQ9+NLMDge7AjLTZ2WaWDxQBd7r7M+VsOxIYCZCTk0NeXl71U74HKCwsbDCftTLKi0D5ECgfUqqbF/WlkXoE8JS7F6fNO9DdV5vZQcAMM5vn7kvKbuju44BxEIbaaCi32Gs4gRTlRaB8CJQPKdXNizgbqVcD6b19uyTmRRkBTEyf4e6rE3+XAnmUbp8QEZGYxRkg3gZ6mFl3M2tKCAK79EYys8OAdsC/0+a1M7NmidcdgBMpv+1CRERiEFsVk7sXmdko4EUgCxjv7u+b2Wgg392TwWIEMMlLDyvbE3jQzEoIQezO9N5PIiISv1jbINx9GjCtzLyby7z/n4jt3gC+EWfaRESkYrHeKCciInsuBQgREYmkACEiIpEUIEREJJIChIiIRFKAEBGRSAoQIiISSQFCREQiKUCIiEgkBQgREYmkACEiIpEUIEREJJIChIiIRFKAEBGRSAoQIiISSQFCREQiKUCIiEgkBQgREYkUa4Aws8Fm9qGZLTaz6yKW/8TMPjOzgsR0cdqyC8xsUWK6IM50iojIrmJ7JrWZZQH3AacAq4C3zWyquy8os+pkdx9VZtt9gFuAXMCBdxLbbogrvSIiUlqcJYh+wGJ3X+ruO4BJwNkZbnsaMN3d1yeCwnRgcEzpFBGRCLGVIIDOwMq096uAYyPW+76ZnQR8BPzS3VeWs23nqIOY2UhgJEBOTg55eXnVT/keoLCwsMF81sooLwLlQ6B8SKluXsQZIDLxLDDR3beb2c+AR4FvVmUH7j4OGAeQm5vrAwcOrPFE1kd5eXk0lM9aGeVFoHwIlA8p1c2LOKuYVgNd0953Scz7iruvc/ftibcPAX0z3VZEROIVZ4B4G+hhZt3NrCkwApiavoKZdUp7exawMPH6ReBUM2tnZu2AUxPzRESklsRWxeTuRWY2inBizwLGu/v7ZjYayHf3qcAVZnYWUASsB36S2Ha9md1GCDIAo919fVxpFRGRXcXaBuHu04BpZebdnPb6euD6crYdD4yPM30iIlI+3UktIiKRFCBERCSSAoSIiERSgBARkUgKECIiEkkBQkREIilAiIhIJAUIERGJpAAhIiKRFCBERCSSAoSIiERSgBARkUgKECIiEkkBQkREIilAiIhIJAUIERGJpAAhIiKRFCBERCRSrAHCzAab2YdmttjMrotY/iszW2Bmc83sFTM7MG1ZsZkVJKapcaZTRER2Fdszqc0sC7gPOAVYBbxtZlPdfUHaau8Cue6+1cwuBcYAwxPLvnT33nGlT0REKhZnCaIfsNjdl7r7DmAScHb6Cu4+0923Jt6+CXSJMT0iIlIFcQaIzsDKtPerEvPKcxHwfNr7bDPLN7M3zeycOBIoIiLli62KqSrM7EdALnBy2uwD3X21mR0EzDCzee6+JGLbkcBIgJycHPLy8mojyXWusLCwwXzWyigvAuVDoHxIqW5exBkgVgNd0953Scwrxcy+DfwWONndtyfnu/vqxN+lZpYH9AF2CRDuPg4YB5Cbm+sDBw6suU9Qj+Xl5dFQPmtllBeB8iFQPqRUNy/irGJ6G+hhZt3NrCkwAijVG8nM+gAPAme5+9q0+e3MrFnidQfgRCC9cVtERGIWWwnC3YvMbBTwIpAFjHf3981sNJDv7lOBu4BWwD/MDOBjdz8L6Ak8aGYlhCB2Z5neTyIiErNY2yDcfRowrcy8m9Nef7uc7d4AvhFn2kREpGK6k1pERCIpQIiISCQFCBERiaQAISIikRQgREQkkgKEiIhEUoAQEZFIChAiIhJJAUJERCIpQIiISCQFCBERiaQAISIikRQgREQkkgKEiIhEUoAQEZFIChAiIhJJAUJERCIpQIiISCQFCBERiRRrgDCzwWb2oZktNrPrIpY3M7PJieX/MbNuacuuT8z/0MxOizOdIiKyq9gChJllAfcB3wEOB84zs8PLrHYRsMHdDwH+CPwhse3hwAjgCGAwcH9ifyIiUkviLEH0Axa7+1J33wFMAs4us87ZwKOJ108B3zIzS8yf5O7b3X0ZsDixPxERqSWNY9x3Z2Bl2vtVwLHlrePuRWa2EWifmP9mmW07Rx3EzEYCIxNvC83sw+onfY/QAfi8rhNRTygvAuVDoHxIySQvDixvQZwBola4+zhgXF2no7aZWb6759Z1OuoD5UWgfAiUDynVzYs4q5hWA13T3ndJzItcx8waA22AdRluKyIiMYozQLwN9DCz7mbWlNDoPLXMOlOBCxKvhwIz3N0T80ckejl1B3oAb8WYVhERKSO2KqZEm8Io4EUgCxjv7u+b2Wgg392nAg8Dj5vZYmA9IYiQWO9JYAFQBFzu7sVxpXUP1eCq1SqgvAiUD4HyIaVaeWHhgl1ERKQ03UktIiKRFCBERCSSAsQewMzGm9laM5ufNm8fM5tuZosSf9vVZRprg5l1NbOZZrbAzN43sysT8xtiXmSb2Vtm9l4iL25NzO+eGLZmcWIYm6Z1ndbaYGZZZvaumT2XeN/g8sHMlpvZPDMrMLP8xLxq/TYUIPYMEwhDjqS7DnjF3XsAryTe7+2KgF+7++HAccDliWFZGmJebAe+6e5HAb2BwWZ2HGG4mj8mhq/ZQBjOpiG4EliY9r6h5sMgd++ddu9DtX4bChB7AHd/jdDLK136MCWPAufUaqLqgLuvcfc5idebCSeEzjTMvHB3L0y8bZKYHPgmYdgaaCB5YWZdgDOAhxLvjQaYD+Wo1m9DAWLPlePuaxKvPwVy6jIxtS0x8m8f4D800LxIVKsUAGuB6cAS4At3L0qsUu4QNXuZPwG/AUoS79vTMPPBgZfM7J3EEERQzd/GHj/UhoSrSTNrMP2VzawV8E/gKnffFC4Yg4aUF4l7g3qbWVtgCnBYHSep1pnZmcBad3/HzAbWdXrqWH93X21m+wHTzeyD9IW789tQCWLP9V8z6wSQ+Lu2jtNTK8ysCSE4/M3dn07MbpB5keTuXwAzgeOBtolha6BhDFFzInCWmS0njBj9TeD/aHj5gLuvTvxdS7hg6Ec1fxsKEHuu9GFKLgD+VYdpqRWJuuWHgYXufk/aooaYF/smSg6YWXPgFEKbzEzCsDXQAPLC3a939y7u3o0wEsMMd/8hDSwfzKylmbVOvgZOBeZTzd+G7qTeA5jZRGAgYeje/wK3AM8ATwIHACuAYe5etiF7r2Jm/YFZwDxS9c03ENohGlpe9CI0OmYRLvSedPfRZnYQ4Up6H+Bd4Efuvr3uUlp7ElVMV7v7mQ0tHxKfd0ribWPg7+7+OzNrTzV+GwoQIiISSVVMIiISSQFCREQiKUCIiEgkBQgREYmkACEiIpEUIESqwMyKE6NlJqcaGxjQzLqlj9grUtc01IZI1Xzp7r3rOhEitUElCJEakBiLf0xiPP63zOyQxPxuZjbDzOaa2StmdkBifo6ZTUk8z+E9MzshsassM/tr4hkPLyXukhapEwoQIlXTvEwV0/C0ZRvd/RvAWMIIowB/Bh51917A34B7E/PvBV5NPM/haOD9xPwewH3ufgTwBfD9mD+PSLl0J7VIFZhZobu3ipi/nPAAn6WJAQU/dff2ZvY50Mnddybmr3H3Dmb2GdAlffiHxBDm0xMPd8HMrgWauPvt8X8ykV2pBCFSc7yc11WRPl5QMWonlDqkACFSc4an/f134vUbhFFGAX5IGGwQwuMfL4WvHvzTprYSKZIpXZ2IVE3zxFPckl5w92RX13ZmNpdQCjgvMe8XwCNmdg3wGXBhYv6VwDgzu4hQUrgUWINIPaI2CJEakGiDyHX3z+s6LSI1RVVMIiISSSUIERGJpBKEiIhEUoAQEZFIChAiIhJJAUJERCIpQIiISKT/D1jZNIOfXMZbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc5615ZNG_ih"
      },
      "source": [
        "Y_pred = model2.predict_classes(X_test)"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnmM3LbiHgiW",
        "outputId": "c66c1530-eebe-447a-c9c3-f54827c69930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_HC_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6245059288537549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23Vl8jp3LtE"
      },
      "source": [
        "# **2. modelling for tweets related to Target : Legalization of Abortion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cd5swpWlmun"
      },
      "source": [
        "First we check the preprocessed tweet data for target Legalization of Abortion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4tvC3aA3YxA",
        "outputId": "5cd3a14d-fb12-4dab-d8b4-b43c2175a833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_AB[:1]"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['laid',\n",
              "  'law',\n",
              "  'abortion',\n",
              "  'bioethics',\n",
              "  'class',\n",
              "  '#catholic',\n",
              "  'legalization',\n",
              "  'abortion']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZrhJeDOl10M"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbKeC8g63k2C",
        "outputId": "1c81881f-16d8-41ef-90bf-c686cc0d6f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_AB)\n",
        "Y = pd.get_dummies(traindata_AB['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2771 unique tokens.\n",
            "Shape of data tensor: (653, 40)\n",
            "Shape of label tensor: (653, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh6dZVAQl8mY"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA497Brc3kjS",
        "outputId": "263f7809-47c0-47ca-be8f-9f3974a03ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (522, 40)\n",
            "Y train shape:  (522, 3)\n",
            "X Val shape:  (131, 40)\n",
            "Y Val shape:  (131, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzGMRiWo3xyD"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnpgWy0b3kYv",
        "outputId": "a2bad779-d45f-499a-c84c-2098d8ef4d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model2 = create_model(embedding_layer)\n",
        "print(model2.summary())"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 40, 100)           277200    \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 296,531\n",
            "Trainable params: 296,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TmwyBrOmEAk"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 20 epochs in each of the 3 folds.\n",
        "The batch size is set to 32 and we trained the data for 20 epochs and 3 folds.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DApipPKH39Ve",
        "outputId": "2fd7ab54-ceae-4d47-f4a7-5cd98c22c486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model2.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 4s - loss: 1.2094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0700s vs `on_train_batch_end` time: 0.5998s). Check your callbacks.\n",
            "14/14 [==============================] - 2s 129ms/step - loss: 1.1508 - val_loss: 1.1187\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0825 - val_loss: 1.1028\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0655 - val_loss: 1.0901\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0372 - val_loss: 1.0880\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0514 - val_loss: 1.0705\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0360 - val_loss: 1.0636\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0254 - val_loss: 1.0664\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 1.0269 - val_loss: 1.0534\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0078 - val_loss: 1.0530\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0079 - val_loss: 1.0501\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0149 - val_loss: 1.0448\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0011 - val_loss: 1.0439\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.9331 - val_loss: 0.9358\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.6174 - val_loss: 1.2761\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5219 - val_loss: 1.3121\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.5100 - val_loss: 1.8540\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4111 - val_loss: 1.9687\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.4104 - val_loss: 2.1129\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4025 - val_loss: 2.1333\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4017 - val_loss: 2.1094\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 1s - loss: 0.9091WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0629s vs `on_train_batch_end` time: 0.1158s). Check your callbacks.\n",
            "14/14 [==============================] - 1s 71ms/step - loss: 1.0663 - val_loss: 0.4436\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.8237 - val_loss: 0.5367\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.7260 - val_loss: 0.4541\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.6254 - val_loss: 0.4306\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5777 - val_loss: 0.4167\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.5394 - val_loss: 0.4373\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.5049 - val_loss: 0.4353\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.5030 - val_loss: 0.4915\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4930 - val_loss: 0.4696\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4538 - val_loss: 0.4452\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.4623 - val_loss: 0.4506\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4122 - val_loss: 0.4534\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4163 - val_loss: 0.4573\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.4302 - val_loss: 0.4566\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.3988 - val_loss: 0.4605\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.3859 - val_loss: 0.4451\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4158 - val_loss: 0.4478\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.6604 - val_loss: 0.6717\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4347 - val_loss: 0.5140\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.3890 - val_loss: 0.5021\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "14/14 [==============================] - 1s 67ms/step - loss: 0.4581 - val_loss: 0.3705\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4367 - val_loss: 0.3468\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4147 - val_loss: 0.3571\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.3871 - val_loss: 0.3531\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4159 - val_loss: 0.3472\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4019 - val_loss: 0.3446\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.3982 - val_loss: 0.3420\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4110 - val_loss: 0.3386\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.3953 - val_loss: 0.3377\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.3553 - val_loss: 0.3363\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.3953 - val_loss: 0.3346\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.3769 - val_loss: 0.3341\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3807 - val_loss: 0.3333\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3677 - val_loss: 0.3323\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.3464 - val_loss: 0.3326\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3465 - val_loss: 0.3302\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.3913 - val_loss: 0.3300\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.3652 - val_loss: 0.3296\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3378 - val_loss: 0.3296\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3687 - val_loss: 0.3290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlqOvEeFmOlu"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQIaLyUN4Jbv",
        "outputId": "903f8405-8616-4606-e497-fae894d8e9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQp1LcfjOk6T",
        "outputId": "ba268d07-d476-4d12-f87c-08c6ec5ab699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_AB)\n",
        "Y_true = pd.get_dummies(testdata_AB['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1526 unique tokens.\n",
            "Shape of data tensor: (280, 40)\n",
            "Shape of label tensor: (280, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6oSdgMOk6e",
        "outputId": "1a4790cb-8df9-4df9-b0c2-25600a58e084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AB_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.544041450777202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi5ybAhb4UZ0"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqjWN2H4YRJ",
        "outputId": "d08330f7-104d-43ce-d240-687b2eca9c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iwgP9hW4eQk",
        "outputId": "27a273e2-eada-4457-8422-2d3d8e21f724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model2 = create_model(embedding_layer_TL)\n",
        "print(model2.summary())"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 40, 100)           277200    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 296,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 277,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nRejvf4ewR",
        "outputId": "342508ec-045e-46f5-ba9c-5dda8b1c7c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model2.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/17 [==>...........................] - ETA: 4s - loss: 1.2078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0574s vs `on_train_batch_end` time: 0.4753s). Check your callbacks.\n",
            "17/17 [==============================] - 2s 98ms/step - loss: 1.1817 - val_loss: 1.1335\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 1.1147 - val_loss: 1.0243\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 1.0634 - val_loss: 1.0015\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0563 - val_loss: 1.0061\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0389 - val_loss: 0.9713\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 1.0082 - val_loss: 0.9358\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9708 - val_loss: 0.8833\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9507 - val_loss: 0.9068\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.9319 - val_loss: 0.9146\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9365 - val_loss: 0.8806\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9554 - val_loss: 0.8922\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9238 - val_loss: 0.8890\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8977 - val_loss: 0.8858\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9485 - val_loss: 0.8763\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8998 - val_loss: 0.8777\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9307 - val_loss: 0.8966\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8997 - val_loss: 0.8890\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8853 - val_loss: 0.8811\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8957 - val_loss: 0.8639\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8899 - val_loss: 0.9212\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.8920 - val_loss: 0.8775\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8769 - val_loss: 0.9128\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.8831 - val_loss: 0.8710\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 1s 59ms/step - loss: 0.8721 - val_loss: 0.8837\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 1s 60ms/step - loss: 0.8773 - val_loss: 0.9030\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 1s 61ms/step - loss: 0.9001 - val_loss: 0.8741\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.8719 - val_loss: 0.8601\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 1s 81ms/step - loss: 0.8702 - val_loss: 0.8809\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 1s 61ms/step - loss: 0.8671 - val_loss: 0.9139\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8847 - val_loss: 0.8513\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8738 - val_loss: 0.8521\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8311 - val_loss: 0.8882\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8422 - val_loss: 0.8776\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8822 - val_loss: 0.9064\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8438 - val_loss: 0.8669\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8574 - val_loss: 0.8616\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.8245 - val_loss: 0.8579\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8489 - val_loss: 0.8644\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8421 - val_loss: 0.8683\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8262 - val_loss: 0.9090\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.8284 - val_loss: 0.8816\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 1s 45ms/step - loss: 0.7984 - val_loss: 0.8467\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8176 - val_loss: 0.8558\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.7661 - val_loss: 0.8936\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.7901 - val_loss: 0.8593\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8003 - val_loss: 0.8837\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.7691 - val_loss: 0.8412\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.7851 - val_loss: 0.8631\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8372 - val_loss: 0.8643\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8019 - val_loss: 0.8342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeXWGsD64eFY",
        "outputId": "74b349d7-afcb-4432-c2cb-20b42dfc4c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5dX38e9iRqCAoBFBBQuXOINEtCoKpQIOhfpWcWgttlp8bFGrVetYK9pHBeustaiI0yPYVixV6kwciwoSUUFlVEEEBQSCgJCs9491Qg5hJzkxOUkgv8917Svn7PE+d5Kz9j1uc3dERERKa1DbCRARkbpJAUJERBIpQIiISCIFCBERSaQAISIiiRQgREQkUdYChJntZmZTzGyWmX1gZucn7GNmdruZzTWzmWZ2UNq2YWY2J7UMy1Y6RUQkmWVrHISZdQA6uPs7ZtYKmA78xN1npe1zLHAucCxwCHCbux9iZjsC04BcwFPH9nL3lVlJrIiIbCVrJQh3X+Lu76RerwFmAx1L7TYEeMjDVKBNKrAMBJ539xWpoPA8MChbaRURka01qomLmFlnoCfwZqlNHYHP0t4vSq0ra33SuYcDwwGaN2/ea7fddquWNNd1RUVFNGigJiRQXhRTPgTlQ4lM8uLjjz/+yt13StqW9QBhZi2BfwK/c/fV1X1+dx8DjAHIzc31adOmVfcl6qS8vDz69u1b28moE5QXQfkQlA8lMskLM/ukrG1ZDbNm1pgIDo+6+xMJuywG0m/5O6XWlbVeRERqSDZ7MRlwPzDb3W8uY7dJwC9SvZkOBVa5+xLgWWCAmbU1s7bAgNQ6ERGpIdmsYjocOB14z8zyU+suB3YHcPd7gMlED6a5wDfAL1PbVpjZtcDbqeNGuvuKLKZVRERKyVqAcPfXAKtgHwd+W8a2scDYLCRNRLJs48aNLFq0iPXr19f4tVu3bs3s2bNr/Lp1UXpeNGvWjE6dOtG4ceOMj6+RXkwiUr8sWrSIVq1a0blzZ6K2ueasWbOGVq1a1eg166rivHB3li9fzqJFi+jSpUvGx6svmIhUu/Xr19OuXbsaDw6SzMxo165dpUt0ChAikhUKDnXLd/l9KECIiEgiBQgREUmkACEi9dKxxx7L119/zddff83dd9+9eX1eXh7HH398Ruc44YQT6NGjB127dqV169b06NGDHj168MYbb9C3b18ymdkhPz+fyZMnVzr9n3/+OSeeeGKlj6sMBQgRqZcmT55MmzZttgoQlTFx4kTy8/O577776NOnD/n5+eTn53PYYYdlfI7yAsSmTZvKPG7XXXflH//4R6XTXBnq5ioiWfW730F+fsX7VUaPHnDrreXvM3r0aJo2bcp5553HBRdcwLvvvstLL73ESy+9xP3338/rr7/OtGnTuPTSS5k3bx49evTg6KOP5rjjjqOgoIATTzyR999/n169evHII49kpdH922+/5Y9//CPr1q3jtdde47LLLmP27NnMmzeP+fPns/vuu3P99ddz+umns3btWgDuvPNODjvsMBYuXMjxxx/P+++/z7hx45g0aRLffPMN8+bN44QTTmDUqFFVTp9KECKyXerTpw+vvvoqANOmTaOgoICNGzfy6quvcuSRR27e74YbbuD73/8++fn5jB49GoAZM2Zw6623MmvWLObPn8/rr7+elTQ2adKEkSNHcvLJJ5Ofn8/JJ58MwKxZs3jhhRd47LHH2HnnnXn++ed55513mDBhAuedd17iufLz85kwYQLvvfceEyZM4LPPPkvcrzJUghCRrKroTj9bevXqxfTp01m9ejVNmzbloIMOYtq0abz66qvcfvvtXH/99WUe27t3bzp16gRAjx49WLhwIUcccURNJZ3BgwfTvHlzIEaljxgxgvz8fBo2bMjHH3+ceEz//v1p3bo1APvssw+ffPIJbdq0qVI6FCBEZLvUuHFjunTpwrhx4zjssMM44IADmDJlCnPnzmXvvfcu99imTZtuft2wYcNy2wKyoUWLFptf33LLLeTk5PDuu+9SVFREs2bNEo/JRppVxSQi260+ffpw0003ceSRR9KnTx/uueceevbsuUV7QqtWrVizZk2tpbGi669atYoOHTrQoEEDHn74YQoLC2ssbQoQIrLd6tOnD0uWLOEHP/gBOTk5NGvWjD59+myxT7t27Tj88MPZb7/9uPjii6v1+scddxydOnWiU6dOnHTSSYn79OvXj1mzZtGjRw8mTJiw1fbf/OY3PPjggxx44IF8+OGHW5Quss1iQtXtg54oVz8pL0JdyofZs2dXWI2TLZqsr0TpvEj6vZjZdHfPTTpeJQgREUmkRmoRkQyccMIJLFiwYIt1N954IwMHDszo+GeffZY//OEPW6zr0qULEydOrLY0VjcFCBGRDFT1i3zgwIEZB5O6QlVMIiKSKGslCDMbCxwPLHP3/RK2Xwz8LC0dewM7pZ5HvRBYAxQCm8pqQBERkezJZgliHDCorI3uPtrde7h7D+Ay4GV3X5G2S7/UdgUHEZFakLUA4e6vACsq3DGcCjyWrbSIiEjl1XobhJntQJQ0/pm22oHnzGy6mQ2vnZSJyPasrjwPorIqk76qqgu9mH4MvF6qeukId19sZjsDz5vZh6kSyVZSAWQ4QE5ODnl5eVlPcF1QUFBQbz5rRZQXoS7lQ+vWrWtt+orCwsKMrl08avmTTz7hzjvv5PTTTwfgm2++YdOmTRmd46GHHgLYPAHg3//+9y3SsXbt2mrPh8qkr3RerF+/vlJ/I3UhQJxCqeold1+c+rnMzCYCvYHEAOHuY4AxECOp68pI0myrS6Nma5vyItSlfJg9e/YWI3iTkjV0KPzmN/DNN3DssVtvP+OMWL76Cko/OK2877ji0cOZPg/iuuuuY8GCBfTp02fz8yDWr1/PL3/5y4yfB7HDDjvQqFGjLT5zw4YNadGiRYWjug899FDuv/9+9t13XwD69u3LTTfdRFFREeeffz7r16+nefPmPPDAA+y1116J16ooL4o1a9aMnj17VnhcsVqtYjKz1sBRwL/S1rUws1bFr4EBwPu1k0IR2VZtC8+DADj55JN5/PHHAViyZAlLliwhNzeX7t278+qrrzJjxgxGjhzJ5ZdfnrU0lCWb3VwfA/oC7c1sEXA10BjA3e9J7XYC8Jy7r007NAeYmIrWjYD/c/dnspVOEcm+8u74d9ih/O3t25e/vSzbyvMghg4dyoABA7jmmmt4/PHHNz9netWqVQwbNow5c+ZgZmzcuDEr1y9P1gKEu5+awT7jiO6w6evmAwdmJ1UiUl9sK8+D6NixI+3atWPmzJlMmDCBe+6J++errrqKfv36MXHiRBYuXFgr1Ye13otJRCRbtoXnQUBUM40aNYpVq1ZxwAEHAFGC6NixIwDjxo2rlXQpQIjIdmtbeB4EwIknnsj48eMZOnTo5nWXXHIJl112GT179qzxJ9oV0/MgtlF1qcdKbVNehLqUD3oeRN2g50GIiEhW1IVxECIidZ6eByEiUk3cvdzBZduabf15EN+lOUFVTCJS7Zo1a8by5cu/05eSVD93Z/ny5TRr1qxSx6kEISLVrlOnTixatIgvv/yyxq+9fv36Sn8Rbq/S86JZs2abB/9lSgFCRKpd8SC12pCXl1ep+Ya2Z1XNC1UxiYhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJlLUAYWZjzWyZmb1fxva+ZrbKzPJTyx/Ttg0ys4/MbK6ZXZqtNIqISNmyWYIYBwyqYJ9X3b1HahkJYGYNgbuAY4B9gFPNbJ8splNERBJkLUC4+yvAiu9waG9grrvPd/dvgfHAkGpNnIiIVKi2Z3P9gZm9C3wOXOTuHwAdgc/S9lkEHFLWCcxsODAcICcnh7y8vOyltg4pKCioN5+1IsqLoHwIyocSVc2L2gwQ7wB7uHuBmR0LPAl0q+xJ3H0MMAYgNzfX68pD27OtLj2gvrYpL4LyISgfSlQ1L2qtF5O7r3b3gtTryUBjM2sPLAZ2S9u1U2qdiIjUoFoLEGa2i6UeWGtmvVNpWQ68DXQzsy5m1gQ4BZhUW+kUEamvslbFZGaPAX2B9ma2CLgaaAzg7vcAJwLnmNkmYB1wiscDbDeZ2QjgWaAhMDbVNiEiIjUoawHC3U+tYPudwJ1lbJsMTM5GukREJDMaSS0iIokUIEREJJEChIiIJFKAEBGRRAoQIiKSSAFCREQSKUCIiEgiBQgREUmkACEiIokUIEREJJEChIiIJFKAEBGRRAoQIiKSSAFCREQSKUCIiEgiBQgREUmkACEiIokUIEREJFHWAoSZjTWzZWb2fhnbf2ZmM83sPTN7w8wOTNu2MLU+38ymZSuNIiJStmyWIMYBg8rZvgA4yt33B64FxpTa3s/de7h7bpbSJyIi5WiUrRO7+ytm1rmc7W+kvZ0KdMpWWkREpPLM3bN38ggQT7n7fhXsdxHQ3d3PSr1fAKwEHPibu5cuXaQfOxwYDpCTk9Nr/Pjx1ZP4Oq6goICWLVvWdjLqBOVFUD4E5UOJTPKiX79+08uqqclaCSJTZtYPOBM4Im31Ee6+2Mx2Bp43sw/d/ZWk41PBYwxAbm6u9+3bN9tJrhPy8vKoL5+1IsqLoHwIyocSVc2LWu3FZGYHAPcBQ9x9efF6d1+c+rkMmAj0rp0UiojUX7UWIMxsd+AJ4HR3/zhtfQsza1X8GhgAJPaEEhGR7MlaFZOZPQb0Bdqb2SLgaqAxgLvfA/wRaAfcbWYAm1L1YDnAxNS6RsD/ufsz2UqniIgky2YvplMr2H4WcFbC+vnAgVsfISIiNUkjqUVEJJEChIiIJFKAEBGRRAoQIiKSSAFCREQSKUCIiEgiBQgREUmkACEiIom2qwDxySewcWNtp0JEZPuwXQWIr76CQYNgxYraTomIyLZvuwoQnTvDa6/BoYfCxx9XuLuIiJRjuwoQ7drBiy/CypURJF56qbZTJCKy7dquAgTAEUfAm29Chw4wcCDce29tp0hEZNtU60+Uy4Y994Q33oBTToHhw+GVV6JEsfvuJUubNhAziouISJLtMkAAtG4N//43XHIJ3H03PPLIlttbtoxA0atXNGwPGADt29dOWkVE6qKMAoSZnQ88AKwhHhHaE7jU3Z/LYtqqrFEjuPlmuOkm+PJL+PTTLZcFC2DyZHj44ShN9O4NxxwTS24uNNjuKuBERDKXaQniV+5+m5kNBNoCpwMPA3U6QBRr0ABycmI5+OAttxUWwrRp8J//xHLNNfCnP8HOO8P558O550KrVrWSbBGRWpXpPXJxbf2xwMPu/kHaujqjqKjyxzRsCIccEkHhzTdh2TJ49NEoQVxxRXSdvf56WLOmulMrIlK3ZRogppvZc0SAeNbMWgEVfh2b2VgzW2Zm75ex3czsdjOba2YzzeygtG3DzGxOahmW0YdpAAUF8NxzUTL4Ltq3h9NOg6efhrfeisbtyy+HLl3gxhvj/CIi9UGmAeJM4FLgYHf/BmgM/DKD48YBg8rZfgzQLbUMB/4KYGY7AlcDhwC9gavNrG0mCX3iiejeusce8cX+0Udbbl+5EmbPjgF1//43LF5c9rkOPjgCxdSp8frSSyNQ3HyzpvQQke1fpgHiB8BH7v61mf0cuBJYVdFB7v4KUN7EF0OAhzxMBdqYWQdgIPC8u69w95XA85QfaDYbOhQefxwOPDDu+Lt3j6XYb38L++wDffrA4MHQrRuMHAnuZZ/zkEOifeKNN6BnT/j97+GggyLIiIhsr8zL+2Ys3slsJnAgcABRKrgPGOruR2VwbGfgKXffL2HbU8AN7v5a6v2LwB+AvkAzd78utf4qYJ2735RwjuFE6YOcnJxe48eP37xt+fImvPBCDnPntuSyy2bToAHk57dm+fKmfO97G2nWrIiJEzuyww6buOiimJvDveLxEa+/3o477ujG0qXNGDRoCWefPZ82bWq2SFFQUEDLli1r9Jp1lfIiKB+C8qFEJnnRr1+/6e6em7jR3StcgHdSP/8InJm+LoNjOwPvl7HtKeCItPcvArnARcCVaeuvAi6q6Fq9evXy72LTplQRZqp7797ur71W8TEFBe5/+IN7o0buO+7oPmaMe2Hhd7r8dzJlypSau1gdp7wIyoegfCiRSV4A07yM79RMq5jWmNllRPfWp82sAdEOUVWLgd3S3ndKrStrfVY0bBg/v/462iSOOAJOPjmmDy9LixZwww2Qnw/77Rcjto84IsZVfPtttlIqIlJzMg0QJwMbiPEQXxBf2KOr4fqTgF+kejMdCqxy9yXAs8AAM2ubapwekFqXVQMHRqP21VdHA3b37jBqVPnH7Lsv5OXBuHEwdy4cd1yMoRg2LM6xYUO2Uy0ikh0ZBYhUUHgUaG1mxwPr3f2hio4zs8eA/wJ7mdkiMzvTzP7HzP4ntctkYD4wF7gX+E3qeiuAa4G3U8vI1Lqsa9EixkR8+CEMGVIytsK97IZsswgIn30GTz0FJ5wAkyZFI/hOO8HPfw5PPgnffFO1tK1bF+f/9a/hkksO4Omny29cz5S7emWJSIKy6p58y7aCocAnwIPAQ8AC4MRMjq3J5bu2QZSnqCh+TpjgfuSR7jNmZHbchg3u//mP+69+FW0U4N68ufvgwe733ee+dGlm5/nqK/dx49xPOMF9hx3iPK1aue+00zoH90MPdX/hhZJ0VtaqVe4//rF7u3buzz333c5R21TnHJQPQflQoqptEJlOtXEFMQZiGYCZ7QS8APyjugNWXVPco6moCGbNisn9RoyI+Z0al9MK06RJTAI4aBDccw+8/HKUKv71r/hpBj/4QZRSuneH5ctLlq++ip+ffw5vvx3X7tgxSilDhkDfvvDqq28yf/5RXHst/OhHse666+DwwzP/bPPnRynnww9j3MigQdGuctFFmc10W1AQkx6KyHaqrMiRvgDvlXrfoPS6urBkowSRbsUK99/+Nu7i+/d3X7my8ucoKopSyJ/+5N6zZ3HFVcnSuLH7Lru477uve9++7lde6f7221uXEIrvDNatc7/tNvecnDj+mGPc33ij4hLFK6+4t2/v3rat+4svuq9Z437SSXGOoUOjl1ZZXn/d/Uc/KrneW29VPh+qk+4Yg/IhKB9KVLUEkWmAGE00Ep+RWv4D3JjJsTW5ZDtAFBs7Nr7I//73qp3n44/d77knqpDmz4/qnkyrikr/4gsK3G+8saQ66+CD3R9+2H39+q2Pvf/+SP9ee0UaihUVxTkaNHDff3/3efO2PG7qVPeBA+P8O+/s/pvfRNUURDXVO+9U7vNXxowZEdSSbG9fCNOmua9eXfnjtrd8+K6UDyVqJEDEOfgpcHNqOSHT42pyqakA4e6+YEHJ6/L+mQsL3adMcb/gAvchQ9x79HD/9tvYVlwaAff/9//c58zJ/Ppl/eJXr3a/88748ocoWVx9tfvnn8d4j9//PtYffXTZJaBnn42SRdu27s88EyWYY4+N49q3dx89uqSEsXq1+5//HPtCtJW8+27mn6M8Cxa4/+tf8frYYyNwXXllSf4VK50Xxb+PtWsj4CUFycrauLH8UlV1+PDDkpJZr16VL6FW5xdjXl4sddHcue6nn+5+xRXuS5ZsvV0BokSNBYhtYanJAFFs6tS4a3/iia23Pfus+557Ri43axbVRscf7758eWyfM8d9+nT3a691b9Ei7uqvvz6z61b0iy8sjOsfd5xvrrrad994PWJEfOGVZ968KEWYxTE77uh+ww1RFVVU5P7BBzE4cOLEuLtfuND9mmvcW7eO/QcNii/nN96IBvvyfPNNlD6efDIGKc6dG/nSsWMEuIKC+NIfNsw3N8ynl26K82Lu3AjCBx0UwfCxx2L/Aw5wz8+vMEu3snZtfL5f/CIC4K9/vfX2Rx6J0tOIEVuXuDJVXGqcM8e9Q4e4mWjcOD7nqlWZn6eqX4xr15YE10cfjbz7xS+io0RdUFgY1anNm0eHDTP3Jk22vFlzr/4A8V07gNQFWQ0QxAOCVicsa4DV5R1bG0ttBIgvvojR12ZxZ/2Pf5R8Gc2Y4d6vX1T1rF1b/nmWLHEfPtx9/Ph4v359yZ3v11+7v/xynLvY/vuv9I4d3bt3j+v37+9+4YUl2++6K4LNnXe6jxoVgWmnndzvvjvzz1ZQ4H7eeVFCWLmyJD0PPVRS8klf8vOjnea000pKFBD/xIcfHnd8Tz8dPcKuuipKG926Rckg6Xxm7rvvHr3HBg6Mn3vuGfubRWmmXTv3/fZb6YcfHl+qLVrE5y4uZfz73xFkGjd2/9//rTgwuscXwmmnlfQaa9PG/ec/d//oo9h2zz2RjuLtnTrF+Rs0cD/55KgiysTSpe7nnhulx2LF6Z44MUbpjxlTsq2wMP7eyvrCSvoyWLXK/dZbo+fc1KkR4EtbscJ95MjIz6uuinXr1sXvq1GjqE58/PHa/6JctSry+phj3D/7LALq6NEl22+/PUq8L700pdqu+ec/uzdt6n7JJfF/uK2paoDIaC6mbUVubq5Pmzatxq/7zTfwi1/AP/8Z70eMgDvuqNo5R42Cu+6Kp+LNnx/r2raN3k1mcMklH7J8eXdWr45nVaxZExMPjhsX++6/P7xfapL1AQPg2dRwwyFDoHlz2Guv6EXVqRPsskuco6gIJk6MsRHr18ekhJMmwZ//HGMwvvgixnX86EewahUsXBjL2WdHr6Zbb4Urr4S1a7e8foMGJeNKzKBrVzjggBiJvt9+8eyNl1+Gq66Cpk0jjevWwZIlkY7mzWGHHSJ8LFgQPbbWrIGJE4soLIwhPY0bxxTtfftGHnz5ZQxgnDgx0rjjjnH9li3jmrvsEulasaLkc0N8zgYNoF8/+P73YxbgqVPhoYdg3rySz3TooTEpZNeucPvt8Ne/wurV0L8/XHxx5Hl6jzD3eO7IhAlw333x+c46C+68M37X6T74AHbdFV54IUboP/NM5P33vhefbf/9I/+K83DGjDz69u27+fi8PDj11DimmFl8ltat4cUXY1zNffdFj7Tjj49noOyyC/zud7HPsGHx2N7p0+O5KJdeWt5fbfUrKoonPp56avQMXLw48qR0L7uNG+NvecEC2HPPAu66qyWDMprec2vr18f/WceO8bc3dCi8/jq0axcPFBs+fOvfVXFaly+PsU+FhfG38Otfx99ybcnL2/JvIomZVW0upm1lqY0SRLHCwiiWT55cMrdTVbz4YrQTnHhi3MVMnrxlfWtFdwZFRXEXuHRpVL28807cARdvGzw47oKLq5DA/eyzY/umTVveyX/ve+6nnBKlmEwVFbkvW+b+5ptRKho1KqovXn45SjvF1W4DB7rfcov77Nlx3OWXR6nos88yu86GDe79+3/hL77o/tRT7hdd5J6bu2WppGFD9113jc/bv7/7Oee477fflp8dShrnu3UrqSorvfzwh+4PPuj+6adRNdi+fawfMCDSs2pV3Hl36BDru3eP3+Pxx0cvsUMPLbnWXntFCeLmm93vvTfy6emn43d//fXuffpE2otLYSed5P6Xv0TbVZ8+UbJJT9uBB670efNK/v4WLHA/6qgoOcydG1V4f/lLSd799KeRjtNOi3ajwkL3O+6IUliLFnHNNm2ixDR6dHxm96hyWrCg4lJxZaSXTmbMcH/ppSgx9+kTn23cuIrPsX597Nex41qHaLeqbLXfc8+5d+3qfsQRW6Zp+vToVQiRX+mWLo3q1K5dYx/3qN6F+Huqrja570IliDS1VYKoDZncGWRi/fq4w/7iC9htt7gLA5g5M+7YGjeO9U2aVPlSm61bB6+8EnfEzzwT4zByc2PMh3vcgbdunfn5kvJi1aq4m8zJialPiufbKjZxYkzf3qMHtGkTY0/eey+mWmnZMu4Cd9opji3+ueeecfeabu3aKFUUFcVU8u4ld5C77Rbzey1bFutatozS5urVceyGDZEXZenZE449NtI+cmS8fuKJkjtSd1i0KH5X06fDjTdu4ttvG7H33jFHWEXPVN+wIdLTti18/DGceWaUFgcOhL/9LdJ29tnxu+rTJ9Z17w5HHx2lD4iZB3JyIq3jxsU5H3888rNNm/g9tm4dJdReveKY66+HOXOiNLBoUdylH3dclBQg8qm49Nm6Ndx2W5TQMxmbA/D88y8zc+ZR3Hhj3Pl361bxMV98ARdeCI89FvvffXeUkNO5R0m6Q4d4fv2iRVFbMHlylGCOPDJKF6edFmmdPBl+9asosV13XZy/9N8hROlt6dIoqULk5bp1cc6NG2HTpijJPvpoZp8/nUoQdaQEUdO2p54aCxZUbSxFXcqLb7+Nu9jhw6NTQKNG0TPpP/9J3n/jxmjf+fTTaPifOjVGxi9evOV+f/ubbx5/c8UVJQ2zb70VpZD/+R/3Vq2+3VwqGjw4SnAV2bgxSnfNmkVp4YEHtrxzLiyM9ou2baOd5aqrojR7331RWhs4MEpc7dtHaaRRo5IxOenLkUeWnHPffaNEd/DB7j/5SZSMbrqppI1r8uTo+Tdjxner908fI1TsjDOiPe6LL6IjxNix7u+9F9v++98oLTVpEj3+0o8rz4UXRueNCy5wnzUreZ8vv4y2NohOFsU2boy/iZ/9LNqy+vUr2TZ0aCw/+1mk+6yzorOHe/xdXHll5h0H1ItJAaLeq8t5UZ0Nu3ffHV/kDRuWjAkZPz6+2Nu1c+/Va7nPmBHVSE2axBf1U09tfZ61ayOw3HtvfElD9P76/POyr710aVStgPtuu0WHh+Iv/1atIghedVUExoYNo4rq4ovjS37atC17kRUWRoC78soIFOmBZKedohfakCFRlXbHHe7vv1+5fCz997B2bXwBlw5axT0Gly6NRugPP8z8Gu5xM1C6y3WSoqK4aXj99Xh/663R8F/cAWL48LLH+JQ2dmwc17Kl+6WXVnwToAChAFHvKS9Cej7MnBndeyG65153XdyV7rXXlu0zOTkRZDL9An7mmSjFnHFGlGpmzty6ze2jj6LtrPgL/447oq3o22+jO/igQdH+YxbdsB99NEouI0fGl+Uxx0TdfXobS06O+6mnRsmldLfW0pJ6MRUVRbC85ZZo55k7N7Mebdlw9ynZrtkAAA8qSURBVN3Rc+2JJzIbozNuXPTeuuaaCHbvvRdtgmYRiIsDTxIFCAWIek95EUrnw/r1cRdfXO20555RpXP11e7//Gd8SWbzIVdTp0YjObh36RJTyECMb7n6avdPPqn4HAsWRFA49dQtq666dImSxt57u++xR9yRt2oVpZdmzTb5BReUXyLaFhQWRnUiuHfuHD93370koM+aFbMZlFclVlOT9YnINqZp0+gufcEF0Zj8ve/V7PUPOQSmTImOCP/7v9FoPXw4HHNMcjfRJJ07R+P5mWdGaJg1KxrIX3mlpOtzcffn4tdvvfUVt9+ew913x/UuuSQayUtzj8b9J5+Mxvkzz4TTT6/WLPjO1q2DM86IBv+zzopG8//+F84/H045JbpF33ZbdIXPqrIix7a4qARRPykvgvIhTJkyxefMian2GzWK9phzzokSy8aN0YX23HOjLaW4y/Eee8TrSy+t2UcHJ/niC/dDDomS36hRW1b/bdoUgyfbt4/tZ51V/qMDauqRoyIi24yuXeH++6M77S9/GYMBu3aNLrk//CHce290J33ggehiOmdOdOm94QY46aStB3mWpagoulM/9VQMmBw2LLps77xzdHteXMkHJX/wQZS8Zs6MgbcXX7xl996GDWPw3Zw5UTIcNy4+R7Yec6wqJhHZbnXuHM9jueIK+MtfYkzC4MHx7JMWLbbc969/jXEeF14IRx0VYx5Kj3uBqNqaOBHGjo2xNOlPitx113gM8Z57wpgxEaTOOSdGoOfklJ3ODRsiyPzqV1Fd9sorEWjK0qZNfJ7hw2P8TnWOU0qnACEi273ddospYMpjFlOMdO0aU3v07h1B4qCDYvsHH0TJ4+GHY2qWLl2ifWC//WCffSIwtGlTcr4FC+Daa2PanTFjYlDdxRdD+/YxkDI/P9pTXngh2kDWrYtpU556KtKbib32Khncmg1ZDRBmNgi4DWgI3OfuN5TafgvQL/V2B2Bnd2+T2lYIvJfa9qm7D85mWkVEIOakev11+PGPYwT5RRfBc8/FXFyNG8cz53/966iqKm+0epcuUcq47LKYw2n06GhsPvLIaHBeuTL223ffOF///jFKvXnzmvmcmchagDCzhsBdwNHAIuBtM5vk7rOK93H3C9L2PxfomXaKde7eI1vpExEpywEHxKSKP/lJTHPSvXtU6Zx+ekybUhndusEjj8Dll0egmDEjztu/fwSZDh2y8xmqQzZLEL2Bue4+H8DMxgNDgFll7H8qcHUW0yMikrFddom2gE8/jXmSMp0Lqiz77BOz+G5LsjZZn5mdCAxy97NS708HDnH3EQn77gFMBTq5e2Fq3SYgH9gE3ODuT5ZxneHAcICcnJxe48ePz8bHqXMKCgpo2bJlbSejTlBeBOVDUD6UyCQv+vXrV+ZkfXWlkfoU4B/FwSFlD3dfbGZ7Ai+Z2XvuPq/0ge4+BhgDMZtrdcxwui2ortlctwfKi6B8CMqHElXNi2yOg1gMpLfFd0qtS3IK8Fj6CndfnPo5H8hjy/YJERHJsmwGiLeBbmbWxcyaEEFgUumdzKw70Bb4b9q6tmbWNPW6PXA4ZbddiIhIFmStisndN5nZCOBZopvrWHf/wMxGEkO7i4PFKcB437IxZG/gb2ZWRASxG9J7P4mISPZltQ3C3ScDk0ut+2Op939KOO4NYP9spk1ERMqnuZhERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCTKaoAws0Fm9pGZzTWzSxO2n2FmX5pZfmo5K23bMDObk1qGZTOdIiKytaw9k9rMGgJ3AUcDi4C3zWySu88qtesEdx9R6tgdgauBXMCB6aljV2YrvSIisqVsliB6A3Pdfb67fwuMB4ZkeOxA4Hl3X5EKCs8Dg7KUThERSZC1EgTQEfgs7f0i4JCE/X5qZkcCHwMXuPtnZRzbMekiZjYcGA6Qk5NDXl5e1VO+DSgoKKg3n7UiyougfAjKhxJVzYtsBohM/Bt4zN03mNnZwIPADytzAncfA4wByM3N9b59+1Z7IuuivLw86stnrYjyIigfgvKhRFXzIptVTIuB3dLed0qt28zdl7v7htTb+4BemR4rIiLZlc0A8TbQzcy6mFkT4BRgUvoOZtYh7e1gYHbq9bPAADNra2ZtgQGpdSIiUkOyVsXk7pvMbATxxd4QGOvuH5jZSGCau08CzjOzwcAmYAVwRurYFWZ2LRFkAEa6+4pspVVERLaW1TYId58MTC617o9pry8DLivj2LHA2GymT0REyqaR1CIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEmU1QJjZIDP7yMzmmtmlCdsvNLNZZjbTzF40sz3SthWaWX5qmZTNdIqIyNay9kxqM2sI3AUcDSwC3jazSe4+K223GUCuu39jZucAo4CTU9vWuXuPbKVPRETKl80SRG9grrvPd/dvgfHAkPQd3H2Ku3+TejsV6JTF9IiISCVkM0B0BD5Le78ota4sZwL/SXvfzMymmdlUM/tJNhIoIiJly1oVU2WY2c+BXOCotNV7uPtiM9sTeMnM3nP3eQnHDgeGA+Tk5JCXl1cTSa51BQUF9eazVkR5EZQPQflQoqp5kc0AsRjYLe19p9S6LZjZj4ArgKPcfUPxendfnPo538zygJ7AVgHC3ccAYwByc3O9b9++1fcJ6rC8vDzqy2etiPIiKB+C8qFEVfMim1VMbwPdzKyLmTUBTgG26I1kZj2BvwGD3X1Z2vq2ZtY09bo9cDiQ3rgtIiJZlrUShLtvMrMRwLNAQ2Csu39gZiOBae4+CRgNtAT+bmYAn7r7YGBv4G9mVkQEsRtK9X4SEZEsy2obhLtPBiaXWvfHtNc/KuO4N4D9s5k2EREpn0ZSi4hIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQkREEilAiIhIIgUIERFJpAAhIiKJshogzGyQmX1kZnPN7NKE7U3NbEJq+5tm1jlt22Wp9R+Z2cBsplNERLaWtQBhZg2Bu4BjgH2AU81sn1K7nQmsdPeuwC3Ajalj9wFOAfYFBgF3p84nIiI1JJsliN7AXHef7+7fAuOBIaX2GQI8mHr9D6C/mVlq/Xh33+DuC4C5qfOJiEgNaZTFc3cEPkt7vwg4pKx93H2Tma0C2qXWTy11bMeki5jZcGB46m2BmX1U9aRvE9oDX9V2IuoI5UVQPgTlQ4lM8mKPsjZkM0DUCHcfA4yp7XTUNDOb5u65tZ2OukB5EZQPQflQoqp5kc0qpsXAbmnvO6XWJe5jZo2A1sDyDI8VEZEsymaAeBvoZmZdzKwJ0eg8qdQ+k4BhqdcnAi+5u6fWn5Lq5dQF6Aa8lcW0iohIKVmrYkq1KYwAngUaAmPd/QMzGwlMc/dJwP3Aw2Y2F1hBBBFS+z0OzAI2Ab9198JspXUbVe+q1cqhvAjKh6B8KFGlvLC4YRcREdmSRlKLiEgiBQgREUmkALENMLOxZrbMzN5PW7ejmT1vZnNSP9vWZhprgpntZmZTzGyWmX1gZuen1tfHvGhmZm+Z2bupvLgmtb5LatqaualpbJrUdlprgpk1NLMZZvZU6n29ywczW2hm75lZvplNS62r0v+GAsS2YRwx5Ui6S4EX3b0b8GLq/fZuE/B7d98HOBT4bWpalvqYFxuAH7r7gUAPYJCZHUpMV3NLavqalcR0NvXB+cDstPf1NR/6uXuPtLEPVfrfUIDYBrj7K0Qvr3Tp05Q8CPykRhNVC9x9ibu/k3q9hvhC6Ej9zAt394LU28apxYEfEtPWQD3JCzPrBBwH3Jd6b9TDfChDlf43FCC2XTnuviT1+gsgpzYTU9NSM//2BN6knuZFqlolH1gGPA/MA752902pXcqcomY7cytwCVCUet+O+pkPDjxnZtNTUxBBFf83tvmpNiTuJs2s3vRXNrOWwD+B37n76rhhDPUpL1Jjg3qYWRtgItC9lpNU48zseGCZu083s761nZ5adoS7LzaznYHnzezD9I3f5X9DJYht11Iz6wCQ+rmsltNTI8ysMREcHnX3J1Kr62VeFHP3r4EpwA+ANqlpa6B+TFFzODDYzBYSM0b/ELiN+pcPuPvi1M9lxA1Db6r4v6EAse1Kn6ZkGPCvWkxLjUjVLd8PzHb3m9M21ce82ClVcsDMmgNHE20yU4hpa6Ae5IW7X+bundy9MzETw0vu/jPqWT6YWQsza1X8GhgAvE8V/zc0knobYGaPAX2JqXuXAlcDTwKPA7sDnwBD3b10Q/Z2xcyOAF4F3qOkvvlyoh2ivuXFAUSjY0PiRu9xdx9pZnsSd9I7AjOAn7v7htpLac1JVTFd5O7H17d8SH3eiam3jYD/c/c/m1k7qvC/oQAhIiKJVMUkIiKJFCBERCSRAoSIiCRSgBARkUQKECIikkgBQqQSzKwwNVtm8VJtEwOaWef0GXtFapum2hCpnHXu3qO2EyFSE1SCEKkGqbn4R6Xm43/LzLqm1nc2s5fMbKaZvWhmu6fW55jZxNTzHN41s8NSp2poZvemnvHwXGqUtEitUIAQqZzmpaqYTk7btsrd9wfuJGYYBbgDeNDdDwAeBW5Prb8deDn1PIeDgA9S67sBd7n7vsDXwE+z/HlEyqSR1CKVYGYF7t4yYf1C4gE+81MTCn7h7u3M7Cugg7tvTK1f4u7tzexLoFP69A+pKcyfTz3cBTP7A9DY3a/L/icT2ZpKECLVx8t4XRnp8wUVonZCqUUKECLV5+S0n/9NvX6DmGUU4GfEZIMQj388BzY/+Kd1TSVSJFO6OxGpnOapp7gVe8bdi7u6tjWzmUQp4NTUunOBB8zsYuBL4Jep9ecDY8zsTKKkcA6wBJE6RG0QItUg1QaR6+5f1XZaRKqLqphERCSRShAiIpJIJQgREUmkACEiIokUIEREJJEChIiIJFKAEBGRRP8fUIp65HFWwjkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA3Ip296PEpq",
        "outputId": "b737c6bf-16f1-4fac-832c-5b78a4ec0ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AB_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5545454545454545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZgZtwUy5UuD"
      },
      "source": [
        "# **3. modelling for tweets related to Target : Atheism**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AndJglj7mZb6"
      },
      "source": [
        "First we check the preprocessed tweet data for target Atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_GO73Wc5ckA",
        "outputId": "77dbfca3-cde1-4cd9-a1dc-affe067e582f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_AT[:1]"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['dear',\n",
              "  'lord',\n",
              "  'thank',\n",
              "  'ur',\n",
              "  'blessings',\n",
              "  'forgive',\n",
              "  'sins',\n",
              "  'lord',\n",
              "  'give',\n",
              "  'strength',\n",
              "  'energy',\n",
              "  'busy',\n",
              "  'day',\n",
              "  'ahead',\n",
              "  '#blessed',\n",
              "  '#hope',\n",
              "  '#semst',\n",
              "  'atheism']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B97j5WeMmkKi"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITghyAfU5on9",
        "outputId": "5e93fb03-4173-4989-ef2c-32dab7cdd2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_AT)\n",
        "Y = pd.get_dummies(traindata_AT['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2462 unique tokens.\n",
            "Shape of data tensor: (513, 40)\n",
            "Shape of label tensor: (513, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0KouwGhmp2Z"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZqc9JFU5vUG",
        "outputId": "6d2f4320-43f7-4fb1-c216-511a5873910c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (410, 40)\n",
            "Y train shape:  (410, 3)\n",
            "X Val shape:  (103, 40)\n",
            "Y Val shape:  (103, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MWxEp6w5364"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9u1Ho5o53Q0",
        "outputId": "4d1991c6-240c-4fa2-abb5-132106c4f5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model2 = create_model(embedding_layer)\n",
        "print(model2.summary())"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 40, 100)           246300    \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 265,631\n",
            "Trainable params: 265,631\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht3uMDBtm1fY"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 20 epochs in each of the 3 folds.\n",
        "The batch size is set to 32 and we trained the data for 20 epochs and 3 folds.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fBoq3UT6EuV",
        "outputId": "924461fa-4576-4e54-8ee5-c4c0cbd86eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model2.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/11 [====>.........................] - ETA: 2s - loss: 1.1955WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0628s vs `on_train_batch_end` time: 0.4929s). Check your callbacks.\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 1.1561 - val_loss: 1.0966\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 1.0624 - val_loss: 1.0491\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 1.0400 - val_loss: 1.0320\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 1.0349 - val_loss: 1.0232\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 1.0261 - val_loss: 1.0145\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 1.0120 - val_loss: 1.0073\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 1.0175 - val_loss: 1.0032\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.9949 - val_loss: 0.9944\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.9911 - val_loss: 0.9903\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 0.9950 - val_loss: 0.9877\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.9773 - val_loss: 0.9856\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.9755 - val_loss: 0.9807\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.9399 - val_loss: 0.9401\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.6248 - val_loss: 1.2638\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.4408 - val_loss: 1.2237\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3686 - val_loss: 1.6899\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3591 - val_loss: 1.8148\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.3520 - val_loss: 1.9277\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3370 - val_loss: 1.9154\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/11 [====>.........................] - ETA: 0s - loss: 0.9322WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0570s vs `on_train_batch_end` time: 0.1037s). Check your callbacks.\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 1.0364 - val_loss: 0.3532\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.6665 - val_loss: 0.5535\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.8224 - val_loss: 0.5273\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.5342 - val_loss: 0.4645\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.5335 - val_loss: 0.4490\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.4488 - val_loss: 0.4284\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.4047 - val_loss: 0.4046\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.4039 - val_loss: 0.4071\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.4069 - val_loss: 0.3698\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3853 - val_loss: 0.3594\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.3512 - val_loss: 0.3528\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3565 - val_loss: 0.3437\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3367 - val_loss: 0.3379\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3431 - val_loss: 0.4013\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.4680 - val_loss: 0.5254\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.4651 - val_loss: 0.5049\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.4338 - val_loss: 0.4615\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3781 - val_loss: 0.4464\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3660 - val_loss: 0.4476\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3639 - val_loss: 0.4489\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 0.4055 - val_loss: 0.2877\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.4078 - val_loss: 0.2874\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3732 - val_loss: 0.2853\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.3569 - val_loss: 0.2833\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.3551 - val_loss: 0.2813\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.3288 - val_loss: 0.2789\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3617 - val_loss: 0.2771\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3296 - val_loss: 0.2754\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3474 - val_loss: 0.2745\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.3416 - val_loss: 0.2737\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3352 - val_loss: 0.2734\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.3630 - val_loss: 0.2740\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.7407 - val_loss: 0.5040\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.5071 - val_loss: 0.3216\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3597 - val_loss: 0.3120\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.3835 - val_loss: 0.3053\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3488 - val_loss: 0.2981\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3776 - val_loss: 0.2925\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.3456 - val_loss: 0.2884\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3309 - val_loss: 0.2852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXveg7L3m_2B"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yayCOjqC6ipM",
        "outputId": "7e0cb1f2-af32-4c23-fbef-8c78a0227763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iew-RGPeQcE3",
        "outputId": "dfe451a7-e4b7-40bb-fab3-a08efcf699e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_AT)\n",
        "Y_true = pd.get_dummies(testdata_AT['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1339 unique tokens.\n",
            "Shape of data tensor: (220, 40)\n",
            "Shape of label tensor: (220, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr2ZgpoiQcFN",
        "outputId": "5a6a1219-7fa8-4d76-b64c-dab1a6059149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AT_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6006389776357827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM9mdkHd6uDs"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDjYRAyu6h0w",
        "outputId": "e5aca783-c1f9-42ef-f7da-48c3277c8099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "246300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENIvOjGJ6ho9",
        "outputId": "ab12f50d-f8ff-4476-f870-66a946531ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model2 = create_model(embedding_layer_TL)\n",
        "print(model2.summary())"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 40, 100)           246300    \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 265,631\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 246,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZjyXfqX663E",
        "outputId": "bdf035c2-49d3-40b1-be22-f22c40ed6be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model2.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/13 [===>..........................] - ETA: 3s - loss: 1.2071WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0532s vs `on_train_batch_end` time: 0.5054s). Check your callbacks.\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 1.1826 - val_loss: 1.1559\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 1.0992 - val_loss: 1.0884\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 1.0316 - val_loss: 1.0746\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.9901 - val_loss: 1.0578\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.9697 - val_loss: 1.0335\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.9065 - val_loss: 0.8976\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.8393 - val_loss: 0.8640\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.8224 - val_loss: 0.8611\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.8010 - val_loss: 0.8655\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.7954 - val_loss: 0.8758\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.7887 - val_loss: 0.8938\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7818 - val_loss: 0.8761\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7755 - val_loss: 0.8797\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.7641 - val_loss: 0.8759\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.7849 - val_loss: 0.9170\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7849 - val_loss: 0.8700\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7574 - val_loss: 0.9445\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.7577 - val_loss: 0.8689\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.7443 - val_loss: 0.8923\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7262 - val_loss: 0.9135\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7175 - val_loss: 0.9039\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7481 - val_loss: 0.8866\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7256 - val_loss: 0.9284\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7198 - val_loss: 0.9691\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6979 - val_loss: 0.9076\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7356 - val_loss: 0.9395\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.7360 - val_loss: 0.8888\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.7418 - val_loss: 0.9628\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.7428 - val_loss: 0.8966\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7346 - val_loss: 0.9110\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.6866 - val_loss: 0.9525\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6804 - val_loss: 0.9187\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6771 - val_loss: 0.9065\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.6931 - val_loss: 1.0344\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.6931 - val_loss: 0.9478\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6637 - val_loss: 0.9346\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 0.6596 - val_loss: 1.0291\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6609 - val_loss: 0.9462\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6789 - val_loss: 0.9318\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.6582 - val_loss: 1.1124\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6892 - val_loss: 0.9241\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.6322 - val_loss: 1.0988\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 46ms/step - loss: 0.6490 - val_loss: 0.9827\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6516 - val_loss: 0.9904\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6965 - val_loss: 1.0172\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6567 - val_loss: 1.1162\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.6283 - val_loss: 1.0708\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6247 - val_loss: 1.0620\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6342 - val_loss: 1.1078\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6343 - val_loss: 1.1792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VosXxD1c67X5",
        "outputId": "11e14329-5e0a-4263-cea4-70c82072080e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFA2rIAgQ83p",
        "outputId": "3c1fe944-6aab-486a-f16b-f644f13ed1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AT_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7157894736842105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qXKf6B7HR9"
      },
      "source": [
        "# **4. Modelling for tweets related to target: Climate Change is a Real Concern**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Fl0P6KnMoz"
      },
      "source": [
        "First we check the preprocessed tweet data for target Climate Change is a Real Concern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-wCIovY74Y_",
        "outputId": "01de428f-c4a3-49ec-f949-79028c6c3f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_CC[:1]"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['cant',\n",
              "  'deny',\n",
              "  'really',\n",
              "  'happening',\n",
              "  '#semst',\n",
              "  'climate',\n",
              "  'change',\n",
              "  'real',\n",
              "  'concern']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKX4PbJkncix"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hWkV61G8EoZ",
        "outputId": "5a7bd001-7fd3-4797-9fb8-52e22e44e765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_CC)\n",
        "Y = pd.get_dummies(traindata_CC['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2281 unique tokens.\n",
            "Shape of data tensor: (395, 40)\n",
            "Shape of label tensor: (395, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84G7kjPynci3"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIgZmm9c8Mv7",
        "outputId": "f831201d-9477-432e-abd2-815d4961796c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (316, 40)\n",
            "Y train shape:  (316, 3)\n",
            "X Val shape:  (79, 40)\n",
            "Y Val shape:  (79, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_DxoMYR8bRn"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22qYAKN8bRp",
        "outputId": "d46580b3-7149-47e2-cc9d-36cdcad919ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model2 = create_model(embedding_layer)\n",
        "print(model2.summary())"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 40, 100)           228200    \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 247,531\n",
            "Trainable params: 247,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL4ctSrAnci5"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 20 epochs in each of the 3 folds.\n",
        "The batch size is set to 32 and we trained the data for 20 epochs and 3 folds.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RggbRK4P8bRu",
        "outputId": "b7138dae-2400-468f-8187-41cd9276f54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model2.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            "2/9 [=====>........................] - ETA: 2s - loss: 1.2056WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0673s vs `on_train_batch_end` time: 0.5291s). Check your callbacks.\n",
            "9/9 [==============================] - 1s 158ms/step - loss: 1.1797 - val_loss: 1.1293\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 1.0849 - val_loss: 1.0119\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.9462 - val_loss: 0.9153\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.9381 - val_loss: 0.9172\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.9155 - val_loss: 0.9054\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.8763 - val_loss: 0.8990\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8787 - val_loss: 0.8896\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.8792 - val_loss: 0.8843\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.8709 - val_loss: 0.8785\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.8688 - val_loss: 0.8757\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8808 - val_loss: 0.8726\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.8625 - val_loss: 0.8703\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8353 - val_loss: 0.8666\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.8452 - val_loss: 0.8659\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.8481 - val_loss: 0.8626\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8413 - val_loss: 0.8604\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8349 - val_loss: 0.8604\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8169 - val_loss: 0.8451\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.7821 - val_loss: 0.8246\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.7058 - val_loss: 0.8430\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.7432 - val_loss: 0.5977\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6930 - val_loss: 0.5106\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5940 - val_loss: 0.4764\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5039 - val_loss: 0.4318\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.4041 - val_loss: 0.3615\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.3204 - val_loss: 0.2839\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.2635 - val_loss: 0.3699\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.2704 - val_loss: 0.3538\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.2307 - val_loss: 0.3586\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.2041 - val_loss: 0.3619\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.2106 - val_loss: 0.2814\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.2564 - val_loss: 0.3355\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2027 - val_loss: 0.2691\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.1937 - val_loss: 0.3041\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.2228 - val_loss: 0.3021\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.1847 - val_loss: 0.2600\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2127 - val_loss: 0.1670\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.1775 - val_loss: 0.2106\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.1656 - val_loss: 0.2451\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.1621 - val_loss: 0.2060\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.2261 - val_loss: 0.1204\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.2158 - val_loss: 0.2605\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.2100 - val_loss: 0.1256\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.1518 - val_loss: 0.1245\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.1602 - val_loss: 0.1676\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.1483 - val_loss: 0.1050\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.1128 - val_loss: 0.1313\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.0887 - val_loss: 0.1618\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.0752 - val_loss: 0.0855\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.0593 - val_loss: 0.0846\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.0416 - val_loss: 0.1383\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.0433 - val_loss: 0.1739\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.0446 - val_loss: 0.1152\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2135 - val_loss: 0.0834\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.0320 - val_loss: 0.1702\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.0418 - val_loss: 0.1997\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.0547 - val_loss: 0.1110\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.0317 - val_loss: 0.0900\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.0536 - val_loss: 0.1091\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.0649 - val_loss: 0.1129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ1XXAYlnci7"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UyWMRb8bR0",
        "outputId": "8527ab55-21c7-4173-98ea-449c4fb76a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz0N9II6T3ew",
        "outputId": "18a5133c-4336-4b2c-88a0-eb956e14c0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_CC)\n",
        "Y_true = pd.get_dummies(testdata_CC['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1167 unique tokens.\n",
            "Shape of data tensor: (169, 40)\n",
            "Shape of label tensor: (169, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndUA2BeT3fE",
        "outputId": "4d3aa893-b9e2-4036-aea4-6edef7b5e85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_CC_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6167400881057269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UECckmdJ8bR8"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1zde7Ff8bR9",
        "outputId": "f4d690e7-21bf-4dae-9b89-a68efca8c39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUUCG7408bSA",
        "outputId": "46351d9e-1595-4040-90aa-13c53e9418ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model2 = create_model(embedding_layer_TL)\n",
        "print(model2.summary())"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 40, 100)           228200    \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 247,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 228,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ3UShmz8bSG",
        "outputId": "ddd16dea-042e-4e66-d3ed-8ce98558f3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model2.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/10 [=====>........................] - ETA: 2s - loss: 1.2078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_end` time: 0.4469s). Check your callbacks.\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 1.1816 - val_loss: 1.1478\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 1.0765 - val_loss: 1.0296\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.9418 - val_loss: 1.0231\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9003 - val_loss: 0.9596\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8780 - val_loss: 0.9607\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.8713 - val_loss: 0.9520\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8541 - val_loss: 0.9504\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8578 - val_loss: 0.9490\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8399 - val_loss: 0.9319\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8320 - val_loss: 0.9523\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8486 - val_loss: 0.9323\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8411 - val_loss: 0.9239\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8337 - val_loss: 0.9283\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8352 - val_loss: 0.9321\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8143 - val_loss: 0.9287\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8186 - val_loss: 0.9218\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8156 - val_loss: 0.9257\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8212 - val_loss: 0.9153\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7969 - val_loss: 0.9238\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8015 - val_loss: 0.9252\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.7926 - val_loss: 0.9133\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7724 - val_loss: 0.9160\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7251 - val_loss: 0.9711\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7367 - val_loss: 0.8771\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7122 - val_loss: 0.9600\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7533 - val_loss: 0.8273\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6944 - val_loss: 0.8979\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6792 - val_loss: 0.8325\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.7276 - val_loss: 0.8034\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7141 - val_loss: 0.8327\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6521 - val_loss: 0.7954\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6650 - val_loss: 0.8629\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6323 - val_loss: 0.7675\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6149 - val_loss: 0.8347\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6108 - val_loss: 0.8009\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5979 - val_loss: 0.7825\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5973 - val_loss: 0.9528\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6135 - val_loss: 0.7902\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6225 - val_loss: 0.8394\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6615 - val_loss: 0.7826\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6056 - val_loss: 0.7990\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6127 - val_loss: 0.7682\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5764 - val_loss: 0.8205\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5795 - val_loss: 0.7696\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5948 - val_loss: 0.8300\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6031 - val_loss: 0.7979\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5941 - val_loss: 0.7970\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5687 - val_loss: 0.7680\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6013 - val_loss: 0.8188\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5309 - val_loss: 0.8070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WguOykzO8bSJ",
        "outputId": "08b001f9-029f-415e-83b0-858800a1ff41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHrLvBFUB9d",
        "outputId": "5423c4b1-9c7a-4e48-ddb0-1f2cc39b4f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_CC_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6375545851528384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHma85Nt9Kky"
      },
      "source": [
        "# **5. Modelling for tweets related to target: Feminist Movement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZJsHUrUn5kE"
      },
      "source": [
        "First we check the preprocessed tweet data for target Feminist Movement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYn6HtDB9Kk1",
        "outputId": "1b4504fd-802b-424a-afca-ae700c04d159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "Tweets_FM[:1]"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['always',\n",
              "  'delight',\n",
              "  'see',\n",
              "  'chestdrumming',\n",
              "  'alpha',\n",
              "  'males',\n",
              "  'hiss',\n",
              "  'scuttle',\n",
              "  'backwards',\n",
              "  'wall',\n",
              "  'feminist',\n",
              "  'enters',\n",
              "  'room',\n",
              "  '#manly',\n",
              "  '#semst',\n",
              "  'feminist',\n",
              "  'movement']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU47Y2Hcn5kL"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9SjnDsq9Kk7",
        "outputId": "03dc465e-08ab-4eee-a3da-0b327c1da727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_FM)\n",
        "Y = pd.get_dummies(traindata_FM['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3031 unique tokens.\n",
            "Shape of data tensor: (664, 40)\n",
            "Shape of label tensor: (664, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXakGexWn5kN"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPEWZ2rc9Kk9",
        "outputId": "d3d76049-da84-45f9-c24d-9d78632e0956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (531, 40)\n",
            "Y train shape:  (531, 3)\n",
            "X Val shape:  (133, 40)\n",
            "Y Val shape:  (133, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWfMQLKi9KlA"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy4Jr0-H9KlA",
        "outputId": "4bdc8ae4-9f29-4999-e577-497b2507ba21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model2 = create_model(embedding_layer)\n",
        "print(model2.summary())"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_24 (Embedding)     (None, 40, 100)           303200    \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 322,531\n",
            "Trainable params: 322,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ansOZNmNn5kP"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVHihgjs9KlD",
        "outputId": "f053f94d-2278-4346-a4ef-a34de785acb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model2.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 3s - loss: 1.2146WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0732s vs `on_train_batch_end` time: 0.5926s). Check your callbacks.\n",
            "14/14 [==============================] - 2s 129ms/step - loss: 1.1897 - val_loss: 1.1553\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.1229 - val_loss: 1.1182\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 1.1138 - val_loss: 1.1054\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0808 - val_loss: 1.0955\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 1.0773 - val_loss: 1.0858\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0692 - val_loss: 1.0798\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0572 - val_loss: 1.0751\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 1.0497 - val_loss: 1.0740\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 1.0502 - val_loss: 1.0683\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0424 - val_loss: 1.0643\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0465 - val_loss: 1.0664\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 1.0445 - val_loss: 1.0608\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0369 - val_loss: 1.0595\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0392 - val_loss: 1.0580\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.9836 - val_loss: 1.0365\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7596 - val_loss: 1.4889\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7132 - val_loss: 1.3032\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.6222 - val_loss: 1.4755\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.5272 - val_loss: 1.8229\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.4713 - val_loss: 1.8421\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 1s - loss: 0.9632WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0575s vs `on_train_batch_end` time: 0.1197s). Check your callbacks.\n",
            "14/14 [==============================] - 1s 74ms/step - loss: 1.0795 - val_loss: 0.4640\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7522 - val_loss: 0.5055\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.8090 - val_loss: 0.5471\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7530 - val_loss: 0.5374\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7250 - val_loss: 0.4871\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7057 - val_loss: 0.4642\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.6906 - val_loss: 0.4687\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.6655 - val_loss: 0.4658\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.6468 - val_loss: 0.4527\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.7367 - val_loss: 0.4674\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7405 - val_loss: 0.5138\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.6724 - val_loss: 0.5040\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.6412 - val_loss: 0.4659\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.7289 - val_loss: 0.6397\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7740 - val_loss: 0.6498\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.7080 - val_loss: 0.6331\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.6574 - val_loss: 0.6148\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.6852 - val_loss: 0.6165\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.6920 - val_loss: 0.5729\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.6283 - val_loss: 0.5142\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.5747 - val_loss: 0.5403\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5867 - val_loss: 0.5007\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.5809 - val_loss: 0.5052\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5737 - val_loss: 0.4782\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5330 - val_loss: 0.4740\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5393 - val_loss: 0.4725\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5338 - val_loss: 0.5414\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.4895 - val_loss: 0.5038\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5543 - val_loss: 0.5001\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5439 - val_loss: 0.5143\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.5248 - val_loss: 0.4653\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.4905 - val_loss: 0.4499\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5228 - val_loss: 0.4494\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4665 - val_loss: 0.5365\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.4965 - val_loss: 0.5626\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.4147 - val_loss: 0.3631\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3750 - val_loss: 0.3302\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.3651 - val_loss: 0.3336\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.3082 - val_loss: 0.3918\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.3231 - val_loss: 0.5643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYFP3QnVn5kQ"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVUf2S6n9KlF",
        "outputId": "32239b0c-e9f5-4818-a36f-2fdfca4199e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmbxOOr1UgYd",
        "outputId": "636e3ac2-8ecf-4470-f8d1-bf58c80b1ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_FM)\n",
        "Y_true = pd.get_dummies(testdata_FM['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1609 unique tokens.\n",
            "Shape of data tensor: (285, 40)\n",
            "Shape of label tensor: (285, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZgl5lPbUgYu",
        "outputId": "b8ed579e-e604-4353-8fc5-f675e6c8cd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_FM_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43737574552683894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yks4widM9KlK"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBaBIA269KlK",
        "outputId": "aae0bfed-6710-47da-854d-41a019032de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ey5Mmr39KlN",
        "outputId": "b64ef1fa-6e9d-47f9-fb9c-ef040d1b94ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model2 = create_model(embedding_layer_TL)\n",
        "print(model2.summary())"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 40, 100)           303200    \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 322,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 303,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvDnzOGQ9KlQ",
        "outputId": "6576c86c-5e29-4ecc-832f-d22ee1e58e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "m_histories['with_TL'] = model2.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/17 [==>...........................] - ETA: 3s - loss: 1.2107WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0611s vs `on_train_batch_end` time: 0.4686s). Check your callbacks.\n",
            "17/17 [==============================] - 2s 99ms/step - loss: 1.1853 - val_loss: 1.1562\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 1.1166 - val_loss: 1.1023\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 1.0762 - val_loss: 1.0850\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 1.0627 - val_loss: 1.0732\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 1.0539 - val_loss: 1.0639\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0292 - val_loss: 1.0295\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 1.0208 - val_loss: 1.0494\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 1.0297 - val_loss: 1.0585\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.9866 - val_loss: 1.0284\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.9909 - val_loss: 1.0142\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9854 - val_loss: 1.0135\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9478 - val_loss: 1.0951\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.9375 - val_loss: 1.0699\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9391 - val_loss: 1.0797\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9434 - val_loss: 1.0362\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9293 - val_loss: 1.0039\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9115 - val_loss: 1.0429\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.9029 - val_loss: 1.1174\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.9287 - val_loss: 1.0046\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 1s 63ms/step - loss: 0.9373 - val_loss: 1.0185\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.8882 - val_loss: 1.1612\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.9081 - val_loss: 1.0253\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.9019 - val_loss: 1.0920\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 0.9057 - val_loss: 1.0479\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 1s 57ms/step - loss: 0.8836 - val_loss: 1.1503\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9316 - val_loss: 0.9985\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9324 - val_loss: 1.0044\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9068 - val_loss: 1.0742\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8982 - val_loss: 1.0467\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9148 - val_loss: 1.1052\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8758 - val_loss: 1.3831\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9587 - val_loss: 1.0251\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8973 - val_loss: 1.0966\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8767 - val_loss: 1.1362\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8763 - val_loss: 1.1402\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8754 - val_loss: 1.0912\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8826 - val_loss: 1.0604\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9026 - val_loss: 1.0786\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8813 - val_loss: 1.0959\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8631 - val_loss: 1.0650\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 0.8759 - val_loss: 1.1179\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8399 - val_loss: 1.1463\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8561 - val_loss: 1.1220\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8432 - val_loss: 1.0776\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8574 - val_loss: 1.2116\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8783 - val_loss: 1.1330\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8385 - val_loss: 1.2052\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8405 - val_loss: 1.1671\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8526 - val_loss: 1.1741\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8152 - val_loss: 1.2240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njB1jFeu9KlX",
        "outputId": "d7a472ba-d41d-4e2f-fd80-c7b6510d4e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZdN-ZSEUnRt",
        "outputId": "396fbc36-ee6a-4853-d384-9687030c25a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model2.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,labels = [0,1], average='micro')\n",
        "result_df.loc[len(result_df)] = ['Approach2_FM_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6611226611226612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjyeG5VHbYj",
        "outputId": "02523ca4-6d41-4752-dd84-bf93e3203abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "result_df"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>F1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Approach1_All_data_model</td>\n",
              "      <td>0.492988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Approach2_HC_WTF</td>\n",
              "      <td>0.531707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Approach2_HC_TF</td>\n",
              "      <td>0.624506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Approach2_AB_WTF</td>\n",
              "      <td>0.544041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Approach2_AB_TF</td>\n",
              "      <td>0.554545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Approach2_AT_WTF</td>\n",
              "      <td>0.600639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Approach2_AT_TF</td>\n",
              "      <td>0.715789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Approach2_CC_WTF</td>\n",
              "      <td>0.616740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Approach2_CC_TF</td>\n",
              "      <td>0.637555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Approach2_FM_WTF</td>\n",
              "      <td>0.437376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Approach2_FM_TF</td>\n",
              "      <td>0.661123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  F1_score\n",
              "0   Approach1_All_data_model  0.492988\n",
              "1           Approach2_HC_WTF  0.531707\n",
              "2            Approach2_HC_TF  0.624506\n",
              "3           Approach2_AB_WTF  0.544041\n",
              "4            Approach2_AB_TF  0.554545\n",
              "5           Approach2_AT_WTF  0.600639\n",
              "6            Approach2_AT_TF  0.715789\n",
              "7           Approach2_CC_WTF  0.616740\n",
              "8            Approach2_CC_TF  0.637555\n",
              "9           Approach2_FM_WTF  0.437376\n",
              "10           Approach2_FM_TF  0.661123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59PbXBkzv4CY"
      },
      "source": [
        "#Independent Evaluation on sample sunseen data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ZiIrxDxje-"
      },
      "source": [
        "**Reading the dataset for independent evaluation**\n",
        "\n",
        "We have sampled a small dataset consisting of 11 tweets along with their Topic and Stance values. Our aim to check if our model is performing as expected on this data.\n",
        "But for that, we have to preprocess and tokenize the data same as that for training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA_kW7y_v1uZ"
      },
      "source": [
        "ide = pd.read_csv(\"/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/IndependentEvaluation .csv\")"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGLSVWFvv1sA",
        "outputId": "00beedb5-da6a-45f2-ed8e-6a6fc748a1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "ide.head()"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Target</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Crooked Hillary clinton deleted 33,000 emails ...</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>Against</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HillaryClinton when you go to prison for defra...</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>Favor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HillaryClinton is Calling for love and Kindness</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>Favor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>There is no such thing as #Abortion upto the p...</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>Against</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Left really needs to reclaim atheism</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>Favor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ...   Stance\n",
              "0  Crooked Hillary clinton deleted 33,000 emails ...  ...  Against\n",
              "1  HillaryClinton when you go to prison for defra...  ...    Favor\n",
              "2    HillaryClinton is Calling for love and Kindness  ...    Favor\n",
              "3  There is no such thing as #Abortion upto the p...  ...  Against\n",
              "4           The Left really needs to reclaim atheism  ...    Favor\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTNTYshvv1pX",
        "outputId": "c2eeb560-70eb-460c-fc97-ec1f09b3f3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# as we have to use only tweet sentences and Target as an input for detecting the Stance, we concatenate this features into a single feature \n",
        "ide[\"Tweet\"] = ide[\"Tweet\"] + \" \" + ide[\"Target\"]\n",
        "ide.shape"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTo2sgTy12wP"
      },
      "source": [
        "**Preprocessing the independent evaluation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-NstsQj1-UX",
        "outputId": "d22c57fd-2bb4-4429-f4da-2889fb9da665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Converting to lower case\n",
        "\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: x.lower()) \n",
        "\n",
        "ide['Tweet'].head(2)"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    crooked hillary clinton deleted 33,000 emails ...\n",
              "1    hillaryclinton when you go to prison for defra...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GDcqRqT1-SI"
      },
      "source": [
        "# Contraction to Expandion [Meaning converting words like \"don't\" to \"do not\"]\n",
        "\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i had\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she had\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that had\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they had\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "\" n \":\"and\",\n",
        "\" u \": \"you\",\n",
        "}\n",
        "\n",
        "def con_to_ext(x):\n",
        "  if type(x) is str:\n",
        "    for key in contractions:\n",
        "      value = contractions[key]\n",
        "      x = x.replace(key, value)\n",
        "    return x\n",
        "  else:\n",
        "    return x"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "493wIUGq1-QC",
        "outputId": "33aa128c-c3e4-4cab-d621-c81c09e2cc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: con_to_ext(x))\n",
        "ide['Tweet'].head(5)"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    crooked hillary clinton deleted 33,000 emails ...\n",
              "1    hillaryclinton when you go to prison for defra...\n",
              "2    hillaryclinton is calling for love and kindnes...\n",
              "3    there is no such thing as #abortion upto the p...\n",
              "4     the left really needs to reclaim atheism atheism\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVZEq501-Nx"
      },
      "source": [
        "## Removing the emails from the Tweet column.\n",
        "\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: re.sub(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)','',x))"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yel2du01-LP",
        "outputId": "ef97e564-7e4b-43d5-c6fb-c90e8094c222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "## Removing Special characters and punctuations\n",
        "\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: re.sub('[^A-Za-z0-9#@]+',' ',x))\n",
        "\n",
        "## Remove the multiple(extra) spaces\n",
        "\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "## Remove the Accented characters (e.g. àÿüûâ)\n",
        "import unicodedata\n",
        "\n",
        "def remove_accent(x):\n",
        "  x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "  return x\n",
        "\n",
        "## Applying on tweets\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: remove_accent(x))\n",
        "\n",
        "### Removing the stop words\n",
        "\n",
        "ide['Tweet'] = ide['Tweet'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
        "\n",
        "\n",
        "ide['Tweet'].head(5)"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    crooked hillary clinton deleted 33 000 emails ...\n",
              "1    hillaryclinton prison defrauding america perju...\n",
              "2    hillaryclinton calling love kindness hillary c...\n",
              "3    thing #abortion upto point birth legalization ...\n",
              "4                   left needs reclaim atheism atheism\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK0qdnnQ2yWn",
        "outputId": "66d55e1e-4c3a-4119-ac42-0d56fcfdfac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Converting the Tweet text to list\n",
        "text = ide['Tweet'].tolist()\n",
        "text[:3]"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crooked hillary clinton deleted 33 000 emails subpoenaed united states congress guilty run rigged system hillary clinton',\n",
              " 'hillaryclinton prison defrauding america perjury room board free hillary clinton',\n",
              " 'hillaryclinton calling love kindness hillary clinton']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3K3pxkf2yiT",
        "outputId": "1b0fd51c-652b-49da-f7a6-84d5bc1943da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##### Converting categorical variable into dummy/indicator variables.\n",
        "y = ide['Stance']\n",
        "y = pd.get_dummies(y).values\n",
        "y.shape"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtVmSvOe2ycU",
        "outputId": "24e8786b-e56b-42e5-ceb0-3d7f5d860579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tokenizing the text\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "\n",
        "### Calculating the vocabulary size\n",
        "vocab_size = len(token.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0jrk2qP2yT2",
        "outputId": "9e4b1366-c405-4464-8a58-5ef913bc7390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Encoding the text\n",
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:3])\n",
        "\n",
        "## prepadding is done with the maxlength 50\n",
        "\n",
        "sentence_max_length = 50\n",
        "X = pad_sequences(encoded_text, maxlen=sentence_max_length)\n",
        "print(X.shape)"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 3, 4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 3, 4], [7, 23, 24, 25, 26, 27, 28, 29, 3, 4], [7, 30, 31, 32, 3, 4]]\n",
            "(11, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NSz-v71-Iz",
        "outputId": "04a08aee-58f0-453e-9af7-3f104789048e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking the shape of X features variable\n",
        "X.shape"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEfpP9cn1-Gd",
        "outputId": "4279c649-bb5a-42d4-eb63-266adb558ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking the shape of y variable\n",
        "y.shape"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_loQAbqv1m2"
      },
      "source": [
        "y_train = X\n",
        "y_val = y"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ_nTZJB4q5G"
      },
      "source": [
        "# Predicting the features given in the independent evaluation metric \n",
        "y_pred_test = model1.predict_classes(y_train)"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p9EO7JC4rGL",
        "outputId": "dc3bb667-657e-4f6d-fc9a-9af4862ec9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting the np array to original form\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "y_val = np.argmax(y, axis= 1)\n",
        "\n",
        "# Calculating the f1-score of the predicted output and actual output.\n",
        "\n",
        "f1_score_result = f1_score(y_val, y_pred_test,average='weighted')\n",
        "#result_df.loc[len(result_df)] = ['Approach1_All_data_model', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5714285714285715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 351
        }
      ]
    }
  ]
}