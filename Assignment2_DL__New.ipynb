{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_DL _New.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xXlnOSPUrF18",
        "EmcvYG6GaZAp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7UPIghEqvMi"
      },
      "source": [
        "# **Assignment 2: Stance Detection in Tweets using Deep Learning on SemEval 2 task 6 data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfY_1TQrqbp9"
      },
      "source": [
        "# Setting notebook and related packages and methods.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONRDMNP9xflY"
      },
      "source": [
        "First we mount the google drive so that we can access the data files from the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4etGXG5qBdFD",
        "outputId": "5108f6dc-3493-424a-a8d4-482f4261ad38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWHE3jlppGdq",
        "outputId": "2b7ed345-e605-4d81-d687-6f39a7488f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "!pip install -U spacy"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.3.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2K98JlkpGTu",
        "outputId": "9b211944-0425-4699-fadd-32d6b457a235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "! pip install -U spacy-Lookups-data"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy-Lookups-data in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy-Lookups-data) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAy-EW1pGFK",
        "outputId": "5a1c85ca-c70d-493d-deb9-362a671ca0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm "
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPLZ3OoRpSVE",
        "outputId": "1ff3a6a5-f478-4bf7-a5f2-6e3c34f6491a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZD-TBcbpSRZ",
        "outputId": "eff37ac0-12eb-462b-ebf3-153bacd2659b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz#egg=en_core_web_lg==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.3.1) (2.3.2)\n",
            "Requirement already satisfied: thinc==7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (7.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (50.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.1) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g56Mcbq6xo30"
      },
      "source": [
        "The next step is to do some preliminary steps like importing related packages and setting up tensorboard and plotter function ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGBdLqcCCK8",
        "outputId": "aeb177e0-2b79-422a-bd61-42cf00aaf2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Importing Related Packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "\n",
        "import re\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "import spacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "from  IPython import display\n",
        "\n",
        "\n",
        "result_df = pd.DataFrame(columns = ['model', 'F1_score'])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939jFOCeCCCj"
      },
      "source": [
        "# Loading Tensorboard\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Open an embedded TensorBoard viewer\n",
        "%tensorboard --logdir {logdir}/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k5AbgNRCB-Y"
      },
      "source": [
        "# Plotter Function to plot performance of models\n",
        "\n",
        "from itertools import cycle\n",
        "def plotter(history_hold, metric = 'binary_crossentropy', ylim=[0.0, 1.0]):\n",
        "  cycol = cycle('bgrcmk')\n",
        "  for name, item in history_hold.items():\n",
        "    y_train = item.history[metric]\n",
        "    y_val = item.history['val_' + metric]\n",
        "    x_train = np.arange(0,len(y_val))\n",
        "\n",
        "    c=next(cycol)\n",
        "\n",
        "    plt.plot(x_train, y_train, c+'-', label=name+'_train')\n",
        "    plt.plot(x_train, y_val, c+'--', label=name+'_val')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.xlim([1, max(plt.xlim())])\n",
        "  plt.ylim(ylim)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel(metric)\n",
        "  plt.grid(True)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXlnOSPUrF18"
      },
      "source": [
        "# Reading data and exploring related features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVp8CiXxyfcR"
      },
      "source": [
        "We use simple read_csv function to read the training as well as test data into dataframes.\n",
        "We can see from the below output that, train data has 2914 values of 5 different features while test data has 1956 values of 5 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4RM46CxCoSJ",
        "outputId": "bc3e9934-2dbb-4335-833d-7fca59984753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Reading Training and Test datasets\n",
        "#train_data = \"/content/drive/My Drive/Colab Notebooks/TweetsDataset/train.csv\"\n",
        "#test_data = \"/content/drive/My Drive/Colab Notebooks/TweetsDataset/test.csv\"\n",
        "train_data = \"/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/StanceDataset/train.csv\"\n",
        "test_data = \"/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/StanceDataset/test.csv\"\n",
        "\n",
        "traindata = pd.read_csv(train_data, engine='python')\n",
        "testdata = pd.read_csv(test_data, engine='python')\n",
        "print(traindata.shape)\n",
        "print(testdata.shape)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2914, 5)\n",
            "(1956, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8jTXRWvy6nr"
      },
      "source": [
        "The features of the dataset are : Tweet, Target, Stance, Opinion_towards and Sentiment. Out of which our main aim is to predict the Stance of a tweet if Tweet and Target is provided. So for our experiment, we dont need fetures like Opinion_towards and Sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ZArRuxrYkx",
        "outputId": "268724f1-a1be-4cd6-e776-cb37f02190df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "traindata.info()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2914 entries, 0 to 2913\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Tweet            2914 non-null   object\n",
            " 1   Target           2914 non-null   object\n",
            " 2   Stance           2914 non-null   object\n",
            " 3   Opinion Towards  2914 non-null   object\n",
            " 4   Sentiment        2914 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 114.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmlOzvB_uvps",
        "outputId": "bc6847d5-558b-4a3d-b465-282565e9694a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "testdata.info()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1956 entries, 0 to 1955\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   Tweet            1956 non-null   object\n",
            " 1   Target           1956 non-null   object\n",
            " 2   Stance           1956 non-null   object\n",
            " 3   Opinion Towards  1956 non-null   object\n",
            " 4   Sentiment        1956 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 76.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPBm7yWzYsR"
      },
      "source": [
        "We can see from the below code output that, traindata consists of tweets related to 5 different Target values namely,\n",
        "\n",
        "1.   Hillary Clinton\n",
        "2.   Feminist Movement\n",
        "3.   Legalization of abortion\n",
        "4.   Atheism\n",
        "5.   Climate Change is a Real Concern\n",
        "\n",
        "And the tweets are classified into 3 Stance values namely,\n",
        "\n",
        "1.   tweets that FAVOR the target value\n",
        "2.   Tweets which are AGAINST the target value\n",
        "3.   Tweets which are neither in FAVOR nor AGAINST (i.e. NONE)\n",
        "\n",
        "We can see the number tweets for each target value as well as number of tweets of eah Stance values described below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJY2bxGvCn-J",
        "outputId": "9ce873fc-2f07-4766-a0f1-b10515d1ee2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# We have to classify the stance of tweets according to the tweet statements as well as the target of the tweet.\n",
        "\n",
        "print(traindata['Target'].value_counts())\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(traindata['Stance'].value_counts())"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hillary Clinton                     689\n",
            "Feminist Movement                   664\n",
            "Legalization of Abortion            653\n",
            "Atheism                             513\n",
            "Climate Change is a Real Concern    395\n",
            "Name: Target, dtype: int64\n",
            "----------------------------------------------------------\n",
            "AGAINST    1395\n",
            "NONE        766\n",
            "FAVOR       753\n",
            "Name: Stance, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ZTvy53u0C2",
        "outputId": "49739c54-56d9-47c3-9e77-63c2a9b9db94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "testdata = testdata[testdata['Target'] != \"Donald Trump\"]\n",
        "print(testdata['Target'].value_counts())\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(testdata['Stance'].value_counts())"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hillary Clinton                     295\n",
            "Feminist Movement                   285\n",
            "Legalization of Abortion            280\n",
            "Atheism                             220\n",
            "Climate Change is a Real Concern    169\n",
            "Name: Target, dtype: int64\n",
            "----------------------------------------------------------\n",
            "AGAINST    715\n",
            "FAVOR      304\n",
            "NONE       230\n",
            "Name: Stance, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQUutoH90mWR"
      },
      "source": [
        "As a next task we try to explore the distribution of tweets as per their Stance values for each target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjsnLnseCn6s",
        "outputId": "19b696aa-055f-457a-98c3-5c7dfa98e9e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# The next exploration is to check the distribution of tweets of different stance values across each target.\n",
        "traindata.groupby(['Target'])['Stance'].value_counts()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target                            Stance \n",
              "Atheism                           AGAINST    304\n",
              "                                  NONE       117\n",
              "                                  FAVOR       92\n",
              "Climate Change is a Real Concern  FAVOR      212\n",
              "                                  NONE       168\n",
              "                                  AGAINST     15\n",
              "Feminist Movement                 AGAINST    328\n",
              "                                  FAVOR      210\n",
              "                                  NONE       126\n",
              "Hillary Clinton                   AGAINST    393\n",
              "                                  NONE       178\n",
              "                                  FAVOR      118\n",
              "Legalization of Abortion          AGAINST    355\n",
              "                                  NONE       177\n",
              "                                  FAVOR      121\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbjzHf9k09i9"
      },
      "source": [
        "From the above result, we can see that the number of tweets are not evenly distributed amongst each target values. For example, There are in total 1395 tweets which are of Stance AGAINST while only  753 tweets are in FAVOR with their target value.\n",
        "\n",
        "Furthermore, we can see that, in each target value, Tweets are not distributed evenly. For example, there are 393 tweets which are in AGAINST with target 'Hillary Clinton' while there are only 15 tweets which are in AGAINST of 'Climate Change is a Real Concern'.\n",
        "\n",
        "For futher better understanding we try to plot some exploration visualisations of the tweet distribution among each target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy6FdX2-y34o",
        "outputId": "9f3756f7-ca6c-4adf-cc6e-b7385127bbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Lets try to plot a graph of the above distribution to check whether there is a class imbalance issue in the dataset\n",
        "\n",
        "Target = traindata['Target'].unique().tolist()\n",
        "df = pd.DataFrame(columns=['Target', 'FAVOR', 'AGAINST', 'NONE'])\n",
        "for target in Target:\n",
        "  data = traindata[traindata['Target']==target]\n",
        "  #print(data[data['Stance']=='FAVOR'].shape[0])\n",
        "  df = df.append({'Target': target, 'FAVOR': data[data['Stance']=='FAVOR'].shape[0], 'AGAINST': data[data['Stance']=='AGAINST'].shape[0], 'NONE': data[data['Stance']=='NONE'].shape[0]}, ignore_index= True)\n",
        "df"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>FAVOR</th>\n",
              "      <th>AGAINST</th>\n",
              "      <th>NONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>118</td>\n",
              "      <td>393</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>121</td>\n",
              "      <td>355</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Atheism</td>\n",
              "      <td>92</td>\n",
              "      <td>304</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Climate Change is a Real Concern</td>\n",
              "      <td>212</td>\n",
              "      <td>15</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Feminist Movement</td>\n",
              "      <td>210</td>\n",
              "      <td>328</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Target FAVOR AGAINST NONE\n",
              "0                   Hillary Clinton   118     393  178\n",
              "1          Legalization of Abortion   121     355  177\n",
              "2                           Atheism    92     304  117\n",
              "3  Climate Change is a Real Concern   212      15  168\n",
              "4                 Feminist Movement   210     328  126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3eHwwwP_82t",
        "outputId": "0dbbc88a-2d7b-4fe9-d950-b95eb274ddff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Grouped bar graph for stance values of each target value.\n",
        "pos = list(range(len(df['FAVOR']))) \n",
        "width = 0.25 \n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "plt.bar(pos, df['FAVOR'], width, alpha=0.5, color='#FF8000', label=df['Target'][0]) \n",
        "plt.bar([p + width for p in pos], df['AGAINST'], width, alpha=0.5, color='#0080FF', label=df['Target'][1]) \n",
        "plt.bar([p + width*2 for p in pos], df['NONE'], width, alpha=0.5, color='#66FF66', label=df['Target'][2]) \n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Count of tweets')\n",
        "ax.set_xticks([p + 1.5 * width for p in pos])\n",
        "ax.set_xticklabels(df['Target'])\n",
        "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
        "plt.ylim([0, max(df['FAVOR'] + df['AGAINST'] + df['NONE'])] )\n",
        "plt.legend(['FAVOR', 'AGAINST', 'NONE'], loc='upper right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoSqqoTashRa"
      },
      "source": [
        "We can see from the above exploration that there is a large difference between number of tweets of each target value. We can also find out that there is a class imbalance problem present in the data as number of tweets have large difference between each stance for each target. For example, for target value \"Climate Change is a Real Concern\", there are only 15 tweets with Stance \"AGAINST\" it.\n",
        "\n",
        "\n",
        "So below we are using two different appraches to tackle this problem. In the first approach we are considering the whole dataset as an input to a single model and try to build a deep model to train this data. In the second approach we divide the dataset according to the target values and then try to build a model for each target value to predict its stance so there are 5 different models for 5 different target values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9O7hrXxaMGO"
      },
      "source": [
        "# Approach 1 : Building a model which takes whole data as a input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fniHrrVx5wp"
      },
      "source": [
        "The main task is to predict the Stance of a particular tweet based on the tweet content and the target it is mentioned for. \n",
        "\n",
        "So for classification purpose we concatenate the tweet statement with its corresponding target value and store it as a complete tweet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D95ZRbdanCp",
        "outputId": "7b83dc70-c3db-4553-e9b9-4e8f678b4cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# as we have to use only tweet sentences and Target as an input for detecting the Stance, we concatenate this features into a single feature \n",
        "train_data = traindata[['Tweet','Stance','Target']]\n",
        "train_data[\"Tweet\"] = train_data[\"Tweet\"] + \" \" + train_data[\"Target\"]\n",
        "train_data.shape"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpJ9ffx6RXe9"
      },
      "source": [
        "***Data Exploration***\n",
        "\n",
        "For futher deep understanding of tweet data we tried some exploration in tweets before preprocessing it. We get a better idea of which kind of preprocessing steps we need to do from it.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4b9S5nyyxSh"
      },
      "source": [
        "As a first exploration step, we need to explore the number of words and characters in tweet statements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9pgoOiManJo",
        "outputId": "3a9b55c9-88b2-4e89-961b-b4343fcd6c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Some more exloration about the tweets which may helps in preprocessing\n",
        "\n",
        "# Word count in the Tweet column \n",
        "\n",
        "train_data['Word_Count'] = train_data['Tweet'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "\n",
        "## Character Counts in Tweet column\n",
        "\n",
        "train_data['Character_Count'] = train_data['Tweet'].apply(lambda x: len(x))\n",
        "\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Character_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...             143\n",
              "1  Hillary is our best choice if we truly want to...  ...             105\n",
              "2  @TheView I think our country is ready for a fe...  ...              97\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...             140\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...              68\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g951fDh2O4W"
      },
      "source": [
        "In the next step of exploration we checked the number of stop words in the sentence as well as the average word length of the tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbOP51w3anhD",
        "outputId": "a39c83b2-bd1a-4600-da05-2b12132d30b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Calculating the average word length [calculated using formula =  (Character_Count/Word_Count)]\n",
        "\n",
        "train_data['Average_Word_length'] = train_data['Character_Count']/train_data['Word_Count']\n",
        "\n",
        "# Counting the stop words\n",
        "\n",
        "train_data['Stop_words_count'] = train_data['Tweet'].apply(lambda x: len([t for t in x.split() if t in STOP_WORDS]))\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Stop_words_count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...                3\n",
              "1  Hillary is our best choice if we truly want to...  ...                7\n",
              "2  @TheView I think our country is ready for a fe...  ...                7\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...                7\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...                5\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly0-mF12cvr"
      },
      "source": [
        "The next step is to explore the hashtags and mentions in the tweet.  We believe gashtags and mentions play an important role during prediction task. During literature survey we came to know that from hashtags we manually extract some decisions regarding the stance of that tweet.\n",
        "\n",
        "For example, tag #NoMoreReligions depicts that the tweet should be in FAVOR with target Atheism. while tag #Godswill states probability of the tweet being AGAINST the Atheism. but some tags like #atheism are ambiguous and we cannot predict Stance manually from them.\n",
        "\n",
        "For this purpose we need to know the number of Hashtags and mentions in the tweet first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikeXBs5Banwv",
        "outputId": "9ba18559-7e16-44a9-f47e-de4c80761337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "## Count HashTags -> # and mentions -> @\n",
        "\n",
        "train_data['HashTag_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.startswith(\"#\")])) \n",
        "\n",
        "train_data['Mention_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.startswith(\"@\")])) \n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... Mention_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...             1\n",
              "1  Hillary is our best choice if we truly want to...  ...             0\n",
              "2  @TheView I think our country is ready for a fe...  ...             1\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...             0\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...             1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U64xah9j3-wh"
      },
      "source": [
        "In the below step we checked the number of digits and Upper case characters in the tweet. That is because we believe, people mostly write in capital letters when they are either highly in FAVOR or in AGAINST with something."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSuEHVC5an8q",
        "outputId": "95d3ee74-1add-4396-d6ad-e52981786c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "## Checking the numeric digits present in the tweets\n",
        "\n",
        "train_data['numeric_digit_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.isdigit()])) \n",
        "\n",
        "# Checking the count of Upper Case in the tweet (Because mostly people write in capital when they are Happy or Sad)\n",
        "\n",
        "train_data['uppercase_Count'] = train_data['Tweet'].apply(lambda x : len([t for t in x.split() if t.isupper() and len(x)>3])) \n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "      <th>numeric_digit_Count</th>\n",
              "      <th>uppercase_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>19</td>\n",
              "      <td>143</td>\n",
              "      <td>7.526316</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>105</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>18</td>\n",
              "      <td>97</td>\n",
              "      <td>5.388889</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>21</td>\n",
              "      <td>140</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>11</td>\n",
              "      <td>68</td>\n",
              "      <td>6.181818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  ... uppercase_Count\n",
              "0  @tedcruz And, #HandOverTheServer she wiped cle...  ...               0\n",
              "1  Hillary is our best choice if we truly want to...  ...               0\n",
              "2  @TheView I think our country is ready for a fe...  ...               1\n",
              "3  I just gave an unhealthy amount of my hard-ear...  ...               2\n",
              "4  @PortiaABoulger Thank you for adding me to you...  ...               0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNV-2k6hrf4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Preprocessing the tweets**\n",
        "\n",
        "After some interesting exploration in Tweet column, we started some basic preprocessing. The first and very basic step is to convert the tweet into lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr-nQaDdannk",
        "outputId": "402751c3-b66f-4d55-c8df-60a9e805bdd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Converting to lower case\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: x.lower()) \n",
        "\n",
        "train_data['Tweet'].head(2)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz and, #handovertheserver she wiped cle...\n",
              "1    hillary is our best choice if we truly want to...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDra46Rl43xy"
      },
      "source": [
        "the next step is to convert contracted word into their expanded format. This step is needed as we want to seperate the words like 'don't' into 'do not' so that model can understand them clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vF9MaUganY7"
      },
      "source": [
        "# Contraction to Expandion [Meaning converting words like \"don't\" to \"do not\"]\n",
        "\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i had\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she had\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that had\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they had\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "\" n \":\"and\",\n",
        "\" u \": \"you\",\n",
        "}\n",
        "\n",
        "def con_to_ext(x):\n",
        "  if type(x) is str:\n",
        "    for key in contractions:\n",
        "      value = contractions[key]\n",
        "      x = x.replace(key, value)\n",
        "    return x\n",
        "  else:\n",
        "    return x"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhfNu43aanGQ",
        "outputId": "59fe5532-05cb-41cc-b3d5-405505c033e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: con_to_ext(x))\n",
        "train_data['Tweet'].head(5)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz and, #handovertheserver she wiped cle...\n",
              "1    hillary is our best choice if we truly want to...\n",
              "2    @theview i think our country is ready for a fe...\n",
              "3    i just gave an unhealthy amount of my hard-ear...\n",
              "4    @portiaaboulger thank you for adding me to you...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfGLSMgE6lBE"
      },
      "source": [
        "The next step of preprocessing we done is to remove the email ids from the tweets as they may contain personal data in alphanumeric format which does not make sense towards Stance detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h1KhlT_am_J"
      },
      "source": [
        "## Count and remove emails from the tweet\n",
        "import re\n",
        "train_data['email'] = train_data['Tweet'].apply(lambda x: re.findall(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)',x))"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CTbaaJjKQY",
        "outputId": "ba7545d1-0088-4ff3-a20f-597dc94567a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Counting the number of email present in the dataset \n",
        "\n",
        "train_data['email_count'] = train_data['email'].apply(lambda x: len(x))\n",
        "\n",
        "# Checking if the emails are greater that 1\n",
        "\n",
        "train_data[train_data['email_count']>0]"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Character_Count</th>\n",
              "      <th>Average_Word_length</th>\n",
              "      <th>Stop_words_count</th>\n",
              "      <th>HashTag_Count</th>\n",
              "      <th>Mention_Count</th>\n",
              "      <th>numeric_digit_Count</th>\n",
              "      <th>uppercase_Count</th>\n",
              "      <th>email</th>\n",
              "      <th>email_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>(2/2) 300 words and be sent to climateconferen...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Climate Change is a Real Concern</td>\n",
              "      <td>17</td>\n",
              "      <td>142</td>\n",
              "      <td>8.352941</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[climateconference2015@gmail.com]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2691</th>\n",
              "      <td>worldwide r.e. agents! - support a prolife gro...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>16</td>\n",
              "      <td>129</td>\n",
              "      <td>8.062500</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[proliferealestate@yahoo.com]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Tweet  ... email_count\n",
              "676   (2/2) 300 words and be sent to climateconferen...  ...           1\n",
              "2691  worldwide r.e. agents! - support a prolife gro...  ...           1\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtBk_1vyjJ8D"
      },
      "source": [
        "## Removing the emails from the Tweet column.\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: re.sub(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)','',x))"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptWUIYd7xys"
      },
      "source": [
        "THe next step of preprocessing is to remove special characters and punctuations from the tweets. we removed all the special characters excluding # and @ from the tweets.\n",
        "\n",
        "After that, we removed extra white spaces from tweets. and removed words which may written in Accented characters.\n",
        "\n",
        "The last step is to remove stop words from the tweet statements.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TolLbs8jJbE",
        "outputId": "322a0dd2-f806-411f-c33c-ba822fdcd733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "## Removing Special characters and punctuations\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: re.sub('[^A-Za-z0-9#@]+',' ',x))\n",
        "\n",
        "## Remove the multiple(extra) spaces\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "## Remove the Accented characters (e.g. àÿüûâ)\n",
        "import unicodedata\n",
        "\n",
        "def remove_accent(x):\n",
        "  x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "  return x\n",
        "\n",
        "## Applying on tweets\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: remove_accent(x))\n",
        "\n",
        "### Removing the stop words\n",
        "\n",
        "train_data['Tweet'] = train_data['Tweet'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
        "\n",
        "\n",
        "train_data['Tweet'].head(5)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @tedcruz #handovertheserver wiped clean 30k de...\n",
              "1    hillary best choice truly want continue progre...\n",
              "2    @theview think country ready female pres hilla...\n",
              "3    gave unhealthy hard earned money away big gov ...\n",
              "4    @portiaaboulger thank adding list hillary clinton\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJkiNwVr9Nw0"
      },
      "source": [
        "The next step is to tokenize (encoding) the preprocessed tweet data and then add padding to the data to make each tweet statement of the same length.\n",
        "\n",
        "for that we copied the Tweet data into a list named 'text'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zlq3tqta-Et",
        "outputId": "3707e397-12ab-488d-bc80-d1c525e2dd6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#train_data['Tw'] = train_data['Tweet']\n",
        "#####\n",
        "text = train_data['Tweet'].tolist()\n",
        "text[:3]"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@tedcruz #handovertheserver wiped clean 30k deleted emails explains dereliction duty lies #benghazi etc #tcot hillary clinton',\n",
              " 'hillary best choice truly want continue progressive nation #ohio hillary clinton',\n",
              " '@theview think country ready female pres hillary hillary clinton']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0TE5tZAa-tH",
        "outputId": "c1b053cf-a286-49b5-953d-db18c719278c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#####\n",
        "y = train_data['Stance']\n",
        "y = pd.get_dummies(y).values\n",
        "y.shape"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2914, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex9V1b04a-qt",
        "outputId": "45bec769-a4cf-44da-b24a-64b4036ce987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "\n",
        "### Calculating the vocabulary size\n",
        "vocab_size = len(token.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIsieoxk-RXy"
      },
      "source": [
        "we used 50 as a max length for the padding to make each sentence of max length 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpc2mg7za-B5",
        "outputId": "71c914b1-e4a2-4f22-eaf4-7a99aa8f81a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "## Encoding the text\n",
        "encoded_text = token.texts_to_sequences(text)\n",
        "print(encoded_text[:3])\n",
        "\n",
        "## By default prepadding is done\n",
        "\n",
        "sentence_max_length = 50\n",
        "X = pad_sequences(encoded_text, maxlen=sentence_max_length)\n",
        "print(X.shape)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[694, 3155, 3156, 1299, 3157, 819, 124, 1859, 3158, 1022, 130, 151, 435, 51, 2, 5], [2, 53, 68, 436, 24, 311, 1023, 173, 1024, 2, 5], [3159, 34, 99, 152, 153, 1860, 2, 2, 5]]\n",
            "(2914, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pTtyMLI_6TC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Word Embedding and Transfer Learning**\n",
        "\n",
        "As we can see from the above that we have very small dataset only with 2914 data points of 5 target values. We can see from above exploration that the data also has class imbalance problem so we are using a pretrained vector weights to use better representation of the vocabulary we have in our data set. \n",
        "\n",
        "We are using Glove Twitter 100 dimensional pretrained vector present on https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "This pretrained vector is present in various dimentions as 50d, 100d and 200d but we are simply using 100d vector for our task.\n",
        "we make a glove vector dictionary to save all the words from pretrained vector file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JL5Q9xuhRT5"
      },
      "source": [
        "##### Glove Vector\n",
        "# e.g. hello -0.11 0.23 0.333 0.54 0.65\n",
        "glove_vectors = dict()\n",
        "#file = open('/content/drive/My Drive/Colab Notebooks/TweetsDataset/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "file = open('/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "glove_vectors = dict()\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  features = np.asarray(values[1:])\n",
        "  glove_vectors[word] = features\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5wXUEA-CAQ2"
      },
      "source": [
        "We can see from the below code that the Glove vector has almost 1.5 million words present with dimension shape of 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVGwo3zvhRRn",
        "outputId": "3c24a594-5314-4716-ad79-265d6d03307e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "### Prints the length of keys in glove vector dictionary\n",
        "print(len(glove_vectors.keys()))\n",
        "\n",
        "#### displaying the shape of the glove vector just for testing purpose\n",
        "print(glove_vectors.get('to').shape)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvz2WuTpCbLf"
      },
      "source": [
        "The next step is to create an Embedded Matrix by mapping each word in our vocabulary with the same word in the Glove Vector.\n",
        "The words which are not in the Glove vector are added to the list named 'Not_words'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGB6D7DphRMG",
        "outputId": "0b81b281-679a-4fc2-c94e-dea88f7d059e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((vocab_size , 100))\n",
        "Not_words = list()\n",
        "for word, i in token.word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "    else:\n",
        "      #print(word) # Printing the misspelled words\n",
        "      Not_words.append(word)\n",
        "\n",
        "print(\"Embedding Matrix size: \", E_T.size)\n",
        "print(\"Words which are not in Embedding Matrix: \", len(Not_words))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Matrix size:  902100\n",
            "Words which are not in Embedding Matrix:  2449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brmZISQuD5vs"
      },
      "source": [
        "The next step is to split the data into Training and Validation datasets. We are using simple train_test_split() function from sklearn to split the data with split size of 0.2 which mean 80% data is used for training the model while remaining 20% data is used for validation purpose to check how well our model is generalizing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMlOHDfIhRJx",
        "outputId": "f7920bc0-50b7-4238-e479-9cb8e1d84244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_val shape: \", X_test.shape)\n",
        "print(\"y_val shape: \", y_test.shape)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (2331, 50)\n",
            "y_train shape:  (2331, 3)\n",
            "X_val shape:  (583, 50)\n",
            "y_val shape:  (583, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNGd_W2lEYNy"
      },
      "source": [
        "We can see from the above code that, 2331 records are used for model training purpose while 583 records are used for validation of the model.\n",
        "\n",
        "---\n",
        " \n",
        "In the next code cell, we created a baseline model with Transfer Learning layer. \n",
        "\n",
        "The model architechture is like encoded input is fed to the Glove pretrained vector to create an Embedding Layer weights. We create an Embedding Layer with the weights generated above and it is our first layer of the model. Output of this layer is given to the LSTM layer with 32 memory units which has dropout rate of 0.5 and recurrent_dropout rate of 0.25. Output of this layer is again passed through the dropout layer of 0.6 value. The output of this dropout layer is fed to the ReLU dense layer of 64 unit for the non-linear activation. This output is again passed though the dropuout layer of 0.6 value and finally fed to the Softmax activation layer with 3 output units which predict the Stance as either 'FAVOR', 'AGAINST' or 'NONE'.\n",
        "\n",
        "We are using 'categorical_crossentropy' as a error metric and 'Categorical_Accuracy' as a performance metric while compiling the model. We have used basic 'adam' optimizer for the training purpose.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBywrek8hRGp"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        " \n",
        "def create_model(embedding_layer):\n",
        "\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(embedding_layer)\n",
        "  model_glove.add(LSTM(units=32, dropout=0.5, recurrent_dropout= 0.25))\n",
        "  #model_glove.add(LSTM(units=64, kernel_regularizer=regularizers.l2(0.01)))\n",
        "  model_glove.add(Dropout(0.6))\n",
        "  model_glove.add(Dense(64, activation='relu'))\n",
        "  model_glove.add(Dropout(0.4))\n",
        "  model_glove.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  #opt= tf.keras.optimizers.SGD(learning_rate= 0.02, momentum=0.6)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model_glove  "
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YbmJtWvKRO0"
      },
      "source": [
        "We dont train the embedding layer as we are using pre-trained vector weights in our embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Matbsx_6hREN",
        "outputId": "faaf4113-a7c0-451f-da06-9ffff90c3c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "vector_size = 100\n",
        "embedding_layer = Embedding( vocab_size,\n",
        "                     vector_size,\n",
        "                     input_length=50,\n",
        "                     weights=[E_T],\n",
        "                     trainable=False)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 50, 100)           902100    \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 921,431\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 902,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__47i84wwctc"
      },
      "source": [
        "def get_callbacks(name):\n",
        "  return [\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=1),\n",
        "  ]"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVt3nWn7Ke_G"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKScRAqrhRBB",
        "outputId": "3d6c386c-02ee-4e31-c872-612baa5b0474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#from sklearn.model_selection import KFold\n",
        "#num_folds = 3\n",
        "#input = np.concatenate((X_train, X_test), axis= 0)\n",
        "#target = np.concatenate((y_train, y_test), axis= 0)\n",
        "\n",
        "#kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "#K = 1\n",
        "#for train, test in kfold.split(input, target):\n",
        "#    print(\"fold number: \", K)\n",
        "#    m_histories = {}\n",
        "#    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=64, epochs=50, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "#    K = K+1\n",
        "\n",
        "m_histories = {}\n",
        "m_histories['with_TL'] = model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/37 [>.............................] - ETA: 11s - loss: 1.0927WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0852s vs `on_train_batch_end` time: 0.5638s). Check your callbacks.\n",
            "37/37 [==============================] - 4s 101ms/step - loss: 1.0756 - val_loss: 1.0224\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 1.0339 - val_loss: 1.0031\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 1.0294 - val_loss: 0.9934\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 1.0087 - val_loss: 0.9803\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 1.0094 - val_loss: 0.9695\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9888 - val_loss: 0.9572\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.9778 - val_loss: 0.9453\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9638 - val_loss: 0.9363\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9651 - val_loss: 0.9294\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.9509 - val_loss: 0.9393\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9392 - val_loss: 0.9203\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9480 - val_loss: 0.9155\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9441 - val_loss: 0.9136\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9265 - val_loss: 0.9134\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9169 - val_loss: 0.9105\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.9182 - val_loss: 0.9074\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.9281 - val_loss: 0.9060\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.9122 - val_loss: 0.8999\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9049 - val_loss: 0.9034\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.9036 - val_loss: 0.8969\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.9007 - val_loss: 0.8962\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8920 - val_loss: 0.8878\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.8897 - val_loss: 0.8874\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8933 - val_loss: 0.8885\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8896 - val_loss: 0.8804\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8747 - val_loss: 0.8734\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8683 - val_loss: 0.8764\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8707 - val_loss: 0.8705\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8522 - val_loss: 0.8686\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.8588 - val_loss: 0.8704\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8507 - val_loss: 0.8693\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8596 - val_loss: 0.8623\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8473 - val_loss: 0.8688\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8281 - val_loss: 0.8695\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8439 - val_loss: 0.8535\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8329 - val_loss: 0.8585\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.8249 - val_loss: 0.8610\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8219 - val_loss: 0.8547\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.8119 - val_loss: 0.8687\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.8021 - val_loss: 0.8687\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.8054 - val_loss: 0.8566\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 3s 76ms/step - loss: 0.7989 - val_loss: 0.8599\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8047 - val_loss: 0.8596\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.7994 - val_loss: 0.8591\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7874 - val_loss: 0.8569\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7730 - val_loss: 0.8745\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 0.8004 - val_loss: 0.8489\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7857 - val_loss: 0.8604\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 0.7758 - val_loss: 0.8810\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 0.7684 - val_loss: 0.8657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeDae0NKpDs9",
        "outputId": "bd48987f-5878-405a-c732-66bbcb79eec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "#multilabel_confusion_matrix(rounded_labels, y_pred)\n",
        "\n",
        "def preprocessing(data):\n",
        "   data = data[['Tweet','Stance','Target']]\n",
        "   data[\"Tweet\"] = data[\"Tweet\"] + \" \" +data[\"Target\"]\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: x.lower()) \n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: con_to_ext(x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: re.sub(r'([-a-zA-Z0-9._-]+@[-a-zA-Z0-9._-]+\\.[-a-zA-Z0-9_-]+)','',x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: re.sub('[^A-Za-z0-9#@]+',' ',x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: remove_accent(x))\n",
        "   data['Tweet'] = data['Tweet'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\n",
        "   text = data['Tweet'].tolist()\n",
        "   return text\n",
        "\n",
        "text = preprocessing(testdata)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMStB_Bpyi05",
        "outputId": "3d03a09e-d548-4300-b309-e0e8554d93b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "y = testdata['Stance']\n",
        "y = pd.get_dummies(y).values\n",
        "y.shape"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1249, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoZVHlcczOjg"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(text)\n",
        "encoded_text = token.texts_to_sequences(text)\n",
        "X = pad_sequences(encoded_text, maxlen=sentence_max_length)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_s2rLpfzpDu"
      },
      "source": [
        "y_pred_test = model.predict_classes(X) "
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye1vhxBKzzjz",
        "outputId": "2e40351c-1f68-4f68-fdb2-c67de63c03c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = np.argmax(y, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(y_true, y_pred_test,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach1_All_data_model', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5222921426954421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmcvYG6GaZAp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Approach 2 : Building separate model for each target value. i.e. 5 models for 5 different targets in training data\n",
        "\n",
        "\n",
        "\n",
        "In this approach, we split the whole dataset into 5 subsets each for one Target value and then construct model for each target to predict if the tweet is in FAVOR of that target or AGAINST that target or NONE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeMLkxwkXkZS"
      },
      "source": [
        "## We are dividing the whole training data into subsets according to the target subject value.\n",
        "\n",
        "traindata_HC = traindata[traindata['Target'] == \"Hillary Clinton\"]\n",
        "testdata_HC = testdata[testdata['Target'] == \"Hillary Clinton\"]\n",
        "traindata_AB = traindata[traindata['Target'] == \"Legalization of Abortion\"]\n",
        "testdata_AB = testdata[testdata['Target'] == \"Legalization of Abortion\"]\n",
        "traindata_AT = traindata[traindata['Target'] == \"Atheism\"]\n",
        "testdata_AT = testdata[testdata['Target'] == \"Atheism\"]\n",
        "traindata_CC = traindata[traindata['Target'] == \"Climate Change is a Real Concern\"]\n",
        "testdata_CC = testdata[testdata['Target'] == \"Climate Change is a Real Concern\"]\n",
        "traindata_FM = traindata[traindata['Target'] == \"Feminist Movement\"]\n",
        "testdata_FM = testdata[testdata['Target'] == \"Feminist Movement\"]"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYUy_g85O6Kf"
      },
      "source": [
        "From the Approach 1, we now knew the exact preprocessing steps required for the tweets. and hence we used minimum required steps of preprocessing on each subset of training data. \n",
        "\n",
        "We have created one method to preprocess the data provided. This preprocessing involves \n",
        "1. concatenating Tweet and Targets\n",
        "2. converting text into Lowercase\n",
        "3. removing some bad symbols like brackets and other alphanumeric characters except # and @\n",
        "4. We will apply this method on each dataset created above as a preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoz-Yq9tXksi"
      },
      "source": [
        "## We are doing some pre-processing steps prior modelling \n",
        "## 1. concatenating Tweet and Targets\n",
        "## 2. converting text into Lowercase\n",
        "## 3. removing some bad symbols like brackets and other alphanumeric characters except # and @\n",
        "## 4. We will apply this method on each dataset created above as a preprocessing data\n",
        "\n",
        "def TextPreprocessing(traindata):\n",
        "  traindata = traindata.reset_index(drop= True)\n",
        "  REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;]')\n",
        "  BAD_SYMBOLS_RE = re.compile('[^a-z #@]')\n",
        "  Tweet_Lines = list()\n",
        "  Tweets = list()\n",
        "  tknzr = TweetTokenizer()\n",
        "\n",
        "  def clean_text(text):\n",
        "      text = text.lower() # lowercase text\n",
        "      text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "      text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "      text = ''.join(word for word in text.split() if word not in stopwords.words()) # remove stopwords from text\n",
        "      return text\n",
        "\n",
        "  traindata['Tweet'] = traindata.Tweet + ' ' + traindata.Target\n",
        "  lines = traindata['Tweet'].values.tolist()\n",
        "  for line in lines:\n",
        "      tokens = tknzr.tokenize(line)\n",
        "      Tweet_Lines = list()\n",
        "      for token in tokens:\n",
        "        token = clean_text(token)\n",
        "        if token != '' :\n",
        "          Tweet_Lines.append(token)\n",
        "      Tweets.append(Tweet_Lines)\n",
        "          \n",
        "  return Tweets"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3Sag7uXkfU"
      },
      "source": [
        "Tweets_HC = TextPreprocessing(traindata_HC)\n",
        "Tweets_AB = TextPreprocessing(traindata_AB)\n",
        "Tweets_AT = TextPreprocessing(traindata_AT)\n",
        "Tweets_CC = TextPreprocessing(traindata_CC)\n",
        "Tweets_FM = TextPreprocessing(traindata_FM)\n",
        "\n",
        "Test_Tweets_HC = TextPreprocessing(testdata_HC)\n",
        "Test_Tweets_AB = TextPreprocessing(testdata_AB)\n",
        "Test_Tweets_AT = TextPreprocessing(testdata_AT)\n",
        "Test_Tweets_CC = TextPreprocessing(testdata_CC)\n",
        "Test_Tweets_FM = TextPreprocessing(testdata_FM)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5nhHtkuPam7"
      },
      "source": [
        "We have to do similar tokenizing and padding task for each of the 5 datasets so we created a generic method which is used to do tokenization and padding.\n",
        "\n",
        "We have used 40 as a max length while padding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKs7MVplfJW-"
      },
      "source": [
        "## Tokenizing and padding the Tweets data to make it suitable for further modelling.\n",
        "\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LENGTH = 40\n",
        "embedding_dim = 100\n",
        "\n",
        "def Padding(Tweets):  \n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(Tweets)\n",
        "  word_index = tokenizer.word_index\n",
        "  print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "  X = tokenizer.texts_to_sequences(Tweets)\n",
        "  X = pad_sequences(X, maxlen=MAX_LENGTH, padding= 'post')\n",
        "  print('Shape of data tensor:', X.shape)\n",
        "\n",
        "  return X, word_index"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOncA-sP_iF"
      },
      "source": [
        "The next step is to split the data for training and validation. We have simply used train_test_split() function from sklearn to split the data with provided split size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLD2-gXytvLO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split(X, Y, split_size):\n",
        "    X_train, X_Val, Y_train, Y_Val = train_test_split(X, Y, test_size= split_size, random_state = 42)\n",
        "    return X_train, X_Val, Y_train, Y_Val"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11z4YpgTu160"
      },
      "source": [
        "def get_callbacks(name):\n",
        "  return [\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=1),\n",
        "  ]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWsGX69fQTjF"
      },
      "source": [
        "**Baseline Model**\n",
        "\n",
        "In the next code cell, we created a baseline model with Transfer Learning layer. \n",
        "\n",
        "The model architechture is like encoded input is fed to the Glove pretrained vector to create an Embedding Layer weights. We create an Embedding Layer with the weights generated above and it is our first layer of the model. Output of this layer is given to the LSTM layer with 32 memory units which has dropout rate of 0.5 and recurrent_dropout rate of 0.25. Output of this layer is again passed through the dropout layer of 0.6 value. The output of this dropout layer is fed to the ReLU dense layer of 64 unit for the non-linear activation. This output is again passed though the dropuout layer of 0.6 value and finally fed to the Softmax activation layer with 3 output units which predict the Stance as either 'FAVOR', 'AGAINST' or 'NONE'.\n",
        "\n",
        "We are using 'categorical_crossentropy' as a error metric and 'Categorical_Accuracy' as a performance metric while compiling the model. We have used basic 'adam' optimizer for the training purpose.\n",
        "\n",
        "Here we are checking the model with and without transfer learning for each of 5 target related models hence we have created a method which will construct a model as per the provided embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbVybWPDu3f5"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "\n",
        "def create_model(embedding_layer):\n",
        "\n",
        "  model_glove = Sequential()\n",
        "  model_glove.add(embedding_layer)\n",
        "  model_glove.add(LSTM(units=32, dropout= 0.5, recurrent_dropout= 0.25, kernel_regularizer=regularizers.l2(0.001)))\n",
        "  #model_glove.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, recurrent_dropout= 0.25)))\n",
        "  #model_glove.add(LSTM(units=64, kernel_regularizer=regularizers.l2(0.01)))\n",
        "  model_glove.add(Dropout(0.4))\n",
        "  model_glove.add(Dense(64, activation='relu'))\n",
        "  model_glove.add(Dropout(0.3))\n",
        "  model_glove.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  #opt= tf.keras.optimizers.SGD(learning_rate= 0.015, momentum= 0.9)\n",
        "  model_glove.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model_glove  "
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJlSroDPuctp"
      },
      "source": [
        "**Word Embedding and Transfer Learning**\n",
        "\n",
        "As we can see from the above that we have very small dataset only with 2914 data points of 5 target values. We can see from above exploration that the data also has class imbalance problem so we are using a pretrained vector weights to use better representation of the vocabulary we have in our data set. \n",
        "\n",
        "We are using Glove Twitter 100 dimensional pretrained vector present on https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "This pretrained vector is present in various dimentions as 50d, 100d and 200d but we are simply using 100d vector for our task.\n",
        "we make a glove vector dictionary to save all the words from pretrained vector file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-rz1hPOuWuF"
      },
      "source": [
        "#file = open('/content/drive/My Drive/Colab Notebooks/TweetsDataset/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "file = open('/content/drive/My Drive/ColabNotebooks/DeepLearningLabs/Assignment2/glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "glove_vectors = dict()\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  features = np.asarray(values[1:])\n",
        "  glove_vectors[word] = features\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh2kj1jcsSBM"
      },
      "source": [
        "# **1. modelling for tweets related to Target : Hillary Clinton**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElHeoAt3RK1x"
      },
      "source": [
        "First we check the preprocessed tweet data for target Hillary Clinton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbUZD-AE0JAI",
        "outputId": "d8943843-b711-4d1e-efb7-fb10cefede0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_HC[:1]"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['@tedcruz',\n",
              "  '#handovertheserver',\n",
              "  'wiped',\n",
              "  'clean',\n",
              "  'deleted',\n",
              "  'emails',\n",
              "  'explains',\n",
              "  'dereliction',\n",
              "  'duty',\n",
              "  'lies',\n",
              "  '#benghazi',\n",
              "  'etc',\n",
              "  '#tcot',\n",
              "  'hillary',\n",
              "  'clinton']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxRy1JBoRScS"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXrlCw2QfJPm",
        "outputId": "d1405a98-9a9f-4775-a0ee-76a8171cac97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_HC)\n",
        "Y = pd.get_dummies(traindata_HC['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2966 unique tokens.\n",
            "Shape of data tensor: (689, 40)\n",
            "Shape of label tensor: (689, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x275qrnrjtXA"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiT6k6-ZDvJf",
        "outputId": "b2c97db7-9c1d-4859-a7af-f8f396095cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (551, 40)\n",
            "Y train shape:  (551, 3)\n",
            "X Val shape:  (138, 40)\n",
            "Y Val shape:  (138, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDYjJn7mv5W6"
      },
      "source": [
        "**Model without Transfer Learning**\n",
        "\n",
        "First we try to model without transfer learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hirEyLi6wUZ6",
        "outputId": "29d3f77f-daec-4a3f-d96b-d01397b09f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 40, 100)           296700    \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 316,031\n",
            "Trainable params: 316,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMm66YgkzHT"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQq9_JExwxag",
        "outputId": "717acea8-2472-4b75-9474-73e5c6db0ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/15 [===>..........................] - ETA: 3s - loss: 1.1949WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0699s vs `on_train_batch_end` time: 0.5170s). Check your callbacks.\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 1.1348 - val_loss: 1.0548\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.0821 - val_loss: 1.0413\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 1.0616 - val_loss: 1.0443\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 1.0478 - val_loss: 1.0146\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 1.0303 - val_loss: 1.0083\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 1.0308 - val_loss: 1.0086\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.0193 - val_loss: 0.9983\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 1.0182 - val_loss: 0.9923\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 66ms/step - loss: 1.0160 - val_loss: 0.9963\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 79ms/step - loss: 1.0082 - val_loss: 0.9880\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 81ms/step - loss: 1.0096 - val_loss: 0.9904\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 82ms/step - loss: 0.9937 - val_loss: 0.9835\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 83ms/step - loss: 0.9982 - val_loss: 0.9832\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 84ms/step - loss: 0.9932 - val_loss: 0.9796\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 93ms/step - loss: 0.9965 - val_loss: 0.9779\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 94ms/step - loss: 0.9978 - val_loss: 0.9794\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 2s 100ms/step - loss: 0.9802 - val_loss: 0.9785\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 70ms/step - loss: 0.9902 - val_loss: 0.9817\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.9852 - val_loss: 0.9757\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 76ms/step - loss: 0.9438 - val_loss: 0.9178\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/15 [===>..........................] - ETA: 1s - loss: 0.7634WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0754s vs `on_train_batch_end` time: 0.1706s). Check your callbacks.\n",
            "15/15 [==============================] - 1s 97ms/step - loss: 0.8125 - val_loss: 0.6266\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 86ms/step - loss: 0.7287 - val_loss: 0.5696\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 84ms/step - loss: 0.7675 - val_loss: 0.5874\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 85ms/step - loss: 0.6270 - val_loss: 0.5896\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 84ms/step - loss: 0.5264 - val_loss: 0.5312\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 81ms/step - loss: 0.4836 - val_loss: 0.5335\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 79ms/step - loss: 0.4672 - val_loss: 0.5256\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 71ms/step - loss: 0.4536 - val_loss: 0.5326\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 0.4742 - val_loss: 0.5346\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.4330 - val_loss: 0.5282\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.4555 - val_loss: 0.6079\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 0.4238 - val_loss: 0.6045\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.4104 - val_loss: 0.5911\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.4025 - val_loss: 0.5898\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.4057 - val_loss: 0.5831\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.3867 - val_loss: 0.5847\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.3687 - val_loss: 0.5928\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.3727 - val_loss: 0.5723\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.3917 - val_loss: 0.5273\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.3564 - val_loss: 0.5292\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "15/15 [==============================] - 1s 68ms/step - loss: 0.5351 - val_loss: 0.3423\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 0.4297 - val_loss: 0.3653\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 62ms/step - loss: 0.3910 - val_loss: 0.3466\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.4275 - val_loss: 0.3643\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.5173 - val_loss: 0.3785\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.4818 - val_loss: 0.3956\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.4794 - val_loss: 0.4068\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.4736 - val_loss: 0.4020\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 1s 64ms/step - loss: 0.4847 - val_loss: 0.3876\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5195 - val_loss: 0.3931\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 1s 65ms/step - loss: 0.5082 - val_loss: 0.4148\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5004 - val_loss: 0.4310\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.5145 - val_loss: 0.4480\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 1s 63ms/step - loss: 0.4855 - val_loss: 0.4367\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.4735 - val_loss: 0.4427\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.4711 - val_loss: 0.4502\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.5165 - val_loss: 0.4889\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.4892 - val_loss: 0.5051\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 0.5100 - val_loss: 0.5328\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.5178 - val_loss: 0.5388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD5NMWk0lOWL"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ObT2XJfxELR",
        "outputId": "11ced1cd-7c92-4a71-837e-e02af2f01b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUvG0BXKM3ch",
        "outputId": "bf5ae590-d664-4484-9429-e5a9b932f672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_HC)\n",
        "Y_true = pd.get_dummies(testdata_HC['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1600 unique tokens.\n",
            "Shape of data tensor: (295, 40)\n",
            "Shape of label tensor: (295, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVJAH2oeM3IV",
        "outputId": "8f289861-fb0c-4bdb-f8ad-175fa51d706f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_HC_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.462292089989901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5dx-eGBl3mr"
      },
      "source": [
        "**Model with Transfer Learning**\n",
        "\n",
        "we try to model with transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_u1IEZrmSlg",
        "outputId": "82d4f20f-3576-4fd0-b911-0eb954a33ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296700"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYFvAnzHydbj",
        "outputId": "9b9a5f77-8fc7-4f67-c357-5c621a914d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model = create_model(embedding_layer_TL)\n",
        "print(model.summary())"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 40, 100)           296700    \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 316,031\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 296,700\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48l4e_FTyxVr",
        "outputId": "95387a1a-2537-4d56-a602-0df733fa5172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/18 [==>...........................] - ETA: 4s - loss: 1.2087WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0587s vs `on_train_batch_end` time: 0.4791s). Check your callbacks.\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 1.1767 - val_loss: 1.1327\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 1.0900 - val_loss: 1.0447\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 1.0318 - val_loss: 1.0268\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 1.0122 - val_loss: 1.0128\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.9985 - val_loss: 0.9999\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9881 - val_loss: 0.9790\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.9586 - val_loss: 0.9762\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.9543 - val_loss: 0.9628\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9153 - val_loss: 1.0096\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9426 - val_loss: 0.9478\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.9108 - val_loss: 0.9805\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8961 - val_loss: 0.9445\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8935 - val_loss: 0.9523\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8998 - val_loss: 0.9524\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8679 - val_loss: 0.9582\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8847 - val_loss: 0.9342\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8747 - val_loss: 0.9443\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8755 - val_loss: 0.9544\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8757 - val_loss: 0.9584\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.8805 - val_loss: 0.9477\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8710 - val_loss: 0.9607\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.8501 - val_loss: 0.9535\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8502 - val_loss: 0.9222\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8582 - val_loss: 0.9235\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8519 - val_loss: 0.9388\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8395 - val_loss: 0.9667\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8504 - val_loss: 0.9307\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 1s 51ms/step - loss: 0.8269 - val_loss: 0.9786\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8665 - val_loss: 0.9096\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7921 - val_loss: 0.9625\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8149 - val_loss: 0.9633\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.8134 - val_loss: 0.9434\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.8201 - val_loss: 0.9276\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7814 - val_loss: 0.9906\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.8229 - val_loss: 0.9583\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.8071 - val_loss: 0.9839\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7944 - val_loss: 0.9121\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7769 - val_loss: 0.9544\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7818 - val_loss: 0.9490\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7587 - val_loss: 0.9386\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7625 - val_loss: 0.9291\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7391 - val_loss: 0.9239\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7731 - val_loss: 0.9959\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7504 - val_loss: 1.0216\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.7610 - val_loss: 0.9691\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7301 - val_loss: 1.0112\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7442 - val_loss: 1.0290\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7460 - val_loss: 1.0157\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 1s 49ms/step - loss: 0.7210 - val_loss: 1.0417\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.7445 - val_loss: 0.9338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08-b6AZBy9lr",
        "outputId": "a67a77f3-4b50-437b-f782-e519d81e4b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc5615ZNG_ih"
      },
      "source": [
        "Y_pred = model.predict_classes(X_test)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnmM3LbiHgiW",
        "outputId": "7b3fabd9-b56c-4cc5-e2e3-75a9bb84de81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_HC_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4097785574763821"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23Vl8jp3LtE"
      },
      "source": [
        "# **2. modelling for tweets related to Target : Legalization of Abortion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cd5swpWlmun"
      },
      "source": [
        "First we check the preprocessed tweet data for target Legalization of Abortion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4tvC3aA3YxA",
        "outputId": "e0f6cf80-4a9a-4290-a92c-7fd081c6083c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_AB[:1]"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['laid',\n",
              "  'law',\n",
              "  'abortion',\n",
              "  'bioethics',\n",
              "  'class',\n",
              "  '#catholic',\n",
              "  'legalization',\n",
              "  'abortion']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZrhJeDOl10M"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbKeC8g63k2C",
        "outputId": "36fa720a-9e3d-482f-fc8f-cd516fe5a8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_AB)\n",
        "Y = pd.get_dummies(traindata_AB['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2771 unique tokens.\n",
            "Shape of data tensor: (653, 40)\n",
            "Shape of label tensor: (653, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh6dZVAQl8mY"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA497Brc3kjS",
        "outputId": "418c92f3-600b-4544-b0a9-05b212d132b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (522, 40)\n",
            "Y train shape:  (522, 3)\n",
            "X Val shape:  (131, 40)\n",
            "Y Val shape:  (131, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzGMRiWo3xyD"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnpgWy0b3kYv",
        "outputId": "40e8eea4-97c6-4dd2-8925-b9c3576718bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 40, 100)           277200    \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 296,531\n",
            "Trainable params: 296,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TmwyBrOmEAk"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DApipPKH39Ve",
        "outputId": "f31fea7b-80c4-4d1a-e361-7e4b9bcac5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 3s - loss: 1.2158WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0718s vs `on_train_batch_end` time: 0.5157s). Check your callbacks.\n",
            "14/14 [==============================] - 2s 123ms/step - loss: 1.1834 - val_loss: 1.1241\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.1172 - val_loss: 1.0506\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0853 - val_loss: 1.0410\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0648 - val_loss: 1.0319\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.0621 - val_loss: 1.0194\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0630 - val_loss: 1.0212\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0462 - val_loss: 1.0103\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.0488 - val_loss: 1.0054\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0398 - val_loss: 1.0009\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.0227 - val_loss: 0.9971\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 1.0302 - val_loss: 0.9930\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.8866 - val_loss: 0.8852\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.5867 - val_loss: 1.4225\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5199 - val_loss: 1.3478\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4891 - val_loss: 1.4189\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.4492 - val_loss: 1.4652\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5191 - val_loss: 1.3437\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.4390 - val_loss: 1.3375\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.4436 - val_loss: 1.9341\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.5350 - val_loss: 1.7273\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 1s - loss: 1.3258WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0595s vs `on_train_batch_end` time: 0.1099s). Check your callbacks.\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.9908 - val_loss: 0.6620\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8278 - val_loss: 0.6602\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.8404 - val_loss: 0.6475\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8141 - val_loss: 0.6970\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8670 - val_loss: 0.8057\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.8317 - val_loss: 0.7149\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.8373 - val_loss: 0.6883\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8225 - val_loss: 0.6674\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.8380 - val_loss: 0.6480\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8537 - val_loss: 0.6041\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.8683 - val_loss: 0.6236\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.7890 - val_loss: 0.6576\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7894 - val_loss: 0.6441\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7682 - val_loss: 0.6339\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7520 - val_loss: 0.6327\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7387 - val_loss: 0.6286\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7427 - val_loss: 0.6117\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7206 - val_loss: 0.6222\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7173 - val_loss: 0.6213\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.6953 - val_loss: 0.6172\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "14/14 [==============================] - 1s 67ms/step - loss: 0.6827 - val_loss: 0.5376\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.6954 - val_loss: 0.5532\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.6720 - val_loss: 0.5391\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.6865 - val_loss: 0.5399\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.6045 - val_loss: 0.5222\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5842 - val_loss: 0.5091\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5915 - val_loss: 0.4902\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5692 - val_loss: 0.4857\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.5682 - val_loss: 0.4869\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5574 - val_loss: 0.4803\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5384 - val_loss: 0.4787\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.5465 - val_loss: 0.4745\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.5226 - val_loss: 0.4606\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5482 - val_loss: 0.5184\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5185 - val_loss: 0.5375\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5342 - val_loss: 0.5258\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5496 - val_loss: 0.5464\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 0.5194 - val_loss: 0.5635\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5426 - val_loss: 0.5655\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.5339 - val_loss: 0.5690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlqOvEeFmOlu"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQIaLyUN4Jbv",
        "outputId": "e76b6e49-cfa6-490e-ebe2-d4063c64ef20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c8zwwy7gCwDMiKoGFcYZOKOGVyQqNFgiOA1RI2++GUh2/1djWbRhHivRr03/owmhihBTQQ0hoSbi1ESnUhM9Io6IoKyiTqAgiDLCAjMPL8/TrXd01M9zEjXLPh9v1716uo6tTzT011PnVOnqszdERERyVbQ2gGIiEjbpAQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEiuxBGFmB5vZk2a2xMxeMbNvxsxjZnaHma0ws0VmdnxG2WVmtjwaLksqThERiWdJXQdhZgOAAe7+gpl1B54HPuvuSzLmORf4OnAucCLw/9z9RDM7EFgIlAMeLTvS3d9LJFgREWkgsRqEu69z9xei8W3AUmBg1mwXAvd78AzQM0os5wDz3X1TlBTmA2OTilVERBrq0BIbMbPBwAjg2ayigcBbGe+ro2m5psetezIwGaBz584jDz744LzE3Ji6ujoKCtrP6RvFm7z2FrPiTVZ7infZsmXvunvfuLLEE4SZdQMeAb7l7lvzvX53nwZMAygvL/eFCxfmexMNVFZWUlFRkfh28kXxJq+9xax4k9We4jWzN3KVJZrizKyIkBx+6+6/j5llDZB5yF8aTcs1XUREWkiSvZgMuBdY6u7/lWO2ucAXo95MJwFb3H0d8Bgwxsx6mVkvYEw0TUREWkiSTUynApOAl82sKpr2XWAQgLvfDcwj9GBaAWwHrojKNpnZj4HnouWmuvumBGMVEZEsiSUId/87YHuZx4Gv5SibDkxPIDQRSdju3buprq5m586deVlfjx49WLp0aV7W1RLaYrydOnWitLSUoqKiJi/TIr2YROTjpbq6mu7duzN48GBCa/O+2bZtG927d89DZC2jrcXr7mzcuJHq6mqGDBnS5OXaRz8sEWlXdu7cSe/evfOSHGTfmRm9e/dudo1OCUJEEqHk0LZ8lP+HEoSIiMRSghARkVhKECLysXTuueeyefNmNm/ezM9//vMPp1dWVnL++ec3aR3jxo2jrKyMww8/nB49elBWVkZZWRnPPvssFRUVNOXODlVVVcybN6/Z8a9du5bx48c3e7nmUIIQkY+lefPm0bNnzwYJojnmzJlDVVUV99xzD6NGjaKqqoqqqipOPPHEJq+jsQSxZ8+enMsddNBB/O53v2t2zM2hbq4ikqhvfQuqqvY+X2NqaztTWJh+X1YGt9/e+DK33norHTt25Bvf+Abf/va3eemll3jiiSd44oknuPfee3n66adZuHAh1157LStXrqSsrIyzzz6b8847j5qaGsaPH8/ixYsZOXIkv/nNbxI56b5r1y6uv/56duzYwd///neuu+46li5dysqVK1m1ahWDBg3ipptuYtKkSbz//vsA3HnnnZxyyimsXr2a888/n8WLFzNjxgzmzp3L9u3bWblyJePGjeOWW27Z5/hUgxCR/dKoUaNYsGABAAsXLqSmpobdu3ezYMECTj/99A/nu/nmmznssMOoqqri1ltvBeDFF1/k9ttvZ8mSJaxatYqnn346kRiLi4uZOnUqEyZMoKqqigkTJgCwZMkS/vKXvzBz5kz69evH/PnzeeGFF5g9ezbf+MY3YtdVVVXF7Nmzefnll5k9ezZvvfVW7HzNoRqEiCRqb0f6TbFt245mX3g2cuRInn/+ebZu3UrHjh05/vjjWbhwIQsWLOCOO+7gpptuyrnsCSecQGlpKQBlZWWsXr2a0047bZ/+hua44IIL6Ny5MxCuSp8yZQpVVVUUFhaybNmy2GXOPPNMevToAcDRRx/NG2+8wb4+/kAJQkT2S0VFRQwZMoQZM2ZwyimnMGzYMJ588klWrFjBUUcd1eiyHTt2/HC8sLCw0XMBSejateuH4z/96U8pKSnhpZdeoq6ujk6dOsUuk0TMamISkf3WqFGjuO222zj99NMZNWoUd999NyNGjKh3PqF79+5s27at1WLc2/a3bNnCgAEDKCgo4IEHHqC2trbFYlOCEJH91qhRo1i3bh0nn3wyJSUldOrUiVGjRtWbp3fv3px66qkce+yxXH311Xnd/nnnnUdpaSmlpaV8/vOfj51n9OjRLFmyhLKyMmbPnt2g/Ktf/Sr33Xcfw4cP59VXX61Xu0icu+83w8iRI70lPPnkky2ynXxRvMlrbzEnHe+SJUvyur6tW7fmdX1Ja6vxxv1fgIWeY5+qGoSIiMTSSWoRkSYYN24cr7/+er1pP/nJTzjnnHOatPxjjz3Gd77znXrThgwZwpw5c/IWY74pQYiINMG+7sjPOeecJieTtkJNTCIiEiuxGoSZTQfOB9a7+7Ex5VcDl2bEcRTQ18PzqFcD24BaYI+7lycVp4iIxEuyBjEDGJur0N1vdfcydy8DrgP+5u6bMmYZHZUrOYiItILEEoS7PwVs2uuMwSXAzKRiERGR5mv1cxBm1oVQ03gkY7IDj5vZ82Y2uXUiE5H9WVt5HkRzNSe+fdUWejF9Bng6q3npNHdfY2b9gPlm9mpUI2kgSiCTAUpKSqisrEw84JqamhbZTr4o3uS1t5iTjrdHjx55vX1FbW1t3m+Hkbpq+Y033uDOO+9k0qRJAGzfvp09e/Y0aXv3338/wIc3AHz44Yc/jLe2tpb3338/73E3J75sO3fubNb/vS0kiIlkNS+5+5rodb2ZzQFOAGIThLtPA6YBlJeXe0VFRaLBQsjgLbGdfFG8yWtvMScd79KlS+vdfTVuUxdfDF/9KmzfDuee27D88svD8O67MG7cHgoL07urpuzjmvo8iBtvvJHXX3+dUaNGffg8iJ07d3LFFVc0+XkQXbp0oUOHDh/+zdu2baOwsJCuXbvu9S60J510Evfeey/HHHMMABUVFdx2223U1dXxzW9+k507d9K5c2d+/etf84lPfKLBtpqjU6dOjBgxosnzt2oTk5n1AD4F/DFjWlcz654aB8YAi1snQhFpr9rD8yAAJkyYwEMPPQTAunXrWLduHeXl5Rx55JEsWLCAF198kalTp/Ld7343sRhySbKb60ygAuhjZtXADUARgLvfHc02Dnjc3d/PWLQEmBNl6w7Ag+7+56TiFJHkNXbE36VL4+V9+sC8efvv8yAuvvhixowZw49+9CMeeuihD58zvWXLFi677DKWL1+OmbF79+5Ett+YxBKEu1/ShHlmELrDZk5bBQxPJioR+bhoL8+DGDhwIL1792bRokXMnj2bu+8Ox88/+MEPGD16NHPmzGH16tWt0oTZ6r2YRESS0h6eBwGhmemWW25hy5YtDBs2DAg1iIEDBwIwY8aMVolLCUJE9lvt4XkQAOPHj2fWrFlcfPHFH0675ppruO666xgxYkSLP9EupS30YhIRScSZZ55Zr+0+83nOq1ev/nD8wQcfrLdcZnPOnXfeudftVFRUNGgCak530pKSkgZJ4OSTT64X74033phzW0lRDUJERGKpBiEi0gR6HoSISJ64e6MXl7U37f15EOHpos2jJiYRybtOnTqxcePGj7RTkvxzdzZu3EinTp2atZxqECKSd6WlpVRXV7Nhw4a8rG/nzp3N3rm1prYYb6dOnT68+K+plCBEJO9SF6nlS2VlZbPuIdTa2lu8uaiJSUREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhIrMQShJlNN7P1ZrY4R3mFmW0xs6pouD6jbKyZvWZmK8zs2qRiFBGR3JKsQcwAxu5lngXuXhYNUwHMrBC4C/g0cDRwiZkdnWCcIiISI7EE4e5PAZs+wqInACvcfZW77wJmARfmNTgREdkrS/J+7WY2GPiTux8bU1YBPAJUA2uBf3P3V8xsPDDW3a+K5psEnOjuU3JsYzIwGaCkpGTkrFmzEvhL6qupqaFbt26JbydfFG/y2lvMijdZ7Sne0aNHP+/u5XFlrXm77xeAQ9y9xszOBf4ADG3uStx9GjANoLy83FviYd6VlZUt9tDwfFC8yWtvMSveZLW3eHNptV5M7r7V3Wui8XlAkZn1AdYAB2fMWhpNExGRFtRqCcLM+lv0wFozOyGKZSPwHDDUzIaYWTEwEZjbWnGKiHxcJdbEZGYzgQqgj5lVAzcARQDufjcwHviKme0BdgATPZwQ2WNmU4DHgEJguru/klScIiISL7EE4e6X7KX8TuDOHGXzgHlJxCUiIk2jK6lFRCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRKLEGY2XQzW29mi3OUX2pmi8zsZTP7h5kNzyhbHU2vMrOFScUoIiK5JVmDmAGMbaT8deBT7n4c8GNgWlb5aHcvc/fyhOITEZFGdEhqxe7+lJkNbqT8HxlvnwFKk4pFRESaz9w9uZWHBPEndz92L/P9G3Cku18VvX8deA9w4Jfunl27yFx2MjAZoKSkZOSsWbPyE3wjampq6NatW+LbyRfFm7z2FrPiTVZ7inf06NHP52ypcffEBmAwsHgv84wGlgK9M6YNjF77AS8BpzdleyNHjvSW8OSTT7bIdvJF8SavvcWseJPVnuIFFnqOfWqr9mIys2HAPcCF7r4xNd3d10Sv64E5wAmtE6GIyMdXqyUIMxsE/B6Y5O7LMqZ3NbPuqXFgDBDbE0pERJKT2ElqM5sJVAB9zKwauAEoAnD3u4Hrgd7Az80MYI+HdrASYE40rQPwoLv/Oak4RUQkXpK9mC7ZS/lVwFUx01cBwxsuISIiLUlXUouISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhKrSQnCzL5pZgdYcK+ZvWBmY5IOTkREWk9TaxBfcvethMd/9gImATcnFpWIiLS6piYIi17PBR5w91cypomIyH6oqQnieTN7nJAgHjOz7kDd3hYys+lmtt7MFucoNzO7w8xWmNkiMzs+o+wyM1seDZc1MU4REcmTpiaIK4FrgU+6+3agCLiiCcvNAMY2Uv5pYGg0TAZ+AWBmBwI3ACcCJwA3mFmvJsYqIiJ50NQEcTLwmrtvNrMvAN8HtuxtIXd/CtjUyCwXAvd78AzQ08wGAOcA8919k7u/B8yn8UQjIiJ51qGJ8/0CGG5mw4H/C9wD3A98ah+3PxB4K+N9dTQt1/QGzGwyofZBSUkJlZWV+xjS3tXU1LTIdvJF8SavvcWseJPV3uLNpakJYo+7u5ldCNzp7vea2ZVJBtZU7j4NmAZQXl7uFRUViW+zsrKSlthOvije5LW3mBVvstpbvLk0tYlpm5ldR+je+j9mVkA4D7Gv1gAHZ7wvjablmi4iIi2kqQliAvAB4XqItwk77FvzsP25wBej3kwnAVvcfR3wGDDGzHpFJ6fHRNNERKSFNKmJyd3fNrPfAp80s/OB/3X3+/e2nJnNBCqAPmZWTeiZVBSt825gHqHr7ApgO1HPKHffZGY/Bp6LVjXV3Rs72S0iInnWpARhZhcTagyVhAvkfmZmV7v77xpbzt0v2Uu5A1/LUTYdmN6U+EREJP+aepL6e4RrINYDmFlf4C9AowlCRETar6aegyhIJYfIxmYsKyIi7VBTaxB/NrPHgJnR+wmE8wciIrKfaupJ6qvN7HPAqdGkae4+J7mwRESktTW1BoG7PwI8kmAsIiLShjSaIMxsG+BxRYROSAckEpWIiLS6RhOEu3dvqUBERKRtUU8kERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCRWognCzMaa2WtmtsLMro0p/6mZVUXDMjPbnFFWm1E2N8k4RUSkoSbf7ru5zKwQuAs4G6gGnjOzue6+JDWPu387Y/6vAyMyVrHD3cuSik9ERBqXZA3iBGCFu69y913ALODCRua/hPQT60REpJWZe9zjHvKwYrPxwFh3vyp6Pwk40d2nxMx7CPAMUOrutdG0PUAVsAe42d3/kGM7k4HJACUlJSNnzZqVxJ9TT01NDd26dUt8O/mieJPX3mJWvMlqT/GOHj36eXcvjytLrImpmSYCv0slh8gh7r7GzA4FnjCzl919ZfaC7j4NmAZQXl7uFRUViQdbWVlJS2wnXxRv8tpbzIo3We0t3lySbGJaAxyc8b40mhZnIlnNS+6+JnpdBVRS//yEiIgkLMkE8Rww1MyGmFkxIQk06I1kZkcCvYB/ZkzrZWYdo/E+wKnAkuxlRUQkOYk1Mbn7HjObAjwGFALT3f0VM5sKLHT3VLKYCMzy+idDjgJ+aWZ1hCR2c2bvJxERSV6i5yDcfR4wL2va9Vnvfxiz3D+A45q7vfXrYd48GDoUBg+GoqLmrkFERFLayknqvHjrLTjvvDBeWAhDhoRkcfjh4TU1HHIIdMjDX/7BByEpvfNOGFLj69fDsGFw6aVKUiLSfu1XCWL4cLjrLli+PD2sWAELFkBNTXq+Dh3SySM1pJJI376wYUN6p5+5408Nq1efwLZtsHlzfBydOsHOnfDjH8MPfgBf+EJ+EpKISEvar3ZbHTrAqaeGIZN72LFnJ47ly6GyErZv3/u6e/WCkhLo1w8OPbSG447rQkkJ9YZ+/cJr587wpz/BDTfAFVfAv/87XH89XHKJEoWItB8fi92VGfTvH4ZRo+qXucO6demksXFjqEVk7/iLi9PLVFYuoaKiX6Pb/Mxn4PzzYe7ckCi++EW48caQKCZODE1gIiJt2cciQTTGDA46KAyf+lT+133hhSFZ/OEP8MMfhuamG28MSePzn1eiEJG2S7f7bgEFBXDRRVBVBQ8/HJLCJZeEE9kPPQR1da0doYhIQ0oQLaigAMaPh0WLYNas0Lw1YUI4uf7II0oUItK2KEG0goKCkBhefhkefBB27w6J4/jjQ1NUQvdPFBFpFiWIVpRqanrlFXjggdCbatw4GDkynNxWohCR1vSxP0ndFhQWhpPXEyeGGsXUqeHk9ogR4cT54MH1hx49WjdeEfl4UIJoQzp0CN1h/+VfQo3iZz+DX/0K3n+//nw9ezZMGvlMILt3hwsL338/vKbGDzgADjssvIrI/k8Jog3q0CFcYHfFFaGZaeNGWL264bB8Ocyfv/cEsm3bIObPj9/px03btavx+Pr0CYkiNRx+eHq8pCR07xWR9k8Joo0zCzvkPn2gPOaZT01LIIdSWAjduoWha9f0a9++4bYjmdPi5uvaFd57D1auTA9PPx16Y2X2vuraFQ49tH4CSQ35ugeWiLQM/VzbuaYkkPnz/8bZZ38qkSP7XbtCMlqxon7yeO01ePTRcEPDlMJCOPjgcCuSgoIQe0FBeki9r6k5np49G5ZnzlNcHGpKvXrtfejSRbUayY89e2DhwvBaWxuGPXtCTf2II8Lv4U9/gkWL+vL22+l5hg8PQ00N3H9/erldu0KT7tlnw4knhrs63HRTmJ4q27ULvvxlGD0aliyBr30tPf2ii+Daa5P7e/erBKFePw2ZQXGxJ7aDLC4OP4wjjmhYVlcHa9eGhJFKIG+8Eb7cdXXpwb3+e9hDt24Ny/fsSb//4IPwY3nvPdiypfH/fVFR7uTRvz8MGhSGgw+G0lLo2DGZz0rapro62LEj1H4Bpk0Ld4ZesyY9fOYzYcddVwcnn9xwHVdfDbfcEnoifu5zAMfUK//Rj0KC2Lw57OCzdekSEsS2bfCb34TvbHFxGIqKQisBhN9zbW24IWj37mFI0n6VIF54AQ48MNw76Z574LTTYPHicBFav371h8GDtSNIWkFB2OGWljbvNiaVlYua9TzfurqQJN57LwybN6fH44YNG2DZsjC+aVPD9WUmjVTiyHzft+9Hq5GkEtu2bemhpiY9DqEpbujQ5H/4cTZuhFdfhaVLQ63wkEPC1f7HHpveebZ127eHo/C33w7D2rXh4GTt2rBjHTIEXn89/bmvXRvmP+88mDMnrOP668N3pH9/GDgw/D8OOyyUFRfD44+H/39hYXoYODCUd+8e7pjwwgvPcdJJn/yw/MADQ/mAASGuwsKw408lgtQtd444Iv47mXLUUfDUU8l8dnH2qwRx0EGhyrV+ffof8tJL4R5I2Z5/PlyY9uCDcNtt6cTRs2conzo1jM+bB//93+mjWHdYu/YTnHhiaCqZPTvMk1nuDvfeG8pffDH8w1M7yvbyQ2tPCgrSNYLm2rkTqqvhzTcbDi+/DP/zP+HoMlPHjvUTx8CBsHLloTz0UMOdfvb72tqmxTVgQNgxpWpnqfHDDtu3A5va2lCLe+aZA3nhhXRCePVVePfd+GXMwvaHDw8JI9VccvDB8Ymypiac/3rzzZCse/WC3r2hrCx8/92bl2Bra2HTpiKqqtI7/lQSWLcuHO2vXRsSfirRZisqCp0pHn00/M9Tf1fPnnDkkeG1sjL8XS+/HGLOdb7s7LNzx1pYGNbx3nvvc9RRIWGtXBnunpB5F+kVK0JNunv30Csw+zVuWlxZt27J3s9tv0oQAwaErqGZLr00XLX87rv1H+hz+OGhvHv38ANfvz78SDZvDl+c73wnfGmWLg01kFT7txns3n0gu3eHBLByJfztb/XLO3YMVUCAO+6AGTPS8fTsGX7ozz4b3v/hD+HILZVASkvDP15t5i2jU6fwXUh9H7K5hwQfl0DefDMcTa5bBx06lH74w00NPXuGnWjqfbdu9cuzp9XWhh3HsmVhJ7JsGfzxj+FoNqWgICSl7MRxxBHhiD+1s9i+PSz/6qv1k8CyZakd5DAgnLs68kj47GfD0emRR4Zh0KDw9730UhgWLQoHVQ8/nI6lS5dQm+rWLbz//vfD9TsPPwxf+lLDz/Lll0Nt5K674HvfCzvh7t3D76i4ONz9+P33w3ypo/xUbdD91AbrKyhIH5B17Bja6fv3Dwdsb78dPo+hQ8PfdfTRcOaZoZly+fJwlF9VFf62qqrwG039TgcNCsmsrCzs7MvKQotDQY7LirdvD/+31LB8OSxcOJwNG0LzVKa+fcN3bfTo8Plt3RqS2tatIdGlxrdtSyeyvZk5M1xDlQTzBBvuzWws8P8Iz6S+x91vziq/HLgVSH2Md7r7PVHZZcD3o+k3uvt9e9teeXm5L1y4ME/R51ZZWdnkJpDq6vClqa4OX5bq6vAl/cUvQvlZZ8Ff/1p/meHDw5cWQk3m3XfDD7lv3/A6ZEj6hHRdXe4v7keJty1ob/HW1cFTTyUX8+bN6YSR/bp1a3q+oqLQg+yDD0ItIfXTNgvfmcwEsGPHi1xyyQj69Gm4vR074IknwsFPZjK84YbwrJXp0+Hb307Pb5beVkFB2Fb//qG2ceih4TtfXR2S17vvht/D22/Hd6cuKAgJI7vrNoQd4aBBoda/YEFY95AhYec9ZEhIMB/1wOrtt9PJIvX62mvpHnrdu6drTgcdBKtWpZPB2rX119WvH/Ttu4Xy8h4fHnykmqlSLRRNsWtXuua5dWv9ZJI5/vnPwzHH7H19uZjZ8+4e08UlwRqEmRUCdwFnA9XAc2Y2192XZM06292nZC17IHADUA448Hy07HtJxZuUVK0gl3nzwhFo6kdUXV2/CeGf/wzDli3paWeckU4qRx6ZfoZFKoGccQZ8/euh/JFHYNWqXvTvH45m1cSVf3tL0PuqZ0/45CfDkMk91Hyzk0ZxcbiGJpUQhg5N12hTKiu31EsOtbVhZ9OrV1jP+eeH6Z07p8+9dOgQareXXw7HHReO0EtLw/ZWrUrXNlI1jqefTq+/U6dQwx8wIBzcpMZTQ//+4bVv35Cg3nkn1Nw2bgyvK1cuZty4Y+nYEU45Jf+fcep5Meeck562fXu4DU5m0rj//rBjLikJO/4xY2iQBHr0gMrKF/f5gKG4ODTN9e69b3/bvkiyiekEYIW7rwIws1nAhUB2gohzDjDf3TdFy84HxgIzE4q11RQXhx/aIYfElz/6aHjdtSv8WDZsqL9DuvLKcHS3YUMYVqwIP+aUSZNgx47hXHNNeH/ggaEXxdSpYQfzn/8ZfuSpncCAAXpGRXthln6o1WmnNX9593CO7De/CdeznHVW2AEOGxZOhB51VNg5ZR+V9+wZmmsypXaSoQdPsGVLODIvKQk7zaYe3aeuw0mdGAaorHy3xTuVdOnSMDFn93ja3yXWxGRm44Gx7n5V9H4ScGJmbSFqYroJ2AAsA77t7m+Z2b8Bndz9xmi+HwA73P22mO1MBiYDlJSUjJw1a1Yif0+mmpoauqUaXtswd1izpjNr1tSybVtP1q/vxDvvdOTYY7dw9tnr2bKliM9+tn7bbkGBM3nyKiZMeIuamkJmzhxEv34f0K/fTrp330NRUR0DBuzkgAP2sHu3sW1bB4qLnaKiOoqK6vJyNN1ePt9M7S3m2bN7M2/eobz5Zlc6dKjjpJM28ulPv80pp2xs7dBitbfPtz3FO3r06JZvYmqi/wZmuvsHZvZ/gPuAM5qzAnefBkyDcA6iJdqu21sbeYj36IwpA4HwfsuWcHIs1c781lvGWWcdRkXFYSxeHE447t5df33Tp8MFF4SmrzFj6pd16BB6dl10UTgKveyy0GSWOfz0p6GZ4Ykn4LvfrX8NRF0dfP3rz3H++Z/k978PJzOzyx97LJyUnTUr1IC6dAlHdKnX224LTRV//3sYMsu7dIGxY0McqWaMgoJQa0q9DhoUjna3bg3t+ZllBQXpo8e6unTHhLb+ndiwIXSI+NKXwt9x991vMnhwV77/fRg/voBevfoCfVs7zJza+uebrb3Fm0uSCWINcHDG+1LSJ6MBcPfMw5V7gFsylq3IWrYy7xEKBxwQTnDFneQ69tjQk+Kdd9JdFj/4IPTqgHBy8K67wrTMIXXRXM+eoekjNb5+whQAAAvzSURBVH3XrvpXVhcVhXmyr5YuKgpnBnv1Cs0d2eVduoTlU71otm8PO8Dt28PJzVRX0r/8JVyglG3z5pAgbrstDNlSJyavuQZ++cv6ZV26pE+gTpoUTpiGv+V0OnUKPeKWLg3TpkwJJ1OLi8P2iovDZzZ9eii/6abQ3p9KnF27hnbsyy8P5a+/Hs4B9Onz0W5Rsn176AX129+GpLpnT2g2Ou00mDx5FWecMWjvK5GPtSQTxHPAUDMbQtjhTwT+JXMGMxvg7uuitxcA0U+Lx4D/MLNUz/YxwHUJxio5FBSkTyRmGzAAvvrV3MsOGxbuSpvLqFHw5z83nF5ZGS48GD06DLlccEEYcrnhhtBdOZU4tm8PQ+oitEsvDTWZ2tqQFFK3RUi1lU+cGJJkqqyurv75mc99LiTD0D21mpKSQXTunC4vLU33Kkolx5qadHlVFfzjH+ny998PzwJJJYhx48LJUQjnAvr2DecJUl25f/7z8P/JvAC0f/+Q9BcvhpNOCussLYV//dfw9w4LvVsTP7Eu+4fEEoS77zGzKYSdfSEw3d1fMbOpwEJ3nwt8w8wuAPYAm4DLo2U3mdmPCUkGYGrqhLVIU5mFI/DOneN7gqT6uudSURGGXC66KAwAlZWrqKiof0S+t3vkzJ5d/717SGAp//Efobvq+vXpIfNiwB/+sP41EhCS2syZoffSVVeFJDNqlBKCfDSJnoNw93nAvKxp12eMX0eOmoG7TwemJxmfSFtiVr93zLnnNj5/dXX6AtDUkLrlQ4cOcPvtycUqHw+tfZJaRD6i4uJw0dZBB7V2JLK/UsVTRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiJZogzGysmb1mZivMrMETes3sX81siZktMrO/mtkhGWW1ZlYVDXOTjFNERBpK7JGjZlYI3AWcDVQDz5nZXHdfkjHbi0C5u283s68AtwATorId7t7II+VFRCRJSdYgTgBWuPsqd98FzAIuzJzB3Z909+3R22eA0gTjERGRZkgyQQwE3sp4Xx1Ny+VK4NGM953MbKGZPWNmn00iQBERyc3cPZkVm40Hxrr7VdH7ScCJ7j4lZt4vAFOAT7n7B9G0ge6+xswOBZ4AznT3lTHLTgYmA5SUlIycNWtWIn9PppqaGrp165b4dvJF8SavvcWseJPVnuIdPXr08+5eHlvo7okMwMnAYxnvrwOui5nvLGAp0K+Rdc0Axu9tmyNHjvSW8OSTT7bIdvJF8SavvcWseJPVnuIFFnqOfWqSTUzPAUPNbIiZFQMTgXq9kcxsBPBL4AJ3X58xvZeZdYzG+wCnApknt0VEJGGJ9WJy9z1mNgV4DCgEprv7K2Y2lZCx5gK3At2Ah80M4E13vwA4CvilmdURzpPc7PV7P4mISMISSxAA7j4PmJc17fqM8bNyLPcP4LgkYxMRkcbpSmoREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJFaiCcLMxprZa2a2wsyujSnvaGazo/JnzWxwRtl10fTXzOycJOMUEZGGEksQZlYI3AV8GjgauMTMjs6a7UrgPXc/HPgp8JNo2aOBicAxwFjg59H6RESkhSRZgzgBWOHuq9x9FzALuDBrnguB+6Lx3wFnmplF02e5+wfu/jqwIlqfiIi0kA4Jrnsg8FbG+2rgxFzzuPseM9sC9I6mP5O17MC4jZjZZGBy9LbGzF7b99D3qg/wbgtsJ18Ub/LaW8yKN1ntKd5DchUkmSBahLtPA6a15DbNbKG7l7fkNveF4k1ee4tZ8SarvcWbS5JNTGuAgzPel0bTYucxsw5AD2BjE5cVEZEEJZkgngOGmtkQMysmnHSemzXPXOCyaHw88IS7ezR9YtTLaQgwFPjfBGMVEZEsiTUxRecUpgCPAYXAdHd/xcymAgvdfS5wL/CAma0ANhGSCNF8DwFLgD3A19y9NqlYP4IWbdLKA8WbvPYWs+JNVnuLN5aFA3YREZH6dCW1iIjEUoIQEZFYShA5mNnBZvakmS0xs1fM7Jsx81SY2RYzq4qG61sj1ox4VpvZy1EsC2PKzczuiG5hssjMjm+NOKNYPpHxuVWZ2VYz+1bWPK3++ZrZdDNbb2aLM6YdaGbzzWx59Norx7KXRfMsN7PL4uZpoXhvNbNXo//5HDPrmWPZRr8/LRjvD81sTcb//dwcyzZ6K58WjHd2Rqyrzawqx7It/vnuM3fXEDMAA4Djo/HuwDLg6Kx5KoA/tXasGfGsBvo0Un4u8ChgwEnAs60dcxRXIfA2cEhb+3yB04HjgcUZ024Bro3GrwV+ErPcgcCq6LVXNN6rleIdA3SIxn8SF29Tvj8tGO8PgX9rwndmJXAoUAy8lP37bKl4s8r/E7i+rXy++zqoBpGDu69z9xei8W3AUnJczd2OXAjc78EzQE8zG9DaQQFnAivd/Y3WDiSbuz9F6GGXKfMWMfcBn41Z9Bxgvrtvcvf3gPmE+4olKi5ed3/c3fdEb58hXFfUJuT4fJuiKbfyybvG4o1uE3QxMDPpOFqKEkQTRHeZHQE8G1N8spm9ZGaPmtkxLRpYQw48bmbPR7cgyRZ3+5O2kPQmkvtH1ZY+35QSd18Xjb8NlMTM01Y/6y8RapFx9vb9aUlToiax6Tma8Nri5zsKeMfdl+cob0ufb5MoQeyFmXUDHgG+5e5bs4pfIDSLDAd+BvyhpePLcpq7H0+4g+7XzOz0Vo5nr6KLKC8AHo4pbmufbwMe2g7aRV9xM/se4bqi3+aYpa18f34BHAaUAesIzTbtwSU0XntoK59vkylBNMLMigjJ4bfu/vvscnff6u410fg8oMjM+rRwmJnxrIle1wNzaHgH3LZ4C5NPAy+4+zvZBW3t883wTqppLnpdHzNPm/qszexy4Hzg0iipNdCE70+LcPd33L3W3euAX+WIo619vh2Ai4DZueZpK59vcyhB5BC1J94LLHX3/8oxT/9oPszsBMLnubHloqwXS1cz654aJ5yYXJw121zgi1FvppOALRlNJa0l51FXW/p8s2TeIuYy4I8x8zwGjDGzXlETyZhoWoszs7HANcAF7r49xzxN+f60iKzzYuNyxNGUW/m0pLOAV929Oq6wLX2+zdLaZ8nb6gCcRmg6WARURcO5wJeBL0fzTAFeIfSgeAY4pRXjPTSK46Uopu9F0zPjNcJDnFYCLwPlrfwZdyXs8HtkTGtTny8hea0DdhPaua8k3JL+r8By4C/AgdG85cA9Gct+ifAskxXAFa0Y7wpCe33qe3x3NO9BwLzGvj+tFO8D0fdzEWGnPyA73uj9uYTehStbM95o+ozU9zZj3lb/fPd10K02REQklpqYREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYg0g5nVZt2FNm93ETWzwZl3CRVpbYk9clRkP7XD3ctaOwiRlqAahEgeRPf6vyW63///mtnh0fTBZvZEdOO5v5rZoGh6SfRshpei4ZRoVYVm9isLzyB53Mw6t9ofJR97ShAizdM5q4lpQkbZFnc/DrgTuD2a9jPgPncfRrhJ3h3R9DuAv3m4EeHxhKtrAYYCd7n7McBm4HMJ/z0iOelKapFmMLMad+8WM301cIa7r4pu8vi2u/c2s3cJt4rYHU1f5+59zGwDUOruH2SsYzDhGRJDo/ffAYrc/cbk/zKRhlSDEMkfzzHeHB9kjNei84TSipQgRPJnQsbrP6PxfxDuNApwKbAgGv8r8BUAMys0sx4tFaRIU+noRKR5Omc9lP7P7p7q6trLzBYRagGXRNO+DvzazK4GNgBXRNO/CUwzsysJNYWvEO4SKtJm6ByESB5E5yDK3f3d1o5FJF/UxCQiIrFUgxARkViqQYiISCwlCBERiaUEISIisZQgREQklhKEiIjE+v8Rloj5yMN+aAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQp1LcfjOk6T",
        "outputId": "0e975570-47e3-48db-b798-ceafc6e92721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_AB)\n",
        "Y_true = pd.get_dummies(testdata_AB['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1526 unique tokens.\n",
            "Shape of data tensor: (280, 40)\n",
            "Shape of label tensor: (280, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6oSdgMOk6e",
        "outputId": "63aa2520-c9ed-4556-98a6-d51310c046a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AB_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5155992445054944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi5ybAhb4UZ0"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqjWN2H4YRJ",
        "outputId": "8f71d6eb-7b6f-4aec-8334-0195486c4876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iwgP9hW4eQk",
        "outputId": "78877814-c6f7-48fa-f22c-f2f96e4a646a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model = create_model(embedding_layer_TL)\n",
        "print(model.summary())"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 40, 100)           277200    \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 296,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 277,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9nRejvf4ewR",
        "outputId": "e3d9ceda-4e0e-42ae-cc2d-4cdbb392e049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/17 [==>...........................] - ETA: 4s - loss: 1.2083WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0574s vs `on_train_batch_end` time: 0.4885s). Check your callbacks.\n",
            "17/17 [==============================] - 2s 98ms/step - loss: 1.1796 - val_loss: 1.1199\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0923 - val_loss: 1.0163\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 1s 52ms/step - loss: 1.0805 - val_loss: 1.0219\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 1s 65ms/step - loss: 1.0501 - val_loss: 0.9908\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0355 - val_loss: 0.9854\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 1.0219 - val_loss: 0.9364\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.9975 - val_loss: 0.8814\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9524 - val_loss: 0.9100\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9421 - val_loss: 0.8839\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9318 - val_loss: 0.8875\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9408 - val_loss: 0.8620\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9230 - val_loss: 0.8592\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9127 - val_loss: 0.8634\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.9368 - val_loss: 0.9405\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9263 - val_loss: 0.8494\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8978 - val_loss: 0.8497\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8885 - val_loss: 0.8519\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8687 - val_loss: 0.8599\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8996 - val_loss: 0.8457\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8931 - val_loss: 0.8456\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8643 - val_loss: 0.8816\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8843 - val_loss: 0.8923\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8715 - val_loss: 0.8579\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.8834 - val_loss: 0.8696\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8813 - val_loss: 0.8892\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8768 - val_loss: 0.8665\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8496 - val_loss: 0.9371\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8355 - val_loss: 0.8724\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8463 - val_loss: 0.8580\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8401 - val_loss: 0.8510\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8689 - val_loss: 0.8463\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 1s 60ms/step - loss: 0.8602 - val_loss: 0.8432\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.8473 - val_loss: 0.8542\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 0.8117 - val_loss: 0.8915\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.8836 - val_loss: 0.8916\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.8483 - val_loss: 0.8386\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 0.8462 - val_loss: 0.8532\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 1s 55ms/step - loss: 0.8276 - val_loss: 0.8612\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8550 - val_loss: 0.8721\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8388 - val_loss: 0.8917\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8030 - val_loss: 0.8878\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8421 - val_loss: 0.8475\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8185 - val_loss: 0.8797\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.7939 - val_loss: 0.8851\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.7864 - val_loss: 0.8642\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8185 - val_loss: 0.8556\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8053 - val_loss: 0.9037\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.7967 - val_loss: 0.8757\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.7475 - val_loss: 0.9589\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8074 - val_loss: 0.9016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeXWGsD64eFY",
        "outputId": "90620ff7-214c-4c26-cd57-1f3441f3de38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA3Ip296PEpq",
        "outputId": "061aed86-38b1-42f1-e5f7-4083dc85aa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AB_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39930106658047837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZgZtwUy5UuD"
      },
      "source": [
        "# **3. modelling for tweets related to Target : Atheism**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AndJglj7mZb6"
      },
      "source": [
        "First we check the preprocessed tweet data for target Atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_GO73Wc5ckA",
        "outputId": "535788a2-8b94-43a6-b858-ccca8ea549a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_AT[:1]"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['dear',\n",
              "  'lord',\n",
              "  'thank',\n",
              "  'ur',\n",
              "  'blessings',\n",
              "  'forgive',\n",
              "  'sins',\n",
              "  'lord',\n",
              "  'give',\n",
              "  'strength',\n",
              "  'energy',\n",
              "  'busy',\n",
              "  'day',\n",
              "  'ahead',\n",
              "  '#blessed',\n",
              "  '#hope',\n",
              "  '#semst',\n",
              "  'atheism']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B97j5WeMmkKi"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITghyAfU5on9",
        "outputId": "0dac7daf-d540-4a26-985b-c1ceb72ebfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_AT)\n",
        "Y = pd.get_dummies(traindata_AT['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2462 unique tokens.\n",
            "Shape of data tensor: (513, 40)\n",
            "Shape of label tensor: (513, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0KouwGhmp2Z"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZqc9JFU5vUG",
        "outputId": "2ff7a429-9faa-4a65-88d8-f9f0ca86cb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (410, 40)\n",
            "Y train shape:  (410, 3)\n",
            "X Val shape:  (103, 40)\n",
            "Y Val shape:  (103, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MWxEp6w5364"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9u1Ho5o53Q0",
        "outputId": "9efe2f14-1b50-4c9e-9b0b-f0e0bce7b3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 40, 100)           246300    \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 265,631\n",
            "Trainable params: 265,631\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht3uMDBtm1fY"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fBoq3UT6EuV",
        "outputId": "42cbade6-d0d1-4943-b38a-f97a6c0303d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/11 [====>.........................] - ETA: 2s - loss: 1.2089WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0768s vs `on_train_batch_end` time: 0.5182s). Check your callbacks.\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.1717 - val_loss: 1.1303\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0787 - val_loss: 1.0617\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0242 - val_loss: 1.0560\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.0113 - val_loss: 1.0464\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0287 - val_loss: 1.0349\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.0144 - val_loss: 1.0273\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 1.0027 - val_loss: 1.0216\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.9969 - val_loss: 1.0198\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.9933 - val_loss: 1.0125\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.9792 - val_loss: 1.0100\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.9757 - val_loss: 1.0075\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.9745 - val_loss: 1.0052\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.9724 - val_loss: 1.0050\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.9796 - val_loss: 1.0019\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.9658 - val_loss: 1.0006\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.9636 - val_loss: 0.9984\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.9650 - val_loss: 0.9992\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.9663 - val_loss: 0.9953\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.9557 - val_loss: 0.9968\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.9636 - val_loss: 0.9882\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/11 [====>.........................] - ETA: 0s - loss: 0.8815WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0688s vs `on_train_batch_end` time: 0.1250s). Check your callbacks.\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.9267 - val_loss: 0.5496\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.7135 - val_loss: 0.4540\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.6344 - val_loss: 0.4876\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.5836 - val_loss: 0.4127\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.5418 - val_loss: 0.3830\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.5012 - val_loss: 0.3802\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.4509 - val_loss: 0.3488\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.5116 - val_loss: 0.3661\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.4070 - val_loss: 0.3915\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.4209 - val_loss: 0.4115\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3724 - val_loss: 0.3664\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3363 - val_loss: 0.3447\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3590 - val_loss: 0.5709\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 0.5059 - val_loss: 0.5298\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3728 - val_loss: 0.3624\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.3972 - val_loss: 0.3390\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3846 - val_loss: 0.3203\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.4068 - val_loss: 0.3211\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3655 - val_loss: 0.3440\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.3633 - val_loss: 0.3814\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            " 2/11 [====>.........................] - ETA: 0s - loss: 0.3835WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0549s vs `on_train_batch_end` time: 0.0824s). Check your callbacks.\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 0.3721 - val_loss: 0.3296\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3951 - val_loss: 0.3288\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.3011 - val_loss: 0.3260\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3455 - val_loss: 0.3281\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.3433 - val_loss: 0.3381\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3579 - val_loss: 0.3420\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.3939 - val_loss: 0.3589\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3630 - val_loss: 0.3582\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3541 - val_loss: 0.3401\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 0.3932 - val_loss: 0.3513\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.4404 - val_loss: 0.4200\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 0.4251 - val_loss: 0.3387\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3741 - val_loss: 0.3868\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3382 - val_loss: 0.3860\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3286 - val_loss: 0.3838\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 0.3317 - val_loss: 0.3898\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.3986 - val_loss: 0.3359\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 0.3884 - val_loss: 0.3438\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.4057 - val_loss: 0.3724\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 1s 61ms/step - loss: 0.4319 - val_loss: 0.3911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXveg7L3m_2B"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yayCOjqC6ipM",
        "outputId": "9d949aa7-f88a-4701-cf2c-023cc76ea4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iew-RGPeQcE3",
        "outputId": "3bd975e4-0d3a-40e3-8805-f6812380a914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_AT)\n",
        "Y_true = pd.get_dummies(testdata_AT['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1339 unique tokens.\n",
            "Shape of data tensor: (220, 40)\n",
            "Shape of label tensor: (220, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr2ZgpoiQcFN",
        "outputId": "c0439fd8-e1e2-423a-f503-3ac8ae9920d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AT_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5305194805194805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM9mdkHd6uDs"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDjYRAyu6h0w",
        "outputId": "90cd1935-fa36-46c7-adb1-ff4d2e7bfe6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "246300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENIvOjGJ6ho9",
        "outputId": "1630e131-de00-4c68-ebf1-038fb9cdca58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model = create_model(embedding_layer_TL)\n",
        "print(model.summary())"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 40, 100)           246300    \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 265,631\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 246,300\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZjyXfqX663E",
        "outputId": "c3099790-35f3-4322-ba75-620f01a5e212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/13 [===>..........................] - ETA: 3s - loss: 1.2078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_end` time: 0.5129s). Check your callbacks.\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 1.1797 - val_loss: 1.1435\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 1.0745 - val_loss: 1.1300\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 1.0209 - val_loss: 1.0703\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 1.0036 - val_loss: 1.0590\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.9564 - val_loss: 0.9961\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.8537 - val_loss: 0.9559\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.8513 - val_loss: 0.9110\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.8326 - val_loss: 0.9088\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.8429 - val_loss: 0.8908\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.7967 - val_loss: 0.9223\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.8158 - val_loss: 0.8733\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.7882 - val_loss: 0.8688\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.7927 - val_loss: 0.9050\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7478 - val_loss: 0.8741\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7577 - val_loss: 0.8578\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.8106 - val_loss: 0.8902\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7798 - val_loss: 0.8689\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.7587 - val_loss: 0.9223\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.7516 - val_loss: 0.8816\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.7709 - val_loss: 0.9202\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.7411 - val_loss: 0.9302\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.7477 - val_loss: 0.8836\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.7299 - val_loss: 0.9686\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6988 - val_loss: 0.9846\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.7377 - val_loss: 0.9108\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.7098 - val_loss: 0.8943\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 0.7165 - val_loss: 0.9328\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.7078 - val_loss: 0.8987\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.7354 - val_loss: 0.9345\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.7073 - val_loss: 0.9031\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6943 - val_loss: 0.9990\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.7143 - val_loss: 0.9205\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.7356 - val_loss: 0.9091\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.6752 - val_loss: 1.0737\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.7303 - val_loss: 0.9874\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.7235 - val_loss: 0.9315\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.6910 - val_loss: 0.9574\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.7142 - val_loss: 1.0197\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6926 - val_loss: 1.0210\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.6611 - val_loss: 0.9756\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6778 - val_loss: 0.9795\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6734 - val_loss: 1.0496\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.6314 - val_loss: 1.0770\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6600 - val_loss: 1.0035\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6796 - val_loss: 1.1250\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6519 - val_loss: 1.1110\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 48ms/step - loss: 0.6677 - val_loss: 1.1095\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 51ms/step - loss: 0.6720 - val_loss: 1.0410\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 0.6584 - val_loss: 1.0379\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 49ms/step - loss: 0.6762 - val_loss: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VosXxD1c67X5",
        "outputId": "c26a0902-9b95-46c5-dc4f-c7fe72ef2165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFA2rIAgQ83p",
        "outputId": "e7d35d6a-cde7-4ded-d9ef-85ebbe6e15e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_AT_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5504132231404959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qXKf6B7HR9"
      },
      "source": [
        "# **4. Modelling for tweets related to target: Climate Change is a Real Concern**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Fl0P6KnMoz"
      },
      "source": [
        "First we check the preprocessed tweet data for target Climate Change is a Real Concern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-wCIovY74Y_",
        "outputId": "f91260e2-403c-4f73-b124-ae7c41dec732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "Tweets_CC[:1]"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['cant',\n",
              "  'deny',\n",
              "  'really',\n",
              "  'happening',\n",
              "  '#semst',\n",
              "  'climate',\n",
              "  'change',\n",
              "  'real',\n",
              "  'concern']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKX4PbJkncix"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hWkV61G8EoZ",
        "outputId": "0d48e4a1-eb02-42eb-9f48-d3550deaabc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_CC)\n",
        "Y = pd.get_dummies(traindata_CC['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2281 unique tokens.\n",
            "Shape of data tensor: (395, 40)\n",
            "Shape of label tensor: (395, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84G7kjPynci3"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIgZmm9c8Mv7",
        "outputId": "004f8d92-ed9c-4b00-ff1e-a40d31f64851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (316, 40)\n",
            "Y train shape:  (316, 3)\n",
            "X Val shape:  (79, 40)\n",
            "Y Val shape:  (79, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_DxoMYR8bRn"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22qYAKN8bRp",
        "outputId": "bab4381d-f853-4174-e17c-2e313f77d918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 40, 100)           228200    \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 247,531\n",
            "Trainable params: 247,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL4ctSrAnci5"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RggbRK4P8bRu",
        "outputId": "53a29655-ad9c-4842-ed64-a8937f4e1cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            "2/9 [=====>........................] - ETA: 2s - loss: 1.2132WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0776s vs `on_train_batch_end` time: 0.5728s). Check your callbacks.\n",
            "9/9 [==============================] - 1s 161ms/step - loss: 1.1821 - val_loss: 1.1405\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 1.0932 - val_loss: 1.0489\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.9914 - val_loss: 0.9697\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.9230 - val_loss: 0.9275\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.8975 - val_loss: 0.9187\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8996 - val_loss: 0.9110\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8768 - val_loss: 0.9047\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.8891 - val_loss: 0.9003\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8768 - val_loss: 0.9038\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8863 - val_loss: 0.8949\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8603 - val_loss: 0.8880\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.8582 - val_loss: 0.8836\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.8602 - val_loss: 0.8837\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8446 - val_loss: 0.8804\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.8282 - val_loss: 0.8851\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8391 - val_loss: 0.8856\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.8557 - val_loss: 0.8809\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.8177 - val_loss: 0.8703\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8378 - val_loss: 0.8689\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.8342 - val_loss: 0.8699\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            "2/9 [=====>........................] - ETA: 0s - loss: 0.8188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0633s vs `on_train_batch_end` time: 0.1011s). Check your callbacks.\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.8440 - val_loss: 0.8495\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8498 - val_loss: 0.8408\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.8314 - val_loss: 0.8326\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.8172 - val_loss: 0.7980\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.7751 - val_loss: 0.6902\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6357 - val_loss: 0.5088\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.4521 - val_loss: 0.4044\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.3529 - val_loss: 0.6656\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2945 - val_loss: 0.4052\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2146 - val_loss: 0.3618\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.1859 - val_loss: 0.3686\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.2032 - val_loss: 0.3684\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.1831 - val_loss: 0.3751\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.1766 - val_loss: 0.3662\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.2195 - val_loss: 0.4636\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.1986 - val_loss: 0.4231\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.1725 - val_loss: 0.4285\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.1573 - val_loss: 0.4523\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.1404 - val_loss: 0.5203\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.1669 - val_loss: 0.5119\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.3475 - val_loss: 0.0993\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2895 - val_loss: 0.2012\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.2265 - val_loss: 0.1229\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.2280 - val_loss: 0.1254\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.2589 - val_loss: 0.1296\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.4033 - val_loss: 0.3085\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.4414 - val_loss: 0.3280\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.4870 - val_loss: 0.3256\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.4611 - val_loss: 0.3222\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.4430 - val_loss: 0.3261\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.4675 - val_loss: 0.3323\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.4784 - val_loss: 0.3345\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.4572 - val_loss: 0.3277\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5030 - val_loss: 0.3316\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.4864 - val_loss: 0.3465\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5159 - val_loss: 0.3570\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5022 - val_loss: 0.3559\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5348 - val_loss: 0.3509\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5207 - val_loss: 0.3272\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5484 - val_loss: 0.3343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ1XXAYlnci7"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UyWMRb8bR0",
        "outputId": "ece7d2f2-d9c4-4ae6-d24a-cea78b5c7341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz0N9II6T3ew",
        "outputId": "fdb82532-1c5a-4366-b723-210839a91c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_CC)\n",
        "Y_true = pd.get_dummies(testdata_CC['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1167 unique tokens.\n",
            "Shape of data tensor: (169, 40)\n",
            "Shape of label tensor: (169, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndUA2BeT3fE",
        "outputId": "6b38a370-c9ae-4ac6-c7ec-cd141f64c1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_CC_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.612403873855905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UECckmdJ8bR8"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1zde7Ff8bR9",
        "outputId": "fad8790f-f268-4ed6-817d-e57ceb1695be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUUCG7408bSA",
        "outputId": "3c091d5a-e3f7-4619-ef5f-54968b50c813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model = create_model(embedding_layer_TL)\n",
        "print(model.summary())"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 40, 100)           228200    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 247,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 228,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ3UShmz8bSG",
        "outputId": "6dfc24cd-d8ea-4bea-ff5d-37526bd0f0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "m_histories['with_TL'] = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/10 [=====>........................] - ETA: 2s - loss: 1.2096WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0664s vs `on_train_batch_end` time: 0.4519s). Check your callbacks.\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 1.1894 - val_loss: 1.1617\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 1.1098 - val_loss: 1.0431\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9497 - val_loss: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9124 - val_loss: 0.9659\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8735 - val_loss: 0.9586\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9126 - val_loss: 0.9469\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8669 - val_loss: 0.9309\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8549 - val_loss: 0.9407\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8332 - val_loss: 0.9313\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8410 - val_loss: 0.9281\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8347 - val_loss: 0.9224\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8254 - val_loss: 0.9177\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8291 - val_loss: 0.9254\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8256 - val_loss: 0.9295\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8277 - val_loss: 0.9245\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8227 - val_loss: 0.9182\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8041 - val_loss: 0.9184\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8111 - val_loss: 0.9116\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8017 - val_loss: 0.9146\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7973 - val_loss: 0.9155\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7973 - val_loss: 0.9247\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7942 - val_loss: 0.9051\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.8165 - val_loss: 0.9078\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.7940 - val_loss: 0.9030\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 0.7779 - val_loss: 0.9001\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7722 - val_loss: 0.9110\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.7702 - val_loss: 0.9064\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.7951 - val_loss: 0.9150\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.7992 - val_loss: 0.8872\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7828 - val_loss: 0.8843\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.7937 - val_loss: 0.9110\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.7673 - val_loss: 0.8977\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7786 - val_loss: 0.9000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7711 - val_loss: 0.9044\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7863 - val_loss: 0.8974\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7780 - val_loss: 0.9034\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.7987 - val_loss: 0.8926\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7761 - val_loss: 0.8892\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7943 - val_loss: 0.8893\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8094 - val_loss: 0.8978\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7881 - val_loss: 0.8996\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8015 - val_loss: 0.8927\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7809 - val_loss: 0.8868\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8075 - val_loss: 0.8854\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7873 - val_loss: 0.8894\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7905 - val_loss: 0.8917\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7805 - val_loss: 0.9012\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7896 - val_loss: 0.9351\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7823 - val_loss: 0.8993\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7809 - val_loss: 0.8977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WguOykzO8bSJ",
        "outputId": "8cb38b3b-0633-41dc-e12b-2d94426a9ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHrLvBFUB9d",
        "outputId": "a0b15d39-e019-4e8f-a480-8e690e672636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_CC_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6131555483504905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHma85Nt9Kky"
      },
      "source": [
        "# **5. Modelling for tweets related to target: Feminist Movement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZJsHUrUn5kE"
      },
      "source": [
        "First we check the preprocessed tweet data for target Feminist Movement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYn6HtDB9Kk1",
        "outputId": "a227f5ac-d80f-47d2-908f-b828ecc11f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "Tweets_FM[:1]"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['always',\n",
              "  'delight',\n",
              "  'see',\n",
              "  'chestdrumming',\n",
              "  'alpha',\n",
              "  'males',\n",
              "  'hiss',\n",
              "  'scuttle',\n",
              "  'backwards',\n",
              "  'wall',\n",
              "  'feminist',\n",
              "  'enters',\n",
              "  'room',\n",
              "  '#manly',\n",
              "  '#semst',\n",
              "  'feminist',\n",
              "  'movement']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU47Y2Hcn5kL"
      },
      "source": [
        "The next step is to call method padding which will tokenize the tweets and pad them with max length of 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9SjnDsq9Kk7",
        "outputId": "8e0eab15-1537-4894-d534-1007b72e2cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X, word_index = Padding(Tweets_FM)\n",
        "Y = pd.get_dummies(traindata_FM['Stance']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3031 unique tokens.\n",
            "Shape of data tensor: (664, 40)\n",
            "Shape of label tensor: (664, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXakGexWn5kN"
      },
      "source": [
        "The next step is to split the above data into training and validation. We are using above mentioned split() method by passing 0.2 as a split size which means 20% of the data is reserved for validation and remaining 80% data is used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPEWZ2rc9Kk9",
        "outputId": "25c0462e-ac8a-48ca-bff2-76f2064160c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "X_train, X_Val, Y_train, Y_Val = split(X, Y, 0.2)\n",
        "print(\"X train shape: \", X_train.shape)\n",
        "print(\"Y train shape: \", Y_train.shape)\n",
        "print(\"X Val shape: \", X_Val.shape)\n",
        "print(\"Y Val shape: \", Y_Val.shape)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train shape:  (531, 40)\n",
            "Y train shape:  (531, 3)\n",
            "X Val shape:  (133, 40)\n",
            "Y Val shape:  (133, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWfMQLKi9KlA"
      },
      "source": [
        "**Without Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy4Jr0-H9KlA",
        "outputId": "b63765b0-6aca-476c-c891-a67235f581c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                                   embedding_dim,\n",
        "                                   input_length=MAX_LENGTH,\n",
        "                                   trainable=True)\n",
        "model = create_model(embedding_layer)\n",
        "print(model.summary())"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 40, 100)           303200    \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 322,531\n",
            "Trainable params: 322,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ansOZNmNn5kP"
      },
      "source": [
        "As we have less amount of data available for training, we are using K-fold cross validation technique to train our model for 50 epochs in each of the 3 folds.\n",
        "The batch size is set to 64 and we trained the data for 50 epochs and 3 folds.\n",
        "\n",
        "From the below output we can see that the model achieved categorical accuracy of about 74% on the validation data set.\n",
        "\n",
        "To check the learning curve of the training and validation we plot the grphs using plotter function mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVHihgjs9KlD",
        "outputId": "4af90d43-dc30-45bf-c73d-32db8302df84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 3\n",
        "input = np.concatenate((X_train, X_Val), axis= 0)\n",
        "target = np.concatenate((Y_train, Y_Val), axis= 0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "K = 1\n",
        "for train, test in kfold.split(input, target):\n",
        "    print(\"fold number: \", K)\n",
        "    m_histories = {}\n",
        "    m_histories['with_TL'] = model.fit(input[train], target[train], batch_size=32, epochs=20, validation_data=(input[test], target[test]), callbacks=get_callbacks('models/with_TL'), verbose=1)\n",
        "    K = K+1"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold number:  1\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 4s - loss: 1.2037WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0732s vs `on_train_batch_end` time: 0.6662s). Check your callbacks.\n",
            "14/14 [==============================] - 2s 150ms/step - loss: 1.1835 - val_loss: 1.1216\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 69ms/step - loss: 1.1341 - val_loss: 1.0877\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 72ms/step - loss: 1.1084 - val_loss: 1.0669\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 1.1068 - val_loss: 1.0572\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0996 - val_loss: 1.0543\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0902 - val_loss: 1.0444\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0824 - val_loss: 1.0478\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0766 - val_loss: 1.0395\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0699 - val_loss: 1.0358\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 1.0662 - val_loss: 1.0262\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0678 - val_loss: 1.0275\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.0558 - val_loss: 1.0223\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0654 - val_loss: 1.0255\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0654 - val_loss: 1.0268\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 1.0561 - val_loss: 1.0230\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0582 - val_loss: 1.0181\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 58ms/step - loss: 1.0494 - val_loss: 1.0150\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 1.0570 - val_loss: 1.0196\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.0458 - val_loss: 1.0117\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.9327 - val_loss: 1.0102\n",
            "fold number:  2\n",
            "Epoch 1/20\n",
            " 2/14 [===>..........................] - ETA: 1s - loss: 0.8100WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0692s vs `on_train_batch_end` time: 0.1226s). Check your callbacks.\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 0.8925 - val_loss: 0.7225\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7925 - val_loss: 0.6836\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.7929 - val_loss: 0.8045\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.7459 - val_loss: 0.6544\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7110 - val_loss: 0.6441\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.6613 - val_loss: 0.6183\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.8081 - val_loss: 0.6603\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7566 - val_loss: 0.7319\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.7081 - val_loss: 0.6512\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.6344 - val_loss: 0.6132\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5802 - val_loss: 0.6462\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.5198 - val_loss: 0.6175\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5123 - val_loss: 0.6107\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4677 - val_loss: 0.6090\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4525 - val_loss: 0.6081\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4862 - val_loss: 0.6350\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.4889 - val_loss: 0.5765\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4333 - val_loss: 0.5514\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4163 - val_loss: 0.7688\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.5252 - val_loss: 0.6189\n",
            "fold number:  3\n",
            "Epoch 1/20\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 0.5189 - val_loss: 0.4075\n",
            "Epoch 2/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.4396 - val_loss: 0.4251\n",
            "Epoch 3/20\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.4724 - val_loss: 0.4175\n",
            "Epoch 4/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4299 - val_loss: 0.4144\n",
            "Epoch 5/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4528 - val_loss: 0.3712\n",
            "Epoch 6/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4771 - val_loss: 0.3912\n",
            "Epoch 7/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4272 - val_loss: 0.4406\n",
            "Epoch 8/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4632 - val_loss: 0.4628\n",
            "Epoch 9/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.4621 - val_loss: 0.4531\n",
            "Epoch 10/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4386 - val_loss: 0.4495\n",
            "Epoch 11/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4574 - val_loss: 0.4245\n",
            "Epoch 12/20\n",
            "14/14 [==============================] - 1s 66ms/step - loss: 0.4132 - val_loss: 0.4249\n",
            "Epoch 13/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.4133 - val_loss: 0.4275\n",
            "Epoch 14/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.3937 - val_loss: 0.4289\n",
            "Epoch 15/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.4063 - val_loss: 0.4327\n",
            "Epoch 16/20\n",
            "14/14 [==============================] - 1s 62ms/step - loss: 0.4105 - val_loss: 0.4314\n",
            "Epoch 17/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.3880 - val_loss: 0.4327\n",
            "Epoch 18/20\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 0.3603 - val_loss: 0.4365\n",
            "Epoch 19/20\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.3706 - val_loss: 0.4402\n",
            "Epoch 20/20\n",
            "14/14 [==============================] - 1s 60ms/step - loss: 0.3674 - val_loss: 0.4447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYFP3QnVn5kQ"
      },
      "source": [
        "We tried to plot learning curves for both validation and training data on Catergorical Crossentropy as well as for Catergorical Accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVUf2S6n9KlF",
        "outputId": "547e960b-070a-4ba6-c047-1145c483cc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c/DsAybyKIjMiioxF0HmYAi6CAKiEbCDRH9JV7iNZfcGKLJL8vVeKO5xJu45Jd4jUkMV4lLVIgarpgQFZWJqME44KgsIougQ3ADWUZEmJnn98epZnpmqoce6ZoFv+/Xq17dfU5V1zM91eepc6q6ytwdERGR+tq1dAAiItI6KUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxEosQZhZfzNbYGbLzWyZmV0ZM4+Z2a1mttrMXjGzU9LqppjZqmiaklScIiISz5L6HYSZ9QX6uvsSM+sOLAY+7+7L0+YZD3wTGA8MA/7b3YeZWS+gDCgGPFp2iLt/kEiwIiLSQGI9CHff6O5LoufbgRVAv3qzTQDu8WARcGCUWMYC8919c5QU5gPjkopVREQaat8cKzGzAcBg4IV6Vf2At9JeV0Rlmcrj3nsqMBWgc+fOQ/r375+TmBtTU1NDu3Zt5/CN4k1eW4tZ8SarLcX7+uuvv+/uB8XVJZ4gzKwb8DDwLXffluv3d/cZwAyA4uJiLysry/UqGigtLaWkpCTx9eSK4k1eW4tZ8SarLcVrZusz1SWa4sysAyE53Ofuf4yZZQOQvstfGJVlKhcRkWaS5FlMBtwJrHD3n2eYbS7wz9HZTKcCW919I/A4MMbMeppZT2BMVCYiIs0kySGm04FLgFfNrDwq+wFwGIC73w7MI5zBtBrYAVwa1W02sx8DL0bLTXf3zQnGKiIi9SSWINz9WcD2Mo8D38hQNxOYmUBoIpKw3bt3U1FRwc6dO3Pyfj169GDFihU5ea/m0Brjzc/Pp7CwkA4dOmS9TLOcxSQiny4VFRV0796dAQMGEEab98327dvp3r17DiJrHq0tXndn06ZNVFRUMHDgwKyXaxvnYYlIm7Jz50569+6dk+Qg+87M6N27d5N7dEoQIpIIJYfW5ZP8P5QgREQklhKEiIjEUoIQkU+l8ePHs2XLFrZs2cKvf/3rPeWlpaWcf/75Wb3HxIkTKSoq4qijjqJHjx4UFRVRVFTECy+8QElJCdlc2aG8vJx58+Y1Of5//OMfTJo0qcnLNYUShIh8Ks2bN48DDzywQYJoijlz5lBeXs4dd9zByJEjKS8vp7y8nGHDhmX9Ho0liKqqqozLHXrooTz00ENNjrkpdJqriCTqW9+C8vK9z9eY6urO5OXVvi4qgltuaXyZm2++mU6dOnHFFVfw7W9/m5dffpmnn36ap59+mjvvvJPnnnuOsrIyrrrqKtasWUNRURHnnHMO5513HpWVlUyaNImlS5cyZMgQfv/73ydy0H3Xrl1ce+21fPTRRzz77LNcffXVrFixgjVr1rB27VoOO+wwfvrTn3LJJZfw4YcfAnDbbbcxfPhw1q1bx/nnn8/SpUu56667mDt3Ljt27GDNmjVMnDiRm266aZ/jUw9CRPZLI0eOZOHChQCUlZVRWVnJ7t27WbhwIWecccae+W644QaOPPJIysvLufnmmwF46aWXuOWWW1i+fDlr167lueeeSyTGjh07Mn36dCZPnkx5eTmTJ08GYPny5Tz55JM88MADHHzwwcyfP58lS5Ywe/Zsrrjiitj3Ki8vZ/bs2bz66qvMnj2bt956K3a+plAPQkQStbc9/Wxs3/5Rk394NmTIEBYvXsy2bdvo1KkTp5xyCmVlZSxcuJBbb72Vn/70pxmXHTp0KIWFhQAUFRWxbt06RowYsU9/Q1NccMEFdO7cGQi/Sp82bRrl5eXk5eXx+uuvxy4zevRoevToAcBxxx3H+vXr2dfbHyhBiMh+qUOHDgwcOJC77rqL4cOHc9JJJ7FgwQJWr17Nscce2+iynTp12vM8Ly+v0WMBSejateue57/4xS8oKCjg5Zdfpqamhvz8/NhlkohZQ0wist8aOXIkP/vZzzjjjDMYOXIkt99+O4MHD65zPKF79+5s3769xWLc2/q3bt1K3759adeuHffeey/V1dXNFpsShIjst0aOHMnGjRs57bTTKCgoID8/n5EjR9aZp3fv3px++umccMIJfO9738vp+s877zwKCwspLCzki1/8Yuw8o0aNYvny5RQVFTF79uwG9Zdffjl33303J598Mq+99lqd3kXi3H2/mYYMGeLNYcGCBc2ynlxRvMlrazEnHe/y5ctz+n7btm3L6fslrbXGG/d/Aco8Q5uqHoSIiMTSQWoRkSxMnDiRN954o07ZjTfeyNixY7Na/vHHH+ff//3f65QNHDiQOXPm5CzGXFOCEBHJwr425GPHjs06mbQWGmISEZFYifUgzGwmcD7wrrufEFP/PeBLaXEcCxzk4X7U64DtQDVQ5e7FScUpIiLxkuxB3AWMy1Tp7je7e5G7FwFXA391981ps4yK6pUcRERaQGIJwt2fATbvdcbgYuCBpGIREZGma/FjEGbWhdDTeDit2IEnzGyxmU1tmchEZH/WWu4H0VRNiW9ftYazmD4HPFdveGmEu28ws4OB+Wb2WtQjaSBKIFMBCgoKKC0tTTzgysrKZllPrije5LW1mJOOt0ePHjm9fEV1dXXOL4eR+tXy+vXrue2227jkkksA2LFjB1VVVVmt75577gHYcwHABx98cE+81dXVfPjhhzmPuynx1bdz584m/d9bQ4K4iHrDS+6+IXp818zmAEOB2ATh7jOAGQDFxcVeUlKSaLAQMnhzrCdXFG/y2lrMSce7YsWKOldfjVvVhRfC5ZfDjh0wfnzD+q98JUzvvw8TJ1aRl1fbXGXTxmV7P4jrr7+eN954g5EjR+65H8TOnTu59NJLs74fRJcuXWjfvv2ev3n79u3k5eXRtWvXvV6F9tRTT+XOO+/k+OOPB6CkpISf/exn1NTUcOWVV7Jz5046d+7M7373O44++ugG62qK/Px8Bg8enPX8LTrEZGY9gDOBR9LKuppZ99RzYAywtGUiFJG2qi3cDwJg8uTJ/OEPfwBg48aNbNy4keLiYo455hgWLlzISy+9xPTp0/nBD36QWAyZJHma6wNACdDHzCqA64AOAO5+ezTbROAJd/8wbdECYE6UrdsD97v7Y0nFKSLJa2yPv0uXxuv79IF58/bf+0FceOGFjBkzhv/8z//kD3/4w577TG/dupUpU6awatUqzIzdu3cnsv7GJJYg3P3iLOa5i3A6bHrZWuDkZKISkU+LtnI/iH79+tG7d29eeeUVZs+eze23h/3nH/7wh4waNYo5c+awbt26FhnCbPGzmEREktIW7gcBYZjppptuYuvWrZx00klA6EH069cPgLvuuqtF4lKCEJH9Vlu4HwTApEmTmDVrFhdeeOGesu9///tcffXVDB48uNnvaJfSGs5iEhFJxOjRo+uM3affz3ndunV7nt9///11lksfzrntttv2up6SkpIGQ0BNOZ20oKCgQRI47bTT6sR7/fXXZ1xXUtSDEBGRWOpBiIhkQfeDEBHJEXdv9MdlbU1bvx9EuLto02iISURyLj8/n02bNn2iRklyz93ZtGkT+fn5TVpOPQgRybnCwkIqKip47733cvJ+O3fubHLj1pJaY7z5+fl7fvyXLSUIEcm51I/UcqW0tLRJ1xBqaW0t3kw0xCQiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJFZiCcLMZprZu2a2NEN9iZltNbPyaLo2rW6cma00s9VmdlVSMYqISGZJ9iDuAsbtZZ6F7l4UTdMBzCwP+BVwLnAccLGZHZdgnCIiEiOxBOHuzwCbP8GiQ4HV7r7W3XcBs4AJOQ1ORET2ypK8XruZDQD+5O4nxNSVAA8DFcA/gO+6+zIzmwSMc/evRvNdAgxz92kZ1jEVmApQUFAwZNasWQn8JXVVVlbSrVu3xNeTK4o3eW0tZsWbrLYU76hRoxa7e3FcXUte7nsJcLi7V5rZeOB/gUFNfRN3nwHMACguLvbmuJl3aWlps900PBcUb/LaWsyKN1ltLd5MWuwsJnff5u6V0fN5QAcz6wNsAPqnzVoYlYmISDNqsQRhZodYdMNaMxsaxbIJeBEYZGYDzawjcBEwt6XiFBH5tEpsiMnMHgBKgD5mVgFcB3QAcPfbgUnA182sCvgIuMjDAZEqM5sGPA7kATPdfVlScYqISLzEEoS7X7yX+tuA2zLUzQPmJRGXiIhkR7+kFhGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISK7EEYWYzzexdM1uaof5LZvaKmb1qZs+b2clpdeui8nIzK0sqRhERySzJHsRdwLhG6t8AznT3E4EfAzPq1Y9y9yJ3L04oPhERaUT7pN7Y3Z8xswGN1D+f9nIRUJhULCIi0nTm7sm9eUgQf3L3E/Yy33eBY9z9q9HrN4APAAd+6+71exfpy04FpgIUFBQMmTVrVm6Cb0RlZSXdunVLfD25oniT19ZiVrzJakvxjho1anHGkRp3T2wCBgBL9zLPKGAF0DutrF/0eDDwMnBGNusbMmSIN4cFCxY0y3pyRfEmr63FrHiT1ZbiBco8Q5vaomcxmdlJwB3ABHfflCp39w3R47vAHGBoy0QoIvLp1WIJwswOA/4IXOLur6eVdzWz7qnnwBgg9kwoERFJTmIHqc3sAaAE6GNmFcB1QAcAd78duBboDfzazACqPIyDFQBzorL2wP3u/lhScYqISLwkz2K6eC/1XwW+GlO+Fji54RIiItKc9EtqERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYmWVIMzsSjM7wII7zWyJmY1JOjgREWk52fYg/sXdtxFu/9kTuAS4IbGoRESkxWWbICx6HA/c6+7L0spERGQ/lG2CWGxmTxASxONm1h2o2dtCZjbTzN41s6UZ6s3MbjWz1Wb2ipmdklY3xcxWRdOULOMUEZEcyTZBXAZcBXzW3XcAHYBLs1juLmBcI/XnAoOiaSrwGwAz6wVcBwwDhgLXmVnPLGMVEZEcyDZBnAasdPctZvZl4D+ArXtbyN2fATY3MssE4B4PFgEHmllfYCww3903u/sHwHwaTzQiIpJj7bOc7zfAyWZ2MvAd4A7gHuDMfVx/P+CttNcVUVmm8gbMbCqh90FBQQGlpaX7GNLeVVZWNst6ckXxJq+txax4k9XW4s0k2wRR5e5uZhOA29z9TjO7LMnAsuXuM4AZAMXFxV5SUpL4OktLS2mO9eSK4k1eW4tZ8SarrcWbSbZDTNvN7GrC6a1/NrN2hOMQ+2oD0D/tdWFUlqlcRESaSbYJYjLwMeH3EG8TGuybc7D+ucA/R2cznQpsdfeNwOPAGDPrGR2cHhOViYhIM8lqiMnd3zaz+4DPmtn5wN/d/Z69LWdmDwAlQB8zqyCcmdQhes/bgXmEU2dXAzuIzoxy981m9mPgxeitprt7Ywe7RUQkx7JKEGZ2IaHHUEr4gdwvzex77v5QY8u5+8V7qXfgGxnqZgIzs4lPRERyL9uD1NcQfgPxLoCZHQQ8CTSaIEREpO3K9hhEu1RyiGxqwrIiItIGZduDeMzMHgceiF5PJhw/EBGR/VS2B6m/Z2ZfAE6Pima4+5zkwhIRkZaWbQ8Cd38YeDjBWEREpBVpNEGY2XbA46oIJyEdkEhUIiLS4hpNEO7evbkCERGR1kVnIomISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisRJNEGY2zsxWmtlqM7sqpv4XZlYeTa+b2Za0uuq0urlJxikiIg1lfbnvpjKzPOBXwDlABfCimc119+Wpedz922nzfxMYnPYWH7l7UVLxiYhI45LsQQwFVrv7WnffBcwCJjQy/8XU3rFORERamLnH3e4hB29sNgkY5+5fjV5fAgxz92kx8x4OLAIK3b06KqsCyoEq4AZ3/98M65kKTAUoKCgYMmvWrCT+nDoqKyvp1q1b4uvJFcWbvLYWs+JNVluKd9SoUYvdvTiuLrEhpia6CHgolRwih7v7BjM7AnjazF519zX1F3T3GcAMgOLiYi8pKUk82NLSUppjPbmieJPX1mJWvMlqa/FmkuQQ0wagf9rrwqgszkXUG15y9w3R41qglLrHJ0REJGFJJogXgUFmNtDMOhKSQIOzkczsGKAn8Le0sp5m1il63gc4HVhef1kREUlOYkNM7l5lZtOAx4E8YKa7LzOz6UCZu6eSxUXALK97MORY4LdmVkNIYjekn/0kIiLJS/QYhLvPA+bVK7u23usfxSz3PHBikrGJiEjj9EtqERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxEk0QZjbOzFaa2Wozuyqm/itm9p6ZlUfTV9PqppjZqmiakmScIiLSUGL3pDazPOBXwDlABfCimc119+X1Zp3t7tPqLdsLuA4oBhxYHC37QVLxiohIXUn2IIYCq919rbvvAmYBE7Jcdiww3903R0lhPjAuoThFRCRGYj0IoB/wVtrrCmBYzHxfMLMzgNeBb7v7WxmW7Re3EjObCkwFKCgooLS0dN8j34vKyspmWU+uKN7ktbWYFW+y2lq8mSSZILLxKPCAu39sZl8D7gbOasobuPsMYAZAcXGxl5SU5DzI+kpLS2mO9eSK4k1eW4tZ8SarrcWbSZIJYgPQP+11YVS2h7tvSnt5B3BT2rIl9ZYtzXmEaaqqYMUK2LwZhg6Fzp2TXFsyamrgzTfh9ddh5crw+Prr8PbbRVx0EVxwARx3HJi1dKQi0hYkmSBeBAaZ2UBCg38R8H/SZzCzvu6+MXp5AbAiev448BMz6xm9HgNcnavAqqvhtddg8WIoKwtTeTl89FGo79gRhg+H0aPD9NnPQvuW7mul2bSpbgJIPV+1Cj7+uHa+bt3g6KPho4/y+MEP4Ac/gCOPhAkTQrI4/fTm+7uqqmDZMtiwAXbvhg8+CImqe/eQjNu1q51efvlAoPa1WcPnXbrAEUdAfn7zxC/yaZRY8+DuVWY2jdDY5wEz3X2ZmU0Hytx9LnCFmV0AVAGbga9Ey242sx8TkgzAdHff/EniqK4OjWd6MnjpJdixI9R37QqnnAJf+xoUF0OPHlBaCk89BT/8YZi6d4czz6xNGO6f/HPJ1o4dsGZNw97AypWhl5PSvn1o9D/zGRg7NiSEz3wmTIccEhrU0tLFDBpUwqOPwty5cNtt8POfQ69ecN55IWGMHRsSyr7YubO2wZ41Cx56CJYuDUmhsrIp71SU9ZyHHAIDB4bpmGOgqCj87X37hiSSl5e7HlNNDbz9duilvfVWeHzzTXj3XTjggP706AEnnxwSmMj+wLw5WrtmUlxc7PffX7YnESxeDEuW1DZOXbrA4MEwZEhIBsXFoTHJy4t/v/ffr00WTz0V9tABevbcxdixHRk9Gs46K+zJfhLbt8Pq1fHTP/5Rd95DD63b+KeeDxgAHTo0vp7646Hbt8MTT8Ajj8Cf/xwSTseOIflNmACf+1xYX32pTcUMFi2C+fNDrGvWhM/mgw9g2jT4+99DfXV1mL9zZzj88NB4fuMbIRE9/zxUVIRYtm8P/6MePeDSS2Hx4pf44x8Hs3JlKE8l85NPhv/6rxDHZZeFhjkbeXkhkZ51FvzylyGWwYNDfAUF4bM85phQ1rt3wwSQel1REXo/6bp1C8usXx9eH3QQnH02jBkD55wD/WJPrWh5bW2M/NMUr3vYzj7+uHbq1St8j7ZsCaMfqfJDD4UTTti3WM1ssbsXx9btTwkiL6/Ya2rKgLAnWz8ZHHNM5mSQjTffhKefhvvvf5ulSw9hYzQ4NmBAbe/irLNCo5OyZUvmJPDOO3Xf/5BD4KijaqcjjwyN16BB+7Z339jGWlUFzz0XehaPPBIaewjDahMmwIknhg3yT3+Cl18OPZheveCb34QZM8JGW1NTO7TVoUP4rIcOhREj4NRTobBw3+Ktrg5JZPfu0AADPPlkSB67doXyXbvggAPCF2bVKrjvvpBk338/JMBdu2rfv0OHEHeXLqHXs317bTKr74ADQm9kwAA4/vjwfznsMOjfPzz26BES5sMPP8+OHcN54omQOFP/2+OOC8lizBg444zQY20NPk0Nbn0ffhi2h/Spe3c4+OCwHSxa1LD+6KNDQ/zhh3D33bXlqW3v7LNh5Mjwf7/uOli/fiO9e/fdM9/Xvgbnnhu+S1/5St0EsHMn3HorTJwYdkhHjWoY89y5Ycft0UfD8HDK174Gt9++b5/HpyZB9O5d7D/6URnDh8NJJ+19z/qTKi0t5cwzS3jttdreRWlpSAYQNqSuXUMS2LSp7rL9+tUmgEGDap8fcUTYSJOKN5svl3s4UP/II/D738PytJ80HnRQiL19e3j11dqEcNhhcNppIRGcdloY4unUqXnizZZ7+OKuWtVwyssLjf3BB4dEcPzx4X93662wbh2sXVubPP77v+GKK0Jv4ic/CTscqQS+ZMnzfO5zw8nPD43Ic8/BX/8KzzwTelS7doXtccSIMFw5eDAce2wYjkp9Bfv3D5/d+++HdezeHRJ4aho+POz4rFwZhu7S66qq4MtfDss/9xy8+GJI3NXV4bGmBr7//fD3/vnPMHv2OgoLB+ypa9cObrghxHHvvfC3v9U2frt2hYQ6c2aov+YaWLCgbiPZt2/YeYKwY/Hkk6Guqiq898knh948hAawrCyU5+WFx2HDQlwQdrRS/5vUsadBgzYyb15fIGxrFRW1f1dNTWg877yz9nPcvLlu/ZQpcMcdoT4vL5Slu/JKuOWWcByyS5eG29A118D114dea/oOYMqNN4bPd926EJ/7Trp3z6djx9A7v+Ya+OIXww7Y5ZeHbaFTpzDl58O//mv4/qxfH/6OVF1qGjs29HzffTeMjKTKDz00DK/ui8YSRCs69LrvNm8OX2AIG+jo0WHP97vfDXvg6dNPfhIa5SVLwnBLt26hYejSJfxDzzknlL35Zvind+hQO61b14URI8IXvLAQLrwwbMTLlsHChWGqqoJJk+r2CI44In7ja2nbtsHjj9funVx9NVx8cRjuOfTQ0Lg++2yYr7g49B5SSSFuKKq1MQu9s0MOCXt52Tj//PC4a1f4Ur/2WmjkIGwPs2bV7hAEw3nssfBFfuyx8L+vb9KksI386Efx63zlldBje+CB2u043RtvhJ7MH/8YTjio7/OfD43Gn/5U29in+853QuP42GNw332H12mgO3WqXeaFF+DBB9nTuHXsGIbRUtq3D9+Vnj1r6/v2ra0/99ww/NmxY3h/95CAUyZODMf90pNXeiM3fHjY8UjVVVdDt24f7akfMSIMZ6YnkFNOqV1+ypSwA5N+4sOQIbX1N98clk3/+449NtR16hTagw4d6tYfckio79MnHIdKr2vfvvY414ABob60dFHsTs6RR4bvWiaHHw7Tp2euP/jg8Pk2l/2qBzFgQLF/5ztlVFbCl74UNrKFC8NB2crKutMjj4Q9wF/+Mv7LuGZNaNBvuCE0mPW98074Z/3Hf4Rx8fo2bAiN55o1YRiiT5/c/73Zitsjr6mB3/wmdF0XLAh7gb16hcbrm99s+B47d4YvWseOLRNva+MO770X9uZXr4Zly1Zy5ZVH079/aMhTe9OphsMMxo8Pe59/+1sYpnj11dAT2LYtzHPIIeHzraoKiSl9WQh1ZqHBrK5uWJ86IN+9e9hxOeywMA0YEBqeo44K62jXLvnPuKYmJNAtW+qOpe/aVfdxb2Wp51u2rGf06MM58sjav6M1n67dFrbhlE/NEFNxcbGXlZU1aRn30Ph9+GFIHB9+GBrLY48NexPr14cGYPfu2qm8fBnXXHM8nTqFva2ysrr1nTqFvTWAf/onmDMnDCmcfXaYRoxo3p5EakhsyZLwt0yeHMpPPDF8+S64IEynndY6TudtS1+ulE8as3tIEk88ER6z0VjD6B560uvXh6luLydsm/37wwEHfEBRUU8OP5w6U2Fhw6FZ93Cc5v33s582bWo4jNNU7duHeDt2hK1bnZqa2j+8S5ewN55KGOmPhx22b8cac6EtbcOfmiGmT8IsjK927hy/l5/64qTr1eu9PePsw4aFKZNrrgnd2yefDGOcN98c5l+0KNSvXBk27CQ26KVLw97qo49+hi9/OfRqDjwQvvCF8OV75pkwTCAtxywk6hNPTOb9t22rTRbp06uv5jFvXhgOSdeuXej59usXzh5LNfj1z95Kad8+fG9S0/HH13194IF1x9I7dqz7mOl5x451Txd+8slnGDDgzD1nzaUeV66Ev/yl7u9/OnQIQ1b1k0dqmDepY5P7o099gkjakCFhuuaa0Dt59tkwhABhox48OHwhzjqrtodx1FHZdZ9ffz0cIF+/PoyLr1sXnr/ySjio/OCDYTwzP7+A884LvYTx42t7CUoO+78DDohPQKWlSygpKWHnznDAt34CSQ2RDhtWt8GvPx1wQPMM9bRv73sa+fpqakK86Ykj9fzZZ0PvJ6VDhzC0fPzx4WSSE04IzwcObPleR2ukBNGMunYNBzHT/e534bTI+fPDwUcIvYzvfjd8UR99tG7jv25dGI4YPDj0AFJnRKR6OuedV3vWzeWXh98LrFr1LKNHn9mMf6m0Ffn5ZGx424p27cKwWf/+UH9Uxz30gFI/Ol2+PJwosGhRONEgpXPncEpy/cTRv3/uEuDHH9cel9myJewopp/8srcplz/6zO8CPsoAAApySURBVJYSRAvq1CkcD5g8OWzIa9aEoagzzgj1r70WDhjn54fGf8CA0BtJnUv/xS+GHkHqwGN9qdPx1q7df44ziTSFWehNH3RQOOsuXWVlSBhLl4Zp2bLw/bvnntp5DjggJIr0xFFYGHolqYb+gw/qNvxbtsCaNSfSrl3dso8+Yp+YxSeO3/ym7m8jckkJopUwa7gnd8YZYYz44IPj9xx69AiTiDRdt27hB51Dh9Yt/+CDkCzSE8ecObW/o8gkLy8ccznwQGjfvgP9+4djOamynj1rn/foERr39JNb9jalfnNSf0o/xTjXlCBasdTBcxFpPj17hjMNR4yoLXMPP1Jbtiz8Qr9Hj9rGPtX4d+1auyOXOsbT1ilBiIjshVkYso37FfX+TNedFBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrESTRBmNs7MVprZajO7Kqb+/5rZcjN7xcyeMrPD0+qqzaw8muYmGaeIiDSU2O8gzCwP+BVwDlABvGhmc9097T5lvAQUu/sOM/s6cBMQXYyaj9w9+7vXi4hITiXZgxgKrHb3te6+C5gFTEifwd0XuHt0S3oWAU28e7GIiCQlyQTRD3gr7XVFVJbJZcBf0l7nm1mZmS0ys88nEaCIiGSW2B3lzGwSMM7dvxq9vgQY5u7TYub9MjANONPdP47K+rn7BjM7AngaGO3ua2KWnQpMBSgoKBgyK/0avgmprKykW7duia8nVxRv8tpazIo3WW0p3lGjRmW8oxzunsgEnAY8nvb6auDqmPnOBlYABzfyXncBk/a2ziFDhnhzWLBgQbOsJ1cUb/LaWsyKN1ltKV6gzDO0qUkOMb0IDDKzgWbWEbgIqHM2kpkNBn4LXODu76aV9zSzTtHzPsDpQPrBbRERSVhiZzG5e5WZTQMeB/KAme6+zMymEzLWXOBmoBvwoIXr5L7p7hcAxwK/NbMawnGSG7zu2U8iIpKwRC/37e7zgHn1yq5Ne352huWeBxK6jbuIiGRDv6QWEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIlmiDMbJyZrTSz1WZ2VUx9JzObHdW/YGYD0uqujspXmtnYJOMUEZGGEksQZpYH/Ao4FzgOuNjMjqs322XAB+5+FPAL4MZo2eOAi4DjgXHAr6P3ExGRZpJkD2IosNrd17r7LmAWMKHePBOAu6PnDwGjzcyi8lnu/rG7vwGsjt5PRESaSfsE37sf8Fba6wpgWKZ53L3KzLYCvaPyRfWW7Re3EjObCkyNXlaa2cp9D32v+gDvN8N6ckXxJq+txax4k9WW4j08U0WSCaJZuPsMYEZzrtPMyty9uDnXuS8Ub/LaWsyKN1ltLd5Mkhxi2gD0T3tdGJXFzmNm7YEewKYslxURkQQlmSBeBAaZ2UAz60g46Dy33jxzgSnR80nA0+7uUflF0VlOA4FBwN8TjFVEROpJbIgpOqYwDXgcyANmuvsyM5sOlLn7XOBO4F4zWw1sJiQRovn+ACwHqoBvuHt1UrF+As06pJUDijd5bS1mxZusthZvLAs77CIiInXpl9QiIhJLCUJERGIpQWRgZv3NbIGZLTezZWZ2Zcw8JWa21czKo+nalog1LZ51ZvZqFEtZTL2Z2a3RJUxeMbNTWiLOKJaj0z63cjPbZmbfqjdPi3++ZjbTzN41s6VpZb3MbL6ZrYoee2ZYdko0zyozmxI3TzPFe7OZvRb9z+eY2YEZlm10+2nGeH9kZhvS/u/jMyzb6KV8mjHe2WmxrjOz8gzLNvvnu8/cXVPMBPQFTomedwdeB46rN08J8KeWjjUtnnVAn0bqxwN/AQw4FXihpWOO4soD3gYOb22fL3AGcAqwNK3sJuCq6PlVwI0xy/UC1kaPPaPnPVso3jFA++j5jXHxZrP9NGO8PwK+m8U2swY4AugIvFz/+9lc8dar/3/Ata3l893XST2IDNx9o7sviZ5vB1aQ4dfcbcgE4B4PFgEHmlnflg4KGA2scff1LR1Ife7+DOEMu3Tpl4i5G/h8zKJjgfnuvtndPwDmE64rlqi4eN39CXevil4uIvyuqFXI8PlmI5tL+eRcY/FGlwm6EHgg6TiaixJEFqKrzA4GXoipPs3MXjazv5jZ8c0aWEMOPGFmi6NLkNQXd/mT1pD0LiLzl6o1fb4pBe6+MXr+NlAQM09r/az/hdCLjLO37ac5TYuGxGZmGMJrjZ/vSOAdd1+Vob41fb5ZUYLYCzPrBjwMfMvdt9WrXkIYFjkZ+CXwv80dXz0j3P0UwhV0v2FmZ7RwPHsV/YjyAuDBmOrW9vk24GHsoE2cK25m1xB+V3Rfhllay/bzG+BIoAjYSBi2aQsupvHeQ2v5fLOmBNEIM+tASA73ufsf69e7+zZ3r4yezwM6mFmfZg4zPZ4N0eO7wBwaXgG3NV7C5Fxgibu/U7+itX2+ad5JDc1Fj+/GzNOqPmsz+wpwPvClKKk1kMX20yzc/R13r3b3GuB/MsTR2j7f9sA/AbMzzdNaPt+mUILIIBpPvBNY4e4/zzDPIdF8mNlQwue5qfmirBNLVzPrnnpOODC5tN5sc4F/js5mOhXYmjZU0lIy7nW1ps+3nvRLxEwBHomZ53FgjJn1jIZIxkRlzc7MxgHfBy5w9x0Z5slm+2kW9Y6LTcwQRzaX8mlOZwOvuXtFXGVr+nybpKWPkrfWCRhBGDp4BSiPpvHAvwH/Fs0zDVhGOINiETC8BeM9Iorj5Sima6Ly9HiNcBOnNcCrQHELf8ZdCQ1+j7SyVvX5EpLXRmA3YZz7MsIl6Z8CVgFPAr2ieYuBO9KW/RfCvUxWA5e2YLyrCeP1qe349mjeQ4F5jW0/LRTvvdH2+Qqh0e9bP97o9XjC2YVrWjLeqPyu1HabNm+Lf777OulSGyIiEktDTCIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBEmsDMqutdhTZnVxE1swHpVwkVaWmJ3XJUZD/1kbsXtXQQIs1BPQiRHIiu9X9TdL3/v5vZUVH5ADN7Orrw3FNmdlhUXhDdm+HlaBoevVWemf2PhXuQPGFmnVvsj5JPPSUIkabpXG+IaXJa3VZ3PxG4DbglKvslcLe7n0S4SN6tUfmtwF89XIjwFMKvawEGAb9y9+OBLcAXEv57RDLSL6lFmsDMKt29W0z5OuAsd18bXeTxbXfvbWbvEy4VsTsq3+jufczsPaDQ3T9Oe48BhHtIDIpe/zvQwd2vT/4vE2lIPQiR3PEMz5vi47Tn1eg4obQgJQiR3Jmc9vi36PnzhCuNAnwJWBg9fwr4OoCZ5ZlZj+YKUiRb2jsRaZrO9W5K/5i7p0517WlmrxB6ARdHZd8Efmdm3wPeAy6Nyq8EZpjZZYSewtcJVwkVaTV0DEIkB6JjEMXu/n5LxyKSKxpiEhGRWOpBiIhILPUgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGL9f7iIKFPSBwvdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmbxOOr1UgYd",
        "outputId": "48a2e15d-7de1-4bcd-ce3d-047d46d63b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "X_test, test_word_index = Padding(Test_Tweets_FM)\n",
        "Y_true = pd.get_dummies(testdata_FM['Stance']).values\n",
        "print('Shape of label tensor:', Y_true.shape)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1609 unique tokens.\n",
            "Shape of data tensor: (285, 40)\n",
            "Shape of label tensor: (285, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZgl5lPbUgYu",
        "outputId": "be366a0f-a0b6-42aa-bafc-188de00dd5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "Y_true = np.argmax(Y_true, axis= 1)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_FM_WTF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4250748671108782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yks4widM9KlK"
      },
      "source": [
        "**With Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBaBIA269KlK",
        "outputId": "a23f3f96-8b8a-4e40-f0a0-9f4eb0c37464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "E_T = np.zeros((len(word_index)+1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_vectors.get(word)\n",
        "    if embedding_vector is not None:  \n",
        "        E_T[i] = embedding_vector\n",
        "\n",
        "E_T.size"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ey5Mmr39KlN",
        "outputId": "b5bed18b-185a-4b7a-ac6a-d1862df4de9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "embedding_layer_TL = Embedding(len(word_index)+1,\n",
        "                                embedding_dim,\n",
        "                                weights=[E_T],\n",
        "                                input_length=MAX_LENGTH,\n",
        "                                trainable=False)\n",
        "model = create_model(embedding_layer_TL)\n",
        "print(model.summary())"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 40, 100)           303200    \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 322,531\n",
            "Trainable params: 19,331\n",
            "Non-trainable params: 303,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvDnzOGQ9KlQ",
        "outputId": "693970f1-ed6a-4741-bb7e-7b31142c277e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "m_histories['with_TL'] = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_Val, Y_Val), callbacks=get_callbacks('models/with_TL'), verbose=1)   "
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 2/17 [==>...........................] - ETA: 4s - loss: 1.2119WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0830s vs `on_train_batch_end` time: 0.4907s). Check your callbacks.\n",
            "17/17 [==============================] - 2s 99ms/step - loss: 1.1857 - val_loss: 1.1502\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 1.1183 - val_loss: 1.1041\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 1.0813 - val_loss: 1.0869\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 1.0645 - val_loss: 1.0783\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 1.0523 - val_loss: 1.0566\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 1.0456 - val_loss: 1.0421\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 1.0034 - val_loss: 1.0493\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.9996 - val_loss: 1.0950\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9752 - val_loss: 1.0045\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9642 - val_loss: 1.1205\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9728 - val_loss: 1.0199\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9421 - val_loss: 1.0678\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9623 - val_loss: 1.0199\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9404 - val_loss: 1.0727\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.9236 - val_loss: 1.1019\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9279 - val_loss: 1.0386\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9292 - val_loss: 1.0598\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9117 - val_loss: 1.0279\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9115 - val_loss: 1.0714\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9026 - val_loss: 1.1264\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9373 - val_loss: 1.0217\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8913 - val_loss: 1.0405\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9242 - val_loss: 1.1300\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8925 - val_loss: 1.0549\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.9230 - val_loss: 0.9986\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.9103 - val_loss: 1.0313\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8703 - val_loss: 1.1185\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8779 - val_loss: 1.1043\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8746 - val_loss: 1.0962\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8887 - val_loss: 1.0558\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8870 - val_loss: 1.0376\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.8579 - val_loss: 1.0539\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8787 - val_loss: 1.1383\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8931 - val_loss: 1.1638\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8991 - val_loss: 1.0986\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.9021 - val_loss: 1.0486\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8638 - val_loss: 1.1346\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8525 - val_loss: 1.1124\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8647 - val_loss: 1.0679\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8648 - val_loss: 1.0385\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8598 - val_loss: 1.1362\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8518 - val_loss: 1.1703\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.8279 - val_loss: 1.2389\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8331 - val_loss: 1.1270\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8315 - val_loss: 1.2553\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8312 - val_loss: 1.3817\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 1s 49ms/step - loss: 0.8953 - val_loss: 1.0728\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 1s 51ms/step - loss: 0.8387 - val_loss: 1.2415\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.8144 - val_loss: 1.0959\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 1s 50ms/step - loss: 0.8531 - val_loss: 1.1268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njB1jFeu9KlX",
        "outputId": "9e999ea5-a77f-414b-9409-8661c19fa878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plotter(m_histories, ylim=[0.0, 2], metric = 'loss')"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZdN-ZSEUnRt",
        "outputId": "d37ec34a-b96f-446c-e858-aeb4676e3cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "\n",
        "f1_score_result = f1_score(Y_true, Y_pred,average='weighted')\n",
        "result_df.loc[len(result_df)] = ['Approach2_FM_TF', f1_score_result]\n",
        "f1_score_result"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5426179178301419"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyjyeG5VHbYj",
        "outputId": "060ac66c-dcaa-4829-e84b-45f977a6519c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "result_df"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>F1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Approach1_All_data_model</td>\n",
              "      <td>0.522292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Approach2_HC_WTF</td>\n",
              "      <td>0.462292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Approach2_HC_TF</td>\n",
              "      <td>0.409779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Approach2_AB_WTF</td>\n",
              "      <td>0.515599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Approach2_AB_TF</td>\n",
              "      <td>0.399301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Approach2_AT_WTF</td>\n",
              "      <td>0.530519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Approach2_AT_TF</td>\n",
              "      <td>0.550413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Approach2_CC_WTF</td>\n",
              "      <td>0.612404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Approach2_CC_TF</td>\n",
              "      <td>0.613156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Approach2_FM_WTF</td>\n",
              "      <td>0.425075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Approach2_FM_TF</td>\n",
              "      <td>0.542618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  F1_score\n",
              "0   Approach1_All_data_model  0.522292\n",
              "1           Approach2_HC_WTF  0.462292\n",
              "2            Approach2_HC_TF  0.409779\n",
              "3           Approach2_AB_WTF  0.515599\n",
              "4            Approach2_AB_TF  0.399301\n",
              "5           Approach2_AT_WTF  0.530519\n",
              "6            Approach2_AT_TF  0.550413\n",
              "7           Approach2_CC_WTF  0.612404\n",
              "8            Approach2_CC_TF  0.613156\n",
              "9           Approach2_FM_WTF  0.425075\n",
              "10           Approach2_FM_TF  0.542618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    }
  ]
}